[2025-09-12T14:37:32.030+0000] {processor.py:161} INFO - Started process (PID=76) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:37:32.033+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T14:37:32.036+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:37:32.035+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:37:32.750+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:37:32.737+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
ModuleNotFoundError: No module named 'snowflake.snowpark'
[2025-09-12T14:37:32.755+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:37:32.902+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.920 seconds
[2025-09-12T14:38:26.174+0000] {processor.py:161} INFO - Started process (PID=108) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:38:26.222+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T14:38:26.263+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:38:26.261+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:38:27.483+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:38:27.467+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
ModuleNotFoundError: No module named 'snowflake.snowpark'
[2025-09-12T14:38:27.489+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:38:27.648+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.517 seconds
[2025-09-12T14:39:21.549+0000] {processor.py:161} INFO - Started process (PID=128) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:39:21.559+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T14:39:21.564+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:39:21.563+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:39:22.636+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:39:22.576+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
ModuleNotFoundError: No module named 'snowflake.snowpark'
[2025-09-12T14:39:22.741+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:39:23.146+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.633 seconds
[2025-09-12T14:39:58.666+0000] {processor.py:161} INFO - Started process (PID=158) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:39:58.706+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T14:39:58.724+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:39:58.716+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:39:59.377+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:39:59.358+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
ModuleNotFoundError: No module named 'snowflake.snowpark'
[2025-09-12T14:39:59.384+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:39:59.569+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.151 seconds
[2025-09-12T14:40:31.038+0000] {processor.py:161} INFO - Started process (PID=170) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:40:31.053+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T14:40:31.056+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:40:31.055+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:40:31.703+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:40:31.690+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
ModuleNotFoundError: No module named 'snowflake.snowpark'
[2025-09-12T14:40:31.707+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:40:33.775+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.828 seconds
[2025-09-12T14:41:11.590+0000] {processor.py:161} INFO - Started process (PID=182) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:41:11.595+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T14:41:11.615+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:41:11.614+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:41:12.677+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:41:12.646+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T14:41:12.681+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:41:13.291+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.751 seconds
[2025-09-12T14:41:45.456+0000] {processor.py:161} INFO - Started process (PID=195) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:41:45.460+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T14:41:45.464+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:41:45.462+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:41:46.016+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:41:45.984+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T14:41:46.019+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:41:46.597+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.219 seconds
[2025-09-12T14:42:35.416+0000] {processor.py:161} INFO - Started process (PID=220) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:42:35.419+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T14:42:35.422+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:42:35.421+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:42:35.790+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:42:35.776+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T14:42:35.793+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:42:35.915+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.552 seconds
[2025-09-12T14:43:17.666+0000] {processor.py:161} INFO - Started process (PID=237) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:43:17.669+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T14:43:17.671+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:43:17.670+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:43:18.011+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:43:17.995+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T14:43:18.013+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:43:18.119+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.486 seconds
[2025-09-12T14:43:55.721+0000] {processor.py:161} INFO - Started process (PID=259) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:43:55.727+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T14:43:55.730+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:43:55.729+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:43:56.124+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:43:56.109+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T14:43:56.127+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:43:57.291+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.627 seconds
[2025-09-12T14:44:39.451+0000] {processor.py:161} INFO - Started process (PID=272) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:44:39.455+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T14:44:39.467+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:44:39.458+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:44:40.233+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:44:40.214+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T14:44:40.236+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:44:40.406+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.066 seconds
[2025-09-12T14:45:16.494+0000] {processor.py:161} INFO - Started process (PID=285) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:45:16.497+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T14:45:16.500+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:45:16.498+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:45:16.868+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:45:16.849+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T14:45:16.871+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:45:17.034+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.576 seconds
[2025-09-12T14:45:47.517+0000] {processor.py:161} INFO - Started process (PID=297) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:45:47.520+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T14:45:47.533+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:45:47.531+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:45:48.095+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:45:48.079+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T14:45:48.097+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:45:48.241+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.799 seconds
[2025-09-12T14:46:20.218+0000] {processor.py:161} INFO - Started process (PID=309) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:46:20.221+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T14:46:20.234+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:46:20.233+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:46:20.812+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:46:20.794+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T14:46:20.814+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:46:20.970+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.851 seconds
[2025-09-12T14:46:56.464+0000] {processor.py:161} INFO - Started process (PID=322) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:46:56.466+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T14:46:56.469+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:46:56.468+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:46:57.052+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:46:57.035+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T14:46:57.054+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:46:57.186+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.822 seconds
[2025-09-12T14:47:31.493+0000] {processor.py:161} INFO - Started process (PID=334) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:47:31.499+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T14:47:31.504+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:47:31.503+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:47:31.980+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:47:31.962+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T14:47:31.983+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:47:32.125+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.686 seconds
[2025-09-12T14:48:15.388+0000] {processor.py:161} INFO - Started process (PID=347) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:48:15.394+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T14:48:15.401+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:48:15.399+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:48:17.376+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:48:17.342+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T14:48:17.382+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:48:17.603+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.284 seconds
[2025-09-12T14:48:58.591+0000] {processor.py:161} INFO - Started process (PID=359) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:48:58.600+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T14:48:58.608+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:48:58.605+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:48:59.324+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:48:59.291+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T14:48:59.328+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:48:59.553+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.029 seconds
[2025-09-12T14:49:41.205+0000] {processor.py:161} INFO - Started process (PID=371) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:49:41.208+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T14:49:41.213+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:49:41.211+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:49:42.570+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:49:42.555+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T14:49:42.573+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:49:42.669+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.511 seconds
[2025-09-12T14:50:33.953+0000] {processor.py:161} INFO - Started process (PID=386) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:50:33.971+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T14:50:33.979+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:50:33.975+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:50:35.864+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:50:35.828+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T14:50:35.870+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:50:36.094+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.217 seconds
[2025-09-12T14:51:17.570+0000] {processor.py:161} INFO - Started process (PID=399) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:51:17.576+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T14:51:17.582+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:51:17.579+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:51:19.599+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:51:19.561+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T14:51:19.605+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:51:19.840+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.345 seconds
[2025-09-12T14:52:00.227+0000] {processor.py:161} INFO - Started process (PID=411) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:52:00.230+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T14:52:00.235+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:52:00.233+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:52:01.115+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:52:01.095+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T14:52:01.119+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:52:01.246+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.058 seconds
[2025-09-12T14:52:41.214+0000] {processor.py:161} INFO - Started process (PID=423) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:52:41.219+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T14:52:41.224+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:52:41.222+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:52:42.345+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:52:42.321+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T14:52:42.348+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:52:42.499+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.378 seconds
[2025-09-12T14:53:17.894+0000] {processor.py:161} INFO - Started process (PID=435) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:53:17.900+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T14:53:17.907+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:53:17.903+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:53:19.786+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:53:19.749+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T14:53:19.792+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:53:20.028+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.217 seconds
[2025-09-12T14:54:01.962+0000] {processor.py:161} INFO - Started process (PID=446) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:54:01.968+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T14:54:01.974+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:54:01.972+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:54:03.928+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:54:03.903+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T14:54:03.933+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:54:04.104+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.200 seconds
[2025-09-12T14:54:40.872+0000] {processor.py:161} INFO - Started process (PID=458) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:54:40.879+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T14:54:40.885+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:54:40.882+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:54:42.582+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:54:42.542+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T14:54:42.589+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:54:42.826+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.041 seconds
[2025-09-12T14:55:35.928+0000] {processor.py:161} INFO - Started process (PID=472) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:55:35.934+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T14:55:35.942+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:55:35.938+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:55:37.755+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:55:37.730+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T14:55:37.760+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:55:37.929+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.111 seconds
[2025-09-12T14:56:17.898+0000] {processor.py:161} INFO - Started process (PID=484) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:56:17.901+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T14:56:17.904+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:56:17.903+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:56:18.814+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:56:18.796+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T14:56:18.817+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:56:18.932+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.082 seconds
[2025-09-12T14:57:17.053+0000] {processor.py:161} INFO - Started process (PID=499) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:57:17.057+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T14:57:17.061+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:57:17.059+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:57:17.931+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:57:17.910+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T14:57:17.934+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:57:18.054+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.039 seconds
[2025-09-12T14:57:58.715+0000] {processor.py:161} INFO - Started process (PID=511) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:57:58.718+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T14:57:58.722+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:57:58.720+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:57:59.667+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:57:59.645+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T14:57:59.671+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:57:59.797+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.125 seconds
[2025-09-12T14:58:49.751+0000] {processor.py:161} INFO - Started process (PID=525) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:58:49.757+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T14:58:49.765+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:58:49.761+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:58:51.495+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:58:51.445+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T14:58:51.501+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:58:51.710+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.050 seconds
[2025-09-12T14:59:36.337+0000] {processor.py:161} INFO - Started process (PID=537) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:59:36.340+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T14:59:36.343+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:59:36.341+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:59:36.715+0000] {logging_mixin.py:188} INFO - [2025-09-12T14:59:36.699+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T14:59:36.718+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T14:59:36.817+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.520 seconds
[2025-09-12T15:00:13.395+0000] {processor.py:161} INFO - Started process (PID=550) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:00:13.404+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:00:13.410+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:00:13.408+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:00:14.482+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:00:14.448+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:00:14.490+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:00:14.728+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.410 seconds
[2025-09-12T15:00:58.936+0000] {processor.py:161} INFO - Started process (PID=564) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:00:58.942+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:00:58.949+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:00:58.946+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:00:59.586+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:00:59.556+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:00:59.590+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:00:59.796+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.987 seconds
[2025-09-12T15:02:36.207+0000] {processor.py:161} INFO - Started process (PID=583) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:02:36.215+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:02:36.223+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:02:36.216+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:02:36.940+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:02:36.919+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:02:36.949+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:02:37.612+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.489 seconds
[2025-09-12T15:03:53.500+0000] {processor.py:161} INFO - Started process (PID=598) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:03:53.503+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:03:53.514+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:03:53.507+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:03:54.149+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:03:54.128+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:03:54.157+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:03:54.307+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.887 seconds
[2025-09-12T15:04:33.630+0000] {processor.py:161} INFO - Started process (PID=610) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:04:33.636+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:04:33.643+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:04:33.641+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:04:34.225+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:04:34.199+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:04:34.230+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:04:34.412+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.848 seconds
[2025-09-12T15:05:13.849+0000] {processor.py:161} INFO - Started process (PID=623) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:05:13.855+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:05:13.862+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:05:13.859+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:05:14.615+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:05:14.583+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:05:14.622+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:05:14.952+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.166 seconds
[2025-09-12T15:05:51.730+0000] {processor.py:161} INFO - Started process (PID=635) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:05:51.736+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:05:51.746+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:05:51.739+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:05:52.342+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:05:52.314+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:05:52.346+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:05:52.525+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.868 seconds
[2025-09-12T15:06:25.581+0000] {processor.py:161} INFO - Started process (PID=647) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:06:25.589+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:06:25.597+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:06:25.594+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:06:26.355+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:06:26.322+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:06:26.360+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:06:26.587+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.091 seconds
[2025-09-12T15:07:03.348+0000] {processor.py:161} INFO - Started process (PID=659) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:07:03.387+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:07:03.393+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:07:03.391+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:07:04.008+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:07:03.989+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:07:04.012+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:07:04.136+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.923 seconds
[2025-09-12T15:07:40.328+0000] {processor.py:161} INFO - Started process (PID=672) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:07:40.334+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:07:40.339+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:07:40.337+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:07:40.955+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:07:40.927+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:07:40.959+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:07:41.147+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.886 seconds
[2025-09-12T15:08:20.057+0000] {processor.py:161} INFO - Started process (PID=685) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:08:20.064+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:08:20.070+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:08:20.067+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:08:20.861+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:08:20.821+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:08:20.871+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:08:21.119+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.128 seconds
[2025-09-12T15:08:57.690+0000] {processor.py:161} INFO - Started process (PID=698) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:08:57.697+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:08:57.703+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:08:57.700+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:08:58.357+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:08:58.326+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:08:58.361+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:08:58.561+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.941 seconds
[2025-09-12T15:09:32.813+0000] {processor.py:161} INFO - Started process (PID=710) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:09:32.819+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:09:32.826+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:09:32.823+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:09:33.635+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:09:33.607+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:09:33.640+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:09:33.838+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.120 seconds
[2025-09-12T15:10:06.745+0000] {processor.py:161} INFO - Started process (PID=722) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:10:06.751+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:10:06.756+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:10:06.754+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:10:07.402+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:10:07.371+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:10:07.407+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:10:07.697+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.033 seconds
[2025-09-12T15:10:39.523+0000] {processor.py:161} INFO - Started process (PID=734) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:10:39.529+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:10:39.535+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:10:39.532+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:10:40.216+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:10:40.185+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:10:40.220+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:10:40.422+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.962 seconds
[2025-09-12T15:11:23.244+0000] {processor.py:161} INFO - Started process (PID=748) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:11:23.250+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:11:23.258+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:11:23.255+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:11:23.910+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:11:23.880+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:11:23.914+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:11:24.142+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.963 seconds
[2025-09-12T15:12:04.987+0000] {processor.py:161} INFO - Started process (PID=761) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:12:04.990+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:12:04.994+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:12:04.992+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:12:05.446+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:12:05.431+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:12:05.448+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:12:05.544+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.589 seconds
[2025-09-12T15:12:40.019+0000] {processor.py:161} INFO - Started process (PID=773) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:12:40.025+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:12:40.032+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:12:40.029+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:12:40.741+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:12:40.710+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:12:40.749+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:12:41.123+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.169 seconds
[2025-09-12T15:13:20.580+0000] {processor.py:161} INFO - Started process (PID=786) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:13:20.585+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:13:20.589+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:13:20.587+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:13:21.141+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:13:21.117+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:13:21.144+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:13:21.305+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.775 seconds
[2025-09-12T15:13:58.632+0000] {processor.py:161} INFO - Started process (PID=799) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:13:58.639+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:13:58.645+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:13:58.643+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:13:59.418+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:13:59.383+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:13:59.423+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:13:59.637+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.073 seconds
[2025-09-12T15:14:33.239+0000] {processor.py:161} INFO - Started process (PID=811) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:14:33.245+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:14:33.251+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:14:33.248+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:14:33.888+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:14:33.855+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:14:33.893+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:14:34.082+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.907 seconds
[2025-09-12T15:15:07.796+0000] {processor.py:161} INFO - Started process (PID=823) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:15:07.803+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:15:07.811+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:15:07.808+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:15:08.478+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:15:08.448+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:15:08.483+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:15:08.774+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.040 seconds
[2025-09-12T15:15:45.227+0000] {processor.py:161} INFO - Started process (PID=836) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:15:45.232+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:15:45.246+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:15:45.243+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:15:45.834+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:15:45.817+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:15:45.837+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:15:45.962+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.780 seconds
[2025-09-12T15:16:23.267+0000] {processor.py:161} INFO - Started process (PID=849) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:16:23.273+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:16:23.279+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:16:23.276+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:16:23.921+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:16:23.891+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:16:23.926+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:16:24.142+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.940 seconds
[2025-09-12T15:16:56.254+0000] {processor.py:161} INFO - Started process (PID=861) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:16:56.261+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:16:56.267+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:16:56.264+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:16:56.957+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:16:56.928+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:16:56.962+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:16:57.170+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.976 seconds
[2025-09-12T15:17:36.819+0000] {processor.py:161} INFO - Started process (PID=874) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:17:36.823+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:17:36.830+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:17:36.828+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:17:37.324+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:17:37.301+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:17:37.328+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:17:37.488+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.732 seconds
[2025-09-12T15:18:11.282+0000] {processor.py:161} INFO - Started process (PID=886) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:18:11.288+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:18:11.294+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:18:11.292+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:18:12.040+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:18:12.009+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:18:12.045+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:18:12.237+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.017 seconds
[2025-09-12T15:18:46.080+0000] {processor.py:161} INFO - Started process (PID=898) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:18:46.085+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:18:46.089+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:18:46.087+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:18:46.568+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:18:46.544+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:18:46.572+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:18:46.911+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.872 seconds
[2025-09-12T15:19:26.399+0000] {processor.py:161} INFO - Started process (PID=911) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:19:26.406+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:19:26.414+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:19:26.410+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:19:27.092+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:19:27.061+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:19:27.096+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:19:27.297+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.985 seconds
[2025-09-12T15:19:59.820+0000] {processor.py:161} INFO - Started process (PID=923) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:19:59.825+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:19:59.831+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:19:59.828+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:20:00.551+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:20:00.518+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:20:00.555+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:20:00.760+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.008 seconds
[2025-09-12T15:20:36.933+0000] {processor.py:161} INFO - Started process (PID=936) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:20:36.942+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:20:36.952+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:20:36.947+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:20:37.736+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:20:37.702+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:20:37.743+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:20:38.030+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.179 seconds
[2025-09-12T15:21:13.718+0000] {processor.py:161} INFO - Started process (PID=948) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:21:13.724+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:21:13.730+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:21:13.727+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:21:14.442+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:21:14.411+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:21:14.447+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:21:14.654+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.999 seconds
[2025-09-12T15:21:47.794+0000] {processor.py:161} INFO - Started process (PID=960) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:21:47.800+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:21:47.807+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:21:47.804+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:21:48.423+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:21:48.395+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:21:48.426+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:21:48.678+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.946 seconds
[2025-09-12T15:22:24.403+0000] {processor.py:161} INFO - Started process (PID=972) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:22:24.410+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:22:24.416+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:22:24.413+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:22:25.089+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:22:25.060+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:22:25.093+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:22:25.291+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.956 seconds
[2025-09-12T15:23:00.037+0000] {processor.py:161} INFO - Started process (PID=984) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:23:00.042+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:23:00.049+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:23:00.045+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:23:00.546+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:23:00.524+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:23:00.550+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:23:00.702+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.743 seconds
[2025-09-12T15:23:35.517+0000] {processor.py:161} INFO - Started process (PID=996) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:23:35.525+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:23:35.532+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:23:35.529+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:23:36.487+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:23:36.456+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:23:36.494+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:23:36.702+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.266 seconds
[2025-09-12T15:24:12.726+0000] {processor.py:161} INFO - Started process (PID=1008) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:24:12.732+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:24:12.738+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:24:12.735+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:24:13.401+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:24:13.370+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:24:13.406+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:24:13.690+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.025 seconds
[2025-09-12T15:24:50.855+0000] {processor.py:161} INFO - Started process (PID=1020) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:24:50.858+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:24:50.864+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:24:50.862+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:24:51.267+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:24:51.252+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:24:51.270+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:24:51.377+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.572 seconds
[2025-09-12T15:25:23.757+0000] {processor.py:161} INFO - Started process (PID=1032) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:25:23.763+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:25:23.769+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:25:23.767+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:25:24.432+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:25:24.397+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:25:24.439+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:25:24.644+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.952 seconds
[2025-09-12T15:25:58.458+0000] {processor.py:161} INFO - Started process (PID=1044) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:25:58.460+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:25:58.463+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:25:58.462+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:25:58.725+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:25:58.712+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:25:58.727+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:25:58.816+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.383 seconds
[2025-09-12T15:26:34.475+0000] {processor.py:161} INFO - Started process (PID=1056) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:26:34.481+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:26:34.487+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:26:34.485+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:26:35.159+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:26:35.124+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:26:35.163+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:26:35.399+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.985 seconds
[2025-09-12T15:27:11.643+0000] {processor.py:161} INFO - Started process (PID=1068) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:27:11.649+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:27:11.655+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:27:11.653+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:27:12.309+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:27:12.274+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:27:12.317+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:27:12.516+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.934 seconds
[2025-09-12T15:27:49.110+0000] {processor.py:161} INFO - Started process (PID=1081) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:27:49.117+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:27:49.122+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:27:49.120+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:27:49.819+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:27:49.790+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:27:49.823+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:27:50.022+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.974 seconds
[2025-09-12T15:28:20.677+0000] {processor.py:161} INFO - Started process (PID=1093) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:28:20.681+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:28:20.687+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:28:20.684+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:28:21.077+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:28:21.058+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:28:21.080+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:28:21.216+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.575 seconds
[2025-09-12T15:28:58.930+0000] {processor.py:161} INFO - Started process (PID=1105) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:28:58.936+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:28:58.942+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:28:58.939+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:28:59.582+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:28:59.550+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:28:59.587+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:28:59.792+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.932 seconds
[2025-09-12T15:29:33.702+0000] {processor.py:161} INFO - Started process (PID=1117) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:29:33.709+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:29:33.715+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:29:33.713+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:29:34.362+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:29:34.332+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:29:34.368+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:29:34.561+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.922 seconds
[2025-09-12T15:30:04.975+0000] {processor.py:161} INFO - Started process (PID=1129) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:30:04.977+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:30:04.980+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:30:04.979+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:30:05.380+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:30:05.345+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:30:05.384+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:30:05.623+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.672 seconds
[2025-09-12T15:30:39.605+0000] {processor.py:161} INFO - Started process (PID=1141) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:30:39.612+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:30:39.617+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:30:39.615+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:30:40.065+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:30:40.045+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:30:40.069+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:30:40.216+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.700 seconds
[2025-09-12T15:31:20.304+0000] {processor.py:161} INFO - Started process (PID=1154) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:31:20.313+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:31:20.319+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:31:20.316+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:31:21.025+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:31:20.995+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:31:21.030+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:31:21.243+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.046 seconds
[2025-09-12T15:32:08.476+0000] {processor.py:161} INFO - Started process (PID=1169) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:32:08.480+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:32:08.486+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:32:08.484+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:32:08.979+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:32:08.953+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:32:08.983+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:32:09.133+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.701 seconds
[2025-09-12T15:32:44.417+0000] {processor.py:161} INFO - Started process (PID=1181) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:32:44.424+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:32:44.430+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:32:44.427+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:32:45.025+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:32:44.998+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:32:45.029+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:32:45.243+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.880 seconds
[2025-09-12T15:33:15.852+0000] {processor.py:161} INFO - Started process (PID=1193) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:33:15.856+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:33:15.859+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:33:15.858+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:33:16.249+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:33:16.229+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:33:16.251+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:33:16.413+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.597 seconds
[2025-09-12T15:33:50.740+0000] {processor.py:161} INFO - Started process (PID=1205) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:33:50.743+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:33:50.745+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:33:50.744+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:33:51.014+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:33:51.000+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:33:51.016+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:33:51.112+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.400 seconds
[2025-09-12T15:34:27.122+0000] {processor.py:161} INFO - Started process (PID=1217) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:34:27.127+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:34:27.135+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:34:27.132+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:34:27.726+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:34:27.696+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:34:27.730+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:34:27.927+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.864 seconds
[2025-09-12T15:35:05.831+0000] {processor.py:161} INFO - Started process (PID=1230) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:35:05.837+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:35:05.842+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:35:05.840+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:35:06.499+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:35:06.453+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:35:06.512+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:35:07.027+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.284 seconds
[2025-09-12T15:35:55.624+0000] {processor.py:161} INFO - Started process (PID=1245) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:35:55.633+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:35:55.640+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:35:55.637+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:35:56.878+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:35:56.842+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:35:56.883+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:35:57.312+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.953 seconds
[2025-09-12T15:36:43.603+0000] {processor.py:161} INFO - Started process (PID=1259) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:36:43.606+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:36:43.609+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:36:43.608+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:36:43.975+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:36:43.958+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:36:43.977+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:36:44.090+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.513 seconds
[2025-09-12T15:37:33.301+0000] {processor.py:161} INFO - Started process (PID=1272) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:37:33.316+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:37:33.329+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:37:33.319+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:37:33.982+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:37:33.964+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:37:33.985+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:37:34.139+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.984 seconds
[2025-09-12T15:38:25.532+0000] {processor.py:161} INFO - Started process (PID=1287) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:38:25.537+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:38:25.540+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:38:25.539+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:38:25.891+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:38:25.876+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:38:25.894+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:38:26.028+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.535 seconds
[2025-09-12T15:39:13.325+0000] {processor.py:161} INFO - Started process (PID=1302) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:39:13.340+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:39:13.348+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:39:13.345+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:39:14.344+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:39:14.296+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:39:14.356+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:39:14.587+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.427 seconds
[2025-09-12T15:39:57.623+0000] {processor.py:161} INFO - Started process (PID=1315) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:39:57.626+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:39:57.629+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:39:57.627+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:39:57.954+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:39:57.940+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:39:57.957+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:39:58.091+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.524 seconds
[2025-09-12T15:40:32.070+0000] {processor.py:161} INFO - Started process (PID=1327) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:40:32.073+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:40:32.077+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:40:32.076+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:40:32.591+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:40:32.567+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:40:32.593+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:40:32.743+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.732 seconds
[2025-09-12T15:41:14.966+0000] {processor.py:161} INFO - Started process (PID=1340) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:41:14.977+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:41:14.983+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:41:14.980+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:41:16.246+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:41:16.198+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:41:16.252+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:41:16.675+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.825 seconds
[2025-09-12T15:41:58.693+0000] {processor.py:161} INFO - Started process (PID=1353) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:41:58.700+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:41:58.710+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:41:58.703+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:41:59.580+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:41:59.544+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:41:59.585+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:41:59.941+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.332 seconds
[2025-09-12T15:42:44.050+0000] {processor.py:161} INFO - Started process (PID=1366) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:42:44.053+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:42:44.058+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:42:44.056+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:42:44.461+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:42:44.444+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:42:44.465+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:42:44.602+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.590 seconds
[2025-09-12T15:43:27.586+0000] {processor.py:161} INFO - Started process (PID=1380) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:43:27.608+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:43:27.624+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:43:27.617+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:43:28.872+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:43:28.839+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:43:28.879+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:43:29.407+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.013 seconds
[2025-09-12T15:44:13.133+0000] {processor.py:161} INFO - Started process (PID=1393) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:44:13.140+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:44:13.145+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:44:13.143+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:44:13.952+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:44:13.906+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:44:13.957+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:44:14.214+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.146 seconds
[2025-09-12T15:45:00.896+0000] {processor.py:161} INFO - Started process (PID=1406) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:45:00.901+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:45:00.908+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:45:00.905+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:45:02.720+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:45:02.455+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:45:02.739+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:45:04.451+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.620 seconds
[2025-09-12T15:47:49.900+0000] {processor.py:161} INFO - Started process (PID=1455) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:47:49.903+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:47:49.905+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:47:49.904+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:47:50.309+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:47:50.294+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:47:50.312+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:47:50.412+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.535 seconds
[2025-09-12T15:48:27.579+0000] {processor.py:161} INFO - Started process (PID=1467) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:48:27.582+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:48:27.585+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:48:27.584+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:48:27.921+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:48:27.908+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:48:27.924+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:48:28.001+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.453 seconds
[2025-09-12T15:49:07.368+0000] {processor.py:161} INFO - Started process (PID=1480) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:49:07.376+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:49:07.381+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:49:07.379+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:49:07.967+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:49:07.951+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:49:07.970+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:49:08.095+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.777 seconds
[2025-09-12T15:49:46.495+0000] {processor.py:161} INFO - Started process (PID=1492) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:49:46.503+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:49:46.506+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:49:46.505+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:49:46.835+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:49:46.820+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:49:46.837+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:49:46.940+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.475 seconds
[2025-09-12T15:50:23.794+0000] {processor.py:161} INFO - Started process (PID=1505) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:50:23.797+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:50:23.799+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:50:23.798+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:50:24.061+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:50:24.048+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:50:24.064+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:50:24.165+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.393 seconds
[2025-09-12T15:50:59.443+0000] {processor.py:161} INFO - Started process (PID=1517) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:50:59.456+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:50:59.465+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:50:59.462+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:51:00.444+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:51:00.400+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:51:00.449+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:51:00.809+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.464 seconds
[2025-09-12T15:51:38.948+0000] {processor.py:161} INFO - Started process (PID=1529) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:51:38.994+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:51:39.017+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:51:39.013+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:51:40.259+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:51:40.231+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:51:40.263+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:51:40.435+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.764 seconds
[2025-09-12T15:52:16.869+0000] {processor.py:161} INFO - Started process (PID=1541) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:52:16.876+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:52:16.882+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:52:16.880+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:52:17.774+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:52:17.741+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:52:17.779+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:52:17.995+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.195 seconds
[2025-09-12T15:53:11.613+0000] {processor.py:161} INFO - Started process (PID=1555) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:53:11.620+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:53:11.627+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:53:11.624+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:53:12.375+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:53:12.334+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:53:12.382+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:53:12.658+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.124 seconds
[2025-09-12T15:53:55.865+0000] {processor.py:161} INFO - Started process (PID=1569) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:53:55.869+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:53:55.874+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:53:55.871+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:53:56.382+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:53:56.358+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:53:56.386+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:53:56.578+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.750 seconds
[2025-09-12T15:54:32.994+0000] {processor.py:161} INFO - Started process (PID=1581) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:54:32.998+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:54:33.003+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:54:33.001+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:54:33.648+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:54:33.627+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:54:33.652+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:54:33.790+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.844 seconds
[2025-09-12T15:55:13.870+0000] {processor.py:161} INFO - Started process (PID=1594) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:55:13.877+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:55:13.880+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:55:13.879+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:55:14.330+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:55:14.311+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:55:14.332+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:55:14.453+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.653 seconds
[2025-09-12T15:55:51.823+0000] {processor.py:161} INFO - Started process (PID=1607) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:55:51.831+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:55:51.837+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:55:51.834+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:55:52.655+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:55:52.621+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:55:52.663+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:55:52.909+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.192 seconds
[2025-09-12T15:56:29.749+0000] {processor.py:161} INFO - Started process (PID=1619) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:56:29.757+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:56:29.763+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:56:29.760+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:56:30.494+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:56:30.460+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:56:30.501+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:56:30.782+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.102 seconds
[2025-09-12T15:57:06.281+0000] {processor.py:161} INFO - Started process (PID=1631) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:57:06.288+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:57:06.294+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:57:06.292+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:57:06.821+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:57:06.793+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:57:06.826+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:57:06.979+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.748 seconds
[2025-09-12T15:57:48.023+0000] {processor.py:161} INFO - Started process (PID=1643) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:57:48.026+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:57:48.031+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:57:48.028+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:57:48.427+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:57:48.407+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:57:48.431+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:57:48.662+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.693 seconds
[2025-09-12T15:58:23.187+0000] {processor.py:161} INFO - Started process (PID=1655) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:58:23.195+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:58:23.203+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:58:23.201+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:58:24.309+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:58:24.272+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:58:24.314+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:58:24.557+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.446 seconds
[2025-09-12T15:59:09.851+0000] {processor.py:161} INFO - Started process (PID=1669) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:59:09.854+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:59:09.857+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:59:09.856+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:59:10.207+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:59:10.171+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:59:10.210+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:59:10.309+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.487 seconds
[2025-09-12T15:59:46.818+0000] {processor.py:161} INFO - Started process (PID=1681) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:59:46.824+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T15:59:46.830+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:59:46.827+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:59:48.115+0000] {logging_mixin.py:188} INFO - [2025-09-12T15:59:48.024+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T15:59:48.123+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T15:59:48.425+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.682 seconds
[2025-09-12T16:00:31.600+0000] {processor.py:161} INFO - Started process (PID=1695) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:00:31.606+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T16:00:31.612+0000] {logging_mixin.py:188} INFO - [2025-09-12T16:00:31.609+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:00:32.267+0000] {logging_mixin.py:188} INFO - [2025-09-12T16:00:32.238+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T16:00:32.272+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:00:32.487+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.956 seconds
[2025-09-12T16:01:18.748+0000] {processor.py:161} INFO - Started process (PID=1708) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:01:18.758+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T16:01:18.763+0000] {logging_mixin.py:188} INFO - [2025-09-12T16:01:18.761+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:01:19.312+0000] {logging_mixin.py:188} INFO - [2025-09-12T16:01:19.291+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T16:01:19.317+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:01:19.467+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.816 seconds
[2025-09-12T16:01:56.813+0000] {processor.py:161} INFO - Started process (PID=1720) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:01:56.820+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T16:01:56.826+0000] {logging_mixin.py:188} INFO - [2025-09-12T16:01:56.824+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:01:57.592+0000] {logging_mixin.py:188} INFO - [2025-09-12T16:01:57.546+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T16:01:57.598+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:01:57.897+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.152 seconds
[2025-09-12T16:02:43.109+0000] {processor.py:161} INFO - Started process (PID=1734) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:02:43.114+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T16:02:43.120+0000] {logging_mixin.py:188} INFO - [2025-09-12T16:02:43.118+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:02:43.999+0000] {logging_mixin.py:188} INFO - [2025-09-12T16:02:43.956+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T16:02:44.013+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:02:44.284+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.237 seconds
[2025-09-12T16:03:32.640+0000] {processor.py:161} INFO - Started process (PID=1747) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:03:32.643+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T16:03:32.648+0000] {logging_mixin.py:188} INFO - [2025-09-12T16:03:32.646+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:03:33.073+0000] {logging_mixin.py:188} INFO - [2025-09-12T16:03:33.052+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T16:03:33.075+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:03:33.190+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.608 seconds
[2025-09-12T16:04:16.959+0000] {processor.py:161} INFO - Started process (PID=1759) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:04:16.965+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T16:04:16.970+0000] {logging_mixin.py:188} INFO - [2025-09-12T16:04:16.968+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:04:17.726+0000] {logging_mixin.py:188} INFO - [2025-09-12T16:04:17.685+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T16:04:17.731+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:04:17.988+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.102 seconds
[2025-09-12T16:05:03.104+0000] {processor.py:161} INFO - Started process (PID=1772) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:05:03.112+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T16:05:03.118+0000] {logging_mixin.py:188} INFO - [2025-09-12T16:05:03.115+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:05:04.981+0000] {logging_mixin.py:188} INFO - [2025-09-12T16:05:04.944+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T16:05:04.985+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:05:05.194+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.162 seconds
[2025-09-12T16:05:46.515+0000] {processor.py:161} INFO - Started process (PID=1785) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:05:46.519+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T16:05:46.522+0000] {logging_mixin.py:188} INFO - [2025-09-12T16:05:46.521+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:05:46.830+0000] {logging_mixin.py:188} INFO - [2025-09-12T16:05:46.816+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T16:05:46.834+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:05:46.937+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.465 seconds
[2025-09-12T16:06:18.965+0000] {processor.py:161} INFO - Started process (PID=1797) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:06:18.968+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T16:06:18.972+0000] {logging_mixin.py:188} INFO - [2025-09-12T16:06:18.971+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:06:19.306+0000] {logging_mixin.py:188} INFO - [2025-09-12T16:06:19.292+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T16:06:19.308+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:06:19.412+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.485 seconds
[2025-09-12T16:06:56.886+0000] {processor.py:161} INFO - Started process (PID=1810) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:06:56.888+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T16:06:56.891+0000] {logging_mixin.py:188} INFO - [2025-09-12T16:06:56.890+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:06:57.524+0000] {logging_mixin.py:188} INFO - [2025-09-12T16:06:57.512+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T16:06:57.526+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:06:57.618+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.765 seconds
[2025-09-12T16:07:29.676+0000] {processor.py:161} INFO - Started process (PID=1822) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:07:29.685+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T16:07:29.693+0000] {logging_mixin.py:188} INFO - [2025-09-12T16:07:29.689+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:07:30.402+0000] {logging_mixin.py:188} INFO - [2025-09-12T16:07:30.374+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T16:07:30.413+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:07:30.589+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.993 seconds
[2025-09-12T16:08:01.902+0000] {processor.py:161} INFO - Started process (PID=1834) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:08:01.909+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T16:08:01.920+0000] {logging_mixin.py:188} INFO - [2025-09-12T16:08:01.917+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:08:03.700+0000] {logging_mixin.py:188} INFO - [2025-09-12T16:08:03.671+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T16:08:03.704+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:08:03.950+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.147 seconds
[2025-09-12T16:08:34.811+0000] {processor.py:161} INFO - Started process (PID=1846) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:08:34.820+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T16:08:34.828+0000] {logging_mixin.py:188} INFO - [2025-09-12T16:08:34.825+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:08:36.809+0000] {logging_mixin.py:188} INFO - [2025-09-12T16:08:36.614+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T16:08:36.822+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:08:37.091+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.379 seconds
[2025-09-12T16:09:12.441+0000] {processor.py:161} INFO - Started process (PID=1858) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:09:12.444+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T16:09:12.446+0000] {logging_mixin.py:188} INFO - [2025-09-12T16:09:12.445+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:09:13.149+0000] {logging_mixin.py:188} INFO - [2025-09-12T16:09:13.135+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T16:09:13.152+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:09:13.254+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.854 seconds
[2025-09-12T16:09:50.479+0000] {processor.py:161} INFO - Started process (PID=1870) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:09:50.550+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T16:09:50.599+0000] {logging_mixin.py:188} INFO - [2025-09-12T16:09:50.598+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:09:57.441+0000] {logging_mixin.py:188} INFO - [2025-09-12T16:09:56.612+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T16:09:57.518+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:10:01.163+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 10.765 seconds
[2025-09-12T16:11:46.600+0000] {processor.py:161} INFO - Started process (PID=1884) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:11:46.612+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T16:11:46.615+0000] {logging_mixin.py:188} INFO - [2025-09-12T16:11:46.614+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:11:47.499+0000] {logging_mixin.py:188} INFO - [2025-09-12T16:11:47.472+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T16:11:47.501+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:11:47.728+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.180 seconds
[2025-09-12T16:12:23.992+0000] {processor.py:161} INFO - Started process (PID=1895) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:12:23.998+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T16:12:24.009+0000] {logging_mixin.py:188} INFO - [2025-09-12T16:12:24.002+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:12:25.183+0000] {logging_mixin.py:188} INFO - [2025-09-12T16:12:25.168+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T16:12:25.188+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:12:25.284+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.344 seconds
[2025-09-12T16:13:01.692+0000] {processor.py:161} INFO - Started process (PID=1907) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:13:01.695+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T16:13:01.698+0000] {logging_mixin.py:188} INFO - [2025-09-12T16:13:01.697+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:13:02.471+0000] {logging_mixin.py:188} INFO - [2025-09-12T16:13:02.454+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T16:13:02.475+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:13:02.568+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.908 seconds
[2025-09-12T16:18:11.286+0000] {processor.py:161} INFO - Started process (PID=1925) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:18:11.312+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T16:18:11.327+0000] {logging_mixin.py:188} INFO - [2025-09-12T16:18:11.326+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:18:17.395+0000] {logging_mixin.py:188} INFO - [2025-09-12T16:18:17.256+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T16:18:17.399+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:18:19.214+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 7.996 seconds
[2025-09-12T16:24:39.134+0000] {processor.py:161} INFO - Started process (PID=1946) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:24:39.147+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T16:24:39.150+0000] {logging_mixin.py:188} INFO - [2025-09-12T16:24:39.149+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:24:45.130+0000] {logging_mixin.py:188} INFO - [2025-09-12T16:24:44.739+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T16:24:45.168+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:24:46.817+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 7.750 seconds
[2025-09-12T16:47:12.766+0000] {processor.py:161} INFO - Started process (PID=1968) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:47:12.846+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T16:47:12.917+0000] {logging_mixin.py:188} INFO - [2025-09-12T16:47:12.916+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:47:27.284+0000] {logging_mixin.py:188} INFO - [2025-09-12T16:47:27.230+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T16:47:27.286+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:47:29.125+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 16.428 seconds
[2025-09-12T16:59:33.865+0000] {processor.py:161} INFO - Started process (PID=1980) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:59:33.929+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T16:59:34.000+0000] {logging_mixin.py:188} INFO - [2025-09-12T16:59:33.998+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:59:46.954+0000] {logging_mixin.py:188} INFO - [2025-09-12T16:59:46.237+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T16:59:46.984+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T16:59:50.487+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 16.780 seconds
[2025-09-12T17:09:02.664+0000] {processor.py:161} INFO - Started process (PID=1992) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:09:02.705+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T17:09:02.754+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:09:02.753+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:09:13.212+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:09:12.773+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-12T17:09:13.271+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:09:18.452+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 15.870 seconds
[2025-09-12T17:24:48.390+0000] {processor.py:161} INFO - Started process (PID=2335) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:24:48.462+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T17:24:48.501+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:24:48.500+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:24:49.344+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:24:49.332+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T17:24:53.444+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:24:54.531+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:24:54.529+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T17:24:54.686+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:24:54.685+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T17:24:54.983+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 6.630 seconds
[2025-09-12T17:25:37.294+0000] {processor.py:161} INFO - Started process (PID=2351) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:25:37.297+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T17:25:37.304+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:25:37.303+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:25:37.749+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:25:37.747+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T17:25:39.570+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:25:39.670+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:25:39.669+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T17:25:39.711+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:25:39.711+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T17:25:39.924+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.670 seconds
[2025-09-12T17:26:32.902+0000] {processor.py:161} INFO - Started process (PID=2370) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:26:32.912+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T17:26:32.920+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:26:32.919+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:26:33.365+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:26:33.363+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T17:26:35.543+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:26:36.736+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:26:36.735+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T17:26:36.944+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:26:36.944+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T17:26:37.257+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.388 seconds
[2025-09-12T17:27:24.026+0000] {processor.py:161} INFO - Started process (PID=2386) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:27:24.034+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T17:27:24.065+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:27:24.064+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:27:24.922+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:27:24.920+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T17:27:27.588+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:27:27.823+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:27:27.822+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T17:27:27.939+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:27:27.938+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T17:27:28.184+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.208 seconds
[2025-09-12T17:28:11.567+0000] {processor.py:161} INFO - Started process (PID=2402) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:28:11.570+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T17:28:11.597+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:28:11.595+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:28:12.288+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:28:12.287+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T17:28:13.957+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:28:14.036+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:28:14.033+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T17:28:14.083+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:28:14.082+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T17:28:14.242+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.724 seconds
[2025-09-12T17:29:18.188+0000] {processor.py:161} INFO - Started process (PID=2417) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:29:18.191+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T17:29:18.197+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:29:18.196+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:29:18.508+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:29:18.507+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T17:29:19.956+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:29:20.061+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:29:20.058+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T17:29:20.111+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:29:20.110+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T17:29:20.303+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.132 seconds
[2025-09-12T17:30:06.751+0000] {processor.py:161} INFO - Started process (PID=2432) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:30:06.754+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T17:30:06.762+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:30:06.760+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:30:07.165+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:30:07.164+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T17:30:08.744+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:30:08.874+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:30:08.873+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T17:30:08.928+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:30:08.928+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T17:30:09.199+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.469 seconds
[2025-09-12T17:31:16.708+0000] {processor.py:161} INFO - Started process (PID=2451) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:31:16.721+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T17:31:16.738+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:31:16.737+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:31:17.393+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:31:17.392+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T17:31:20.690+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:31:20.892+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:31:20.891+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T17:31:20.988+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:31:20.988+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T17:31:21.227+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.560 seconds
[2025-09-12T17:33:23.947+0000] {processor.py:161} INFO - Started process (PID=2471) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:33:23.952+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T17:33:23.963+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:33:23.962+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:33:24.734+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:33:24.732+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T17:33:28.829+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:33:29.305+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:33:29.303+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T17:33:29.396+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:33:29.396+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T17:33:29.711+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.815 seconds
[2025-09-12T17:34:26.286+0000] {processor.py:161} INFO - Started process (PID=2487) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:34:26.291+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T17:34:26.294+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:34:26.293+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:34:26.794+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:34:26.792+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T17:34:29.369+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:34:29.506+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:34:29.505+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T17:34:29.567+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:34:29.566+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T17:34:29.776+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.543 seconds
[2025-09-12T17:36:32.101+0000] {processor.py:161} INFO - Started process (PID=2510) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:36:32.116+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T17:36:32.119+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:36:32.118+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:36:32.809+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:36:32.761+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T17:36:37.325+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:36:37.574+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:36:37.572+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T17:36:37.649+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:36:37.648+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T17:36:37.907+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.843 seconds
[2025-09-12T17:37:24.233+0000] {processor.py:161} INFO - Started process (PID=2526) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:37:24.248+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T17:37:24.257+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:37:24.255+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:37:25.077+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:37:25.066+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T17:37:28.051+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:37:28.217+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:37:28.216+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T17:37:28.323+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:37:28.323+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T17:37:28.578+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.383 seconds
[2025-09-12T17:38:11.983+0000] {processor.py:161} INFO - Started process (PID=2541) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:38:11.986+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T17:38:11.989+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:38:11.987+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:38:12.397+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:38:12.395+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T17:38:14.926+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:38:15.063+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:38:15.062+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T17:38:15.105+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:38:15.104+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T17:38:15.381+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.420 seconds
[2025-09-12T17:38:58.896+0000] {processor.py:161} INFO - Started process (PID=2557) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:38:58.902+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T17:38:58.906+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:38:58.905+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:38:59.856+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:38:59.854+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T17:39:04.026+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:39:04.245+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:39:04.244+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T17:39:04.333+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:39:04.333+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T17:39:04.570+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.698 seconds
[2025-09-12T17:39:58.509+0000] {processor.py:161} INFO - Started process (PID=2576) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:39:58.522+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T17:39:58.549+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:39:58.548+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:39:59.137+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:39:59.136+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T17:40:01.294+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:40:01.365+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:40:01.364+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T17:40:01.398+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:40:01.398+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T17:40:01.570+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.092 seconds
[2025-09-12T17:40:43.587+0000] {processor.py:161} INFO - Started process (PID=2591) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:40:43.600+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T17:40:43.603+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:40:43.602+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:40:44.047+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:40:44.037+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T17:40:45.172+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:40:45.239+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:40:45.238+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T17:40:45.278+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:40:45.278+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T17:40:45.412+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.861 seconds
[2025-09-12T17:41:31.184+0000] {processor.py:161} INFO - Started process (PID=2607) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:41:31.187+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T17:41:31.199+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:41:31.198+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:41:31.826+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:41:31.825+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T17:41:32.997+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:41:33.446+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:41:33.071+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T17:41:33.469+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:41:33.469+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T17:41:33.595+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.458 seconds
[2025-09-12T17:42:18.693+0000] {processor.py:161} INFO - Started process (PID=2624) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:42:18.698+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T17:42:18.706+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:42:18.705+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:42:19.227+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:42:19.225+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T17:42:21.011+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:42:21.155+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:42:21.154+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T17:42:21.195+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:42:21.194+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T17:42:21.526+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.868 seconds
[2025-09-12T17:42:59.996+0000] {processor.py:161} INFO - Started process (PID=2639) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:43:00.010+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T17:43:00.027+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:43:00.025+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:43:00.444+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:43:00.443+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T17:43:01.711+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:43:01.804+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:43:01.803+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T17:43:02.335+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:43:02.335+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T17:43:02.484+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.515 seconds
[2025-09-12T17:48:14.053+0000] {processor.py:161} INFO - Started process (PID=2961) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:48:14.058+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T17:48:14.066+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:48:14.064+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:48:14.579+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:48:14.577+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T17:48:16.198+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:48:16.293+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:48:16.291+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T17:48:16.332+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:48:16.332+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T17:48:16.528+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.498 seconds
[2025-09-12T17:49:05.673+0000] {processor.py:161} INFO - Started process (PID=2977) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:49:05.677+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T17:49:05.688+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:49:05.686+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:49:06.103+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:49:06.101+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T17:49:07.779+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:49:07.837+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:49:07.836+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T17:49:07.870+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:49:07.869+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T17:49:07.993+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.345 seconds
[2025-09-12T17:50:00.649+0000] {processor.py:161} INFO - Started process (PID=2996) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:50:00.653+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T17:50:00.658+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:50:00.657+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:50:01.046+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:50:01.045+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T17:50:01.975+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:50:02.040+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:50:02.039+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T17:50:02.069+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:50:02.068+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T17:50:02.222+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.593 seconds
[2025-09-12T17:50:50.110+0000] {processor.py:161} INFO - Started process (PID=3011) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:50:50.115+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T17:50:50.123+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:50:50.122+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:50:51.053+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:50:51.052+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T17:50:52.190+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:50:52.282+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:50:52.281+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T17:50:52.325+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:50:52.325+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T17:50:52.590+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.510 seconds
[2025-09-12T17:51:34.599+0000] {processor.py:161} INFO - Started process (PID=3027) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:51:34.604+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T17:51:34.613+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:51:34.610+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:51:35.006+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:51:35.005+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T17:51:37.037+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:51:37.142+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:51:37.141+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T17:51:37.198+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:51:37.198+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T17:51:37.442+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.871 seconds
[2025-09-12T17:52:17.063+0000] {processor.py:161} INFO - Started process (PID=3043) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:52:17.067+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T17:52:17.073+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:52:17.072+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:52:17.502+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:52:17.501+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T17:52:18.528+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:52:18.614+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:52:18.613+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T17:52:18.646+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:52:18.645+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T17:52:18.794+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.757 seconds
[2025-09-12T17:53:05.987+0000] {processor.py:161} INFO - Started process (PID=3061) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:53:05.995+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T17:53:06.012+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:53:06.008+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:53:07.184+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:53:07.175+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T17:53:10.318+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:53:10.479+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:53:10.477+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T17:53:10.522+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:53:10.521+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T17:53:10.760+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.825 seconds
[2025-09-12T17:53:57.055+0000] {processor.py:161} INFO - Started process (PID=3081) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:53:57.065+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T17:53:57.095+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:53:57.089+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:53:58.736+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:53:58.734+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T17:54:00.872+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:54:01.007+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:54:01.006+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T17:54:01.068+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:54:01.067+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T17:54:01.287+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.317 seconds
[2025-09-12T17:54:56.399+0000] {processor.py:161} INFO - Started process (PID=3099) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:54:56.407+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T17:54:56.416+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:54:56.415+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:54:56.804+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:54:56.803+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T17:54:58.091+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:54:58.166+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:54:58.165+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T17:54:58.199+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:54:58.199+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T17:54:58.484+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.104 seconds
[2025-09-12T17:55:34.460+0000] {processor.py:161} INFO - Started process (PID=3114) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:55:34.462+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T17:55:34.468+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:55:34.467+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:55:34.734+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:55:34.733+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T17:55:35.729+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:55:35.789+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:55:35.789+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T17:55:35.815+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:55:35.815+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T17:55:35.954+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.509 seconds
[2025-09-12T17:56:17.143+0000] {processor.py:161} INFO - Started process (PID=3129) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:56:17.146+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T17:56:17.151+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:56:17.150+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:56:17.452+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:56:17.450+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T17:56:18.484+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:56:18.541+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:56:18.540+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T17:56:18.573+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:56:18.572+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T17:56:18.712+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.589 seconds
[2025-09-12T17:57:03.367+0000] {processor.py:161} INFO - Started process (PID=3144) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:57:03.385+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T17:57:03.408+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:57:03.405+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:57:04.382+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:57:04.375+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T17:57:07.224+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:57:07.375+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:57:07.374+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T17:57:07.425+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:57:07.425+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T17:57:07.699+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.411 seconds
[2025-09-12T17:57:50.490+0000] {processor.py:161} INFO - Started process (PID=3160) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:57:50.493+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T17:57:50.510+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:57:50.499+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:57:50.920+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:57:50.919+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T17:57:51.772+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:57:51.846+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:57:51.845+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T17:57:51.878+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:57:51.878+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T17:57:52.016+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.542 seconds
[2025-09-12T17:58:32.933+0000] {processor.py:161} INFO - Started process (PID=3175) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:58:32.943+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T17:58:32.976+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:58:32.966+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:58:34.289+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:58:34.284+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T17:58:36.940+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:58:37.976+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:58:37.291+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T17:58:38.012+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:58:38.011+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T17:58:38.152+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.346 seconds
[2025-09-12T17:59:33.598+0000] {processor.py:161} INFO - Started process (PID=3195) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:59:33.606+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T17:59:33.626+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:59:33.623+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:59:34.660+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:59:34.658+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T17:59:38.228+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T17:59:38.431+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:59:38.429+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T17:59:38.495+0000] {logging_mixin.py:188} INFO - [2025-09-12T17:59:38.494+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T17:59:38.811+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.268 seconds
[2025-09-12T18:00:23.209+0000] {processor.py:161} INFO - Started process (PID=3213) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:00:23.218+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T18:00:23.263+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:00:23.260+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:00:24.806+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:00:24.804+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T18:00:27.696+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:00:27.796+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:00:27.791+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T18:00:28.375+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:00:28.374+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T18:00:28.605+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.465 seconds
[2025-09-12T18:01:12.121+0000] {processor.py:161} INFO - Started process (PID=3229) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:01:12.133+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T18:01:12.152+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:01:12.150+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:01:13.354+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:01:13.351+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T18:01:16.691+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:01:16.792+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:01:16.791+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T18:01:16.842+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:01:16.841+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T18:01:17.195+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.124 seconds
[2025-09-12T18:01:59.249+0000] {processor.py:161} INFO - Started process (PID=3245) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:01:59.254+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T18:01:59.262+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:01:59.260+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:01:59.683+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:01:59.681+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T18:02:01.224+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:02:01.298+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:02:01.297+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T18:02:01.332+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:02:01.331+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T18:02:01.474+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.253 seconds
[2025-09-12T18:03:05.208+0000] {processor.py:161} INFO - Started process (PID=3265) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:03:05.217+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T18:03:05.240+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:03:05.237+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:03:06.263+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:03:06.260+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T18:03:09.595+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:03:09.717+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:03:09.716+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T18:03:09.753+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:03:09.752+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T18:03:09.974+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.817 seconds
[2025-09-12T18:04:06.835+0000] {processor.py:161} INFO - Started process (PID=3285) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:04:06.850+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T18:04:06.872+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:04:06.868+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:04:08.187+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:04:08.186+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T18:04:10.986+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:04:11.103+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:04:11.101+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T18:04:11.157+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:04:11.155+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T18:04:11.332+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.586 seconds
[2025-09-12T18:04:59.868+0000] {processor.py:161} INFO - Started process (PID=3302) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:04:59.884+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T18:04:59.911+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:04:59.907+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:05:01.752+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:05:01.747+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T18:05:04.140+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:05:04.707+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:05:04.706+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T18:05:04.746+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:05:04.745+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T18:05:04.910+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.132 seconds
[2025-09-12T18:05:40.985+0000] {processor.py:161} INFO - Started process (PID=3317) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:05:40.987+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T18:05:40.995+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:05:40.993+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:05:41.229+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:05:41.228+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T18:05:42.400+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:05:42.455+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:05:42.454+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T18:05:42.478+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:05:42.477+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T18:05:42.644+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.673 seconds
[2025-09-12T18:06:26.823+0000] {processor.py:161} INFO - Started process (PID=3332) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:06:26.833+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T18:06:26.863+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:06:26.849+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:06:28.103+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:06:28.099+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T18:06:30.675+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:06:30.768+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:06:30.767+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T18:06:30.802+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:06:30.801+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T18:06:30.978+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.293 seconds
[2025-09-12T18:07:19.724+0000] {processor.py:161} INFO - Started process (PID=3348) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:07:19.728+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T18:07:19.735+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:07:19.734+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:07:20.165+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:07:20.163+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T18:07:21.902+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:07:21.980+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:07:21.979+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T18:07:22.012+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:07:22.011+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T18:07:22.220+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.518 seconds
[2025-09-12T18:08:06.630+0000] {processor.py:161} INFO - Started process (PID=3363) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:08:06.638+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T18:08:06.658+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:08:06.655+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:08:07.863+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:08:07.849+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T18:08:11.005+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:08:11.117+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:08:11.115+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T18:08:11.159+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:08:11.159+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T18:08:11.391+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.816 seconds
[2025-09-12T18:09:05.994+0000] {processor.py:161} INFO - Started process (PID=3382) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:09:05.998+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T18:09:06.005+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:09:06.004+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:09:06.389+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:09:06.388+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T18:09:08.292+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:09:08.370+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:09:08.369+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T18:09:08.401+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:09:08.401+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T18:09:08.581+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.625 seconds
[2025-09-12T18:09:50.240+0000] {processor.py:161} INFO - Started process (PID=3397) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:09:50.260+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T18:09:50.296+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:09:50.293+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:09:52.505+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:09:52.503+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T18:09:55.197+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:09:55.283+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:09:55.281+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T18:09:55.328+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:09:55.327+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T18:09:55.528+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.342 seconds
[2025-09-12T18:10:48.108+0000] {processor.py:161} INFO - Started process (PID=3415) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:10:48.112+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T18:10:48.121+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:10:48.119+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:10:48.517+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:10:48.515+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T18:10:50.741+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:10:50.920+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:10:50.919+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T18:10:50.992+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:10:50.989+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T18:10:51.210+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.135 seconds
[2025-09-12T18:11:38.523+0000] {processor.py:161} INFO - Started process (PID=3432) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:11:38.525+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T18:11:38.530+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:11:38.529+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:11:38.825+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:11:38.824+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T18:11:40.067+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:11:40.127+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:11:40.126+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T18:11:40.154+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:11:40.153+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T18:11:40.297+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.788 seconds
[2025-09-12T18:12:22.425+0000] {processor.py:161} INFO - Started process (PID=3447) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:12:22.434+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T18:12:22.457+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:12:22.454+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:12:23.362+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:12:23.359+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T18:12:28.014+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:12:28.207+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:12:28.205+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T18:12:28.246+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:12:28.245+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T18:12:28.439+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 6.102 seconds
[2025-09-12T18:13:22.874+0000] {processor.py:161} INFO - Started process (PID=3467) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:13:22.896+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T18:13:22.950+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:13:22.937+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:13:24.614+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:13:24.613+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T18:13:27.097+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:13:27.193+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:13:27.192+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T18:13:27.240+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:13:27.239+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T18:13:27.441+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.699 seconds
[2025-09-12T18:14:11.616+0000] {processor.py:161} INFO - Started process (PID=3482) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:14:11.639+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T18:14:11.795+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:14:11.791+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:14:13.778+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:14:13.776+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T18:14:16.434+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:14:16.659+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:14:16.658+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T18:14:16.725+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:14:16.725+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T18:14:16.868+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.412 seconds
[2025-09-12T18:15:04.549+0000] {processor.py:161} INFO - Started process (PID=3499) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:15:04.557+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T18:15:04.574+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:15:04.570+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:15:05.604+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:15:05.599+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T18:15:09.462+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:15:09.565+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:15:09.564+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T18:15:09.604+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:15:09.603+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T18:15:09.791+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.319 seconds
[2025-09-12T18:15:53.488+0000] {processor.py:161} INFO - Started process (PID=3516) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:15:53.520+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T18:15:53.568+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:15:53.565+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:15:55.467+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:15:55.465+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T18:15:58.921+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:15:59.003+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:15:59.002+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T18:15:59.034+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:15:59.034+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T18:15:59.171+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.784 seconds
[2025-09-12T18:16:54.084+0000] {processor.py:161} INFO - Started process (PID=3534) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:16:54.094+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T18:16:54.112+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:16:54.107+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:16:56.588+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:16:56.586+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T18:16:58.675+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:16:58.790+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:16:58.789+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T18:16:58.830+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:16:58.829+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T18:16:59.021+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.990 seconds
[2025-09-12T18:18:06.931+0000] {processor.py:161} INFO - Started process (PID=3556) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:18:06.938+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T18:18:06.949+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:18:06.948+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:18:07.489+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:18:07.486+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T18:18:09.580+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:18:09.644+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:18:09.643+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T18:18:09.670+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:18:09.670+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T18:18:09.808+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.918 seconds
[2025-09-12T18:18:53.326+0000] {processor.py:161} INFO - Started process (PID=3573) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:18:53.339+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T18:18:53.361+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:18:53.358+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:18:55.379+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:18:55.375+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T18:18:57.879+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:18:57.985+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:18:57.983+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T18:18:58.028+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:18:58.027+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T18:18:58.771+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.531 seconds
[2025-09-12T18:19:43.999+0000] {processor.py:161} INFO - Started process (PID=3589) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:19:44.005+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T18:19:44.020+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:19:44.017+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:19:45.064+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:19:45.063+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T18:19:46.069+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:19:46.161+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:19:46.160+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T18:19:46.195+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:19:46.194+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T18:19:46.366+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.399 seconds
[2025-09-12T18:20:34.065+0000] {processor.py:161} INFO - Started process (PID=3607) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:20:34.073+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T18:20:34.090+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:20:34.087+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:20:35.309+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:20:35.307+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T18:20:38.638+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:20:38.723+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:20:38.721+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T18:20:38.760+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:20:38.759+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T18:20:38.997+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.980 seconds
[2025-09-12T18:21:37.816+0000] {processor.py:161} INFO - Started process (PID=3626) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:21:37.826+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T18:21:37.855+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:21:37.852+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:21:40.885+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:21:40.884+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T18:21:42.796+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:21:42.869+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:21:42.867+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T18:21:42.905+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:21:42.904+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T18:21:43.060+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.311 seconds
[2025-09-12T18:22:32.165+0000] {processor.py:161} INFO - Started process (PID=3644) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:22:32.170+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T18:22:32.197+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:22:32.187+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:22:33.253+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:22:33.252+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T18:22:34.367+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:22:34.434+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:22:34.433+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T18:22:34.464+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:22:34.464+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T18:22:34.643+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.548 seconds
[2025-09-12T18:23:35.323+0000] {processor.py:161} INFO - Started process (PID=3661) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:23:35.334+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T18:23:35.356+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:23:35.353+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:23:37.569+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:23:37.568+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T18:23:39.654+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:23:39.745+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:23:39.743+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T18:23:39.781+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:23:39.781+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T18:23:40.041+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.792 seconds
[2025-09-12T18:24:22.702+0000] {processor.py:161} INFO - Started process (PID=3676) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:24:22.714+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T18:24:22.733+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:24:22.729+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:24:25.237+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:24:25.235+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T18:24:27.024+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:24:27.173+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:24:27.172+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T18:24:27.201+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:24:27.200+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T18:24:27.347+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.730 seconds
[2025-09-12T18:25:24.512+0000] {processor.py:161} INFO - Started process (PID=3696) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:25:24.518+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T18:25:24.528+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:25:24.526+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:25:25.699+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:25:25.697+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T18:25:26.951+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:25:27.012+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:25:27.011+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T18:25:27.035+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:25:27.034+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T18:25:27.161+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.698 seconds
[2025-09-12T18:26:17.160+0000] {processor.py:161} INFO - Started process (PID=3712) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:26:17.169+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T18:26:17.187+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:26:17.184+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:26:19.646+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:26:19.645+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T18:26:21.614+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:26:21.729+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:26:21.727+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T18:26:21.775+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:26:21.774+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T18:26:22.030+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.949 seconds
[2025-09-12T18:27:09.446+0000] {processor.py:161} INFO - Started process (PID=3730) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:27:09.450+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T18:27:09.457+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:27:09.456+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:27:10.388+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:27:10.387+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T18:27:11.954+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:27:12.033+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:27:12.031+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T18:27:12.063+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:27:12.063+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T18:27:12.233+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.812 seconds
[2025-09-12T18:28:03.813+0000] {processor.py:161} INFO - Started process (PID=3748) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:28:03.816+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T18:28:03.821+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:28:03.820+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:28:04.062+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:28:04.061+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T18:28:04.900+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:28:04.968+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:28:04.967+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T18:28:05.010+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:28:05.009+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T18:28:05.229+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.430 seconds
[2025-09-12T18:28:47.131+0000] {processor.py:161} INFO - Started process (PID=3763) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:28:47.141+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T18:28:47.168+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:28:47.163+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:28:49.182+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:28:49.169+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T18:28:52.472+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:28:52.586+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:28:52.584+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T18:28:52.642+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:28:52.641+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T18:28:52.832+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.802 seconds
[2025-09-12T18:29:38.041+0000] {processor.py:161} INFO - Started process (PID=3782) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:29:38.048+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T18:29:38.068+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:29:38.064+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:29:39.534+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:29:39.518+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T18:29:41.627+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:29:41.756+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:29:41.755+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T18:29:41.806+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:29:41.805+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T18:29:42.030+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.062 seconds
[2025-09-12T18:30:15.480+0000] {processor.py:161} INFO - Started process (PID=3797) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:30:15.493+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T18:30:15.511+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:30:15.508+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:30:16.560+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:30:16.557+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T18:30:19.345+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:30:19.448+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:30:19.447+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T18:30:19.497+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:30:19.496+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T18:30:19.704+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.319 seconds
[2025-09-12T18:31:04.443+0000] {processor.py:161} INFO - Started process (PID=3814) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:31:04.445+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T18:31:04.450+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:31:04.449+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:31:04.698+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:31:04.698+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T18:31:05.714+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:31:05.773+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:31:05.771+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T18:31:05.802+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:31:05.800+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T18:31:05.931+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.504 seconds
[2025-09-12T18:31:55.790+0000] {processor.py:161} INFO - Started process (PID=3831) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:31:55.796+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T18:31:55.814+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:31:55.811+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:31:56.802+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:31:56.799+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T18:32:00.191+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:32:00.395+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:32:00.393+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T18:32:00.523+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:32:00.522+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T18:32:00.808+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.074 seconds
[2025-09-12T18:32:51.235+0000] {processor.py:161} INFO - Started process (PID=3849) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:32:51.308+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T18:32:51.359+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:32:51.355+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:32:53.952+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:32:53.944+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T18:32:56.130+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:32:56.196+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:32:56.195+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T18:32:56.227+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:32:56.226+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T18:32:56.392+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.303 seconds
[2025-09-12T18:33:50.142+0000] {processor.py:161} INFO - Started process (PID=3869) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:33:50.147+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T18:33:50.157+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:33:50.155+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:33:50.683+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:33:50.681+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T18:33:52.441+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:33:52.515+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:33:52.514+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T18:33:52.549+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:33:52.548+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T18:33:52.709+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.594 seconds
[2025-09-12T18:34:28.038+0000] {processor.py:161} INFO - Started process (PID=3885) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:34:28.051+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T18:34:28.075+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:34:28.071+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:34:29.028+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:34:29.025+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T18:34:32.471+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:34:32.597+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:34:32.596+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T18:34:32.650+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:34:32.649+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T18:34:32.906+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.931 seconds
[2025-09-12T18:35:14.390+0000] {processor.py:161} INFO - Started process (PID=3901) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:35:14.406+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T18:35:14.431+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:35:14.428+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:35:15.559+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:35:15.554+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T18:35:17.988+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:35:18.116+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:35:18.115+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T18:35:18.166+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:35:18.166+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T18:35:18.370+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.088 seconds
[2025-09-12T18:35:55.506+0000] {processor.py:161} INFO - Started process (PID=3916) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:35:55.509+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T18:35:55.515+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:35:55.514+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:35:55.851+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:35:55.850+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T18:35:57.265+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:35:57.347+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:35:57.346+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T18:35:57.380+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:35:57.379+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T18:35:57.534+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.048 seconds
[2025-09-12T18:36:40.977+0000] {processor.py:161} INFO - Started process (PID=3930) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:36:40.988+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T18:36:41.008+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:36:41.005+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:36:42.459+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:36:42.457+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T18:36:44.889+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:36:45.004+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:36:45.002+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T18:36:45.054+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:36:45.053+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T18:36:45.370+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.443 seconds
[2025-09-12T18:37:22.124+0000] {processor.py:161} INFO - Started process (PID=3945) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:37:22.133+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T18:37:22.149+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:37:22.146+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:37:23.323+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:37:23.313+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T18:37:26.253+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:37:26.443+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:37:26.442+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T18:37:26.521+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:37:26.520+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T18:37:26.753+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.685 seconds
[2025-09-12T18:38:18.519+0000] {processor.py:161} INFO - Started process (PID=3963) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:38:18.532+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T18:38:18.551+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:38:18.550+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:38:18.994+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:38:18.992+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T18:38:20.395+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:38:20.476+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:38:20.475+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T18:38:20.512+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:38:20.512+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T18:38:20.710+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.263 seconds
[2025-09-12T18:39:03.797+0000] {processor.py:161} INFO - Started process (PID=3978) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:39:03.802+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T18:39:03.814+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:39:03.812+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:39:04.239+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:39:04.237+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T18:39:05.830+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:39:05.898+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:39:05.896+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T18:39:05.928+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:39:05.928+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T18:39:06.079+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.312 seconds
[2025-09-12T18:40:00.876+0000] {processor.py:161} INFO - Started process (PID=3998) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:40:00.888+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T18:40:00.919+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:40:00.909+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:40:02.604+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:40:02.603+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T18:40:04.879+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:40:05.019+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:40:05.018+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T18:40:05.079+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:40:05.078+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T18:40:05.476+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.689 seconds
[2025-09-12T18:40:45.575+0000] {processor.py:161} INFO - Started process (PID=4013) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:40:45.588+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T18:40:45.610+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:40:45.607+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:40:46.622+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:40:46.619+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T18:40:49.052+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:40:49.191+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:40:49.189+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T18:40:49.255+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:40:49.253+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T18:40:49.719+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.239 seconds
[2025-09-12T18:41:28.297+0000] {processor.py:161} INFO - Started process (PID=4029) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:41:28.309+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T18:41:28.336+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:41:28.332+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:41:29.324+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:41:29.316+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T18:41:32.098+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:41:32.180+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:41:32.179+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T18:41:32.218+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:41:32.217+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T18:41:32.471+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.250 seconds
[2025-09-12T18:42:19.717+0000] {processor.py:161} INFO - Started process (PID=4046) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:42:19.724+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T18:42:19.733+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:42:19.732+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:42:20.166+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:42:20.165+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T18:42:21.056+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:42:21.115+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:42:21.112+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T18:42:21.139+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:42:21.138+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T18:42:21.247+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.558 seconds
[2025-09-12T18:43:01.665+0000] {processor.py:161} INFO - Started process (PID=4063) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:43:01.667+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-12T18:43:01.673+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:43:01.671+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:43:01.914+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:43:01.913+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-12T18:43:02.721+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-12T18:43:02.780+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:43:02.779+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-12T18:43:02.805+0000] {logging_mixin.py:188} INFO - [2025-09-12T18:43:02.805+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-12T18:43:02.939+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.290 seconds
