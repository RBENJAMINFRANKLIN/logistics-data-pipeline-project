[2025-09-11T04:46:59.190+0000] {processor.py:161} INFO - Started process (PID=63) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T04:46:59.200+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T04:46:59.222+0000] {logging_mixin.py:188} INFO - [2025-09-11T04:46:59.217+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T04:47:00.254+0000] {logging_mixin.py:188} INFO - [2025-09-11T04:47:00.251+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T04:47:03.857+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T04:47:03.901+0000] {logging_mixin.py:188} INFO - [2025-09-11T04:47:03.899+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T04:47:03.940+0000] {logging_mixin.py:188} INFO - [2025-09-11T04:47:03.939+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T04:47:04.501+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.374 seconds
[2025-09-11T04:47:54.182+0000] {processor.py:161} INFO - Started process (PID=84) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T04:47:54.186+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T04:47:54.191+0000] {logging_mixin.py:188} INFO - [2025-09-11T04:47:54.189+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T04:47:54.591+0000] {logging_mixin.py:188} INFO - [2025-09-11T04:47:54.590+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T04:47:55.683+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T04:47:57.605+0000] {logging_mixin.py:188} INFO - [2025-09-11T04:47:57.604+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T04:47:57.634+0000] {logging_mixin.py:188} INFO - [2025-09-11T04:47:57.634+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T04:47:57.788+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.619 seconds
[2025-09-11T04:49:11.489+0000] {processor.py:161} INFO - Started process (PID=115) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T04:49:11.495+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T04:49:11.509+0000] {logging_mixin.py:188} INFO - [2025-09-11T04:49:11.508+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T04:49:12.045+0000] {logging_mixin.py:188} INFO - [2025-09-11T04:49:12.044+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T04:49:14.770+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T04:49:14.845+0000] {logging_mixin.py:188} INFO - [2025-09-11T04:49:14.845+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T04:49:14.881+0000] {logging_mixin.py:188} INFO - [2025-09-11T04:49:14.880+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T04:49:15.077+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.620 seconds
[2025-09-11T04:50:09.283+0000] {processor.py:161} INFO - Started process (PID=130) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T04:50:09.302+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T04:50:09.319+0000] {logging_mixin.py:188} INFO - [2025-09-11T04:50:09.314+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T04:50:09.853+0000] {logging_mixin.py:188} INFO - [2025-09-11T04:50:09.851+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T04:50:13.188+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T04:50:13.280+0000] {logging_mixin.py:188} INFO - [2025-09-11T04:50:13.279+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T04:50:13.340+0000] {logging_mixin.py:188} INFO - [2025-09-11T04:50:13.340+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T04:50:13.477+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.223 seconds
[2025-09-11T04:51:19.156+0000] {processor.py:161} INFO - Started process (PID=145) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T04:51:19.167+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T04:51:19.179+0000] {logging_mixin.py:188} INFO - [2025-09-11T04:51:19.177+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T04:51:19.762+0000] {logging_mixin.py:188} INFO - [2025-09-11T04:51:19.761+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T04:51:24.229+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T04:51:24.365+0000] {logging_mixin.py:188} INFO - [2025-09-11T04:51:24.363+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T04:51:24.422+0000] {logging_mixin.py:188} INFO - [2025-09-11T04:51:24.421+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T04:51:24.784+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.663 seconds
[2025-09-11T04:52:16.685+0000] {processor.py:161} INFO - Started process (PID=160) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T04:52:16.691+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T04:52:16.703+0000] {logging_mixin.py:188} INFO - [2025-09-11T04:52:16.701+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T04:52:17.324+0000] {logging_mixin.py:188} INFO - [2025-09-11T04:52:17.323+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T04:52:20.474+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T04:52:20.903+0000] {logging_mixin.py:188} INFO - [2025-09-11T04:52:20.899+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T04:52:21.069+0000] {logging_mixin.py:188} INFO - [2025-09-11T04:52:21.068+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T04:52:22.029+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.377 seconds
[2025-09-11T04:53:34.766+0000] {processor.py:161} INFO - Started process (PID=179) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T04:53:34.779+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T04:53:34.792+0000] {logging_mixin.py:188} INFO - [2025-09-11T04:53:34.783+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T04:53:35.081+0000] {logging_mixin.py:188} INFO - [2025-09-11T04:53:35.080+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T04:53:39.279+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T04:53:39.623+0000] {logging_mixin.py:188} INFO - [2025-09-11T04:53:39.621+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T04:53:39.695+0000] {logging_mixin.py:188} INFO - [2025-09-11T04:53:39.694+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T04:53:42.358+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 7.638 seconds
[2025-09-11T04:55:13.740+0000] {processor.py:161} INFO - Started process (PID=201) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T04:55:13.757+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T04:55:13.780+0000] {logging_mixin.py:188} INFO - [2025-09-11T04:55:13.774+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T04:55:15.117+0000] {logging_mixin.py:188} INFO - [2025-09-11T04:55:15.113+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T04:55:19.096+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T04:55:19.254+0000] {logging_mixin.py:188} INFO - [2025-09-11T04:55:19.252+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T04:55:19.324+0000] {logging_mixin.py:188} INFO - [2025-09-11T04:55:19.323+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T04:55:19.776+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 6.093 seconds
[2025-09-11T04:56:27.244+0000] {processor.py:161} INFO - Started process (PID=216) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T04:56:27.261+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T04:56:27.302+0000] {logging_mixin.py:188} INFO - [2025-09-11T04:56:27.288+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T04:56:28.433+0000] {logging_mixin.py:188} INFO - [2025-09-11T04:56:28.421+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T04:56:32.404+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T04:56:32.550+0000] {logging_mixin.py:188} INFO - [2025-09-11T04:56:32.548+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T04:56:32.609+0000] {logging_mixin.py:188} INFO - [2025-09-11T04:56:32.608+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T04:56:32.946+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.822 seconds
[2025-09-11T04:57:40.236+0000] {processor.py:161} INFO - Started process (PID=231) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T04:57:40.272+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T04:57:40.341+0000] {logging_mixin.py:188} INFO - [2025-09-11T04:57:40.327+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T04:57:41.328+0000] {logging_mixin.py:188} INFO - [2025-09-11T04:57:41.327+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T04:57:44.699+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T04:57:44.915+0000] {logging_mixin.py:188} INFO - [2025-09-11T04:57:44.912+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T04:57:44.994+0000] {logging_mixin.py:188} INFO - [2025-09-11T04:57:44.993+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T04:57:45.319+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.296 seconds
[2025-09-11T05:01:16.595+0000] {processor.py:161} INFO - Started process (PID=91) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:01:16.598+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:01:16.615+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:01:16.614+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:01:17.128+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:01:17.111+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
ModuleNotFoundError: No module named 'snowflake.snowpark'
[2025-09-11T05:01:17.133+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:01:17.307+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.762 seconds
[2025-09-11T05:02:06.123+0000] {processor.py:161} INFO - Started process (PID=108) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:02:06.140+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:02:06.159+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:02:06.149+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:02:08.059+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:02:07.972+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
ModuleNotFoundError: No module named 'snowflake.snowpark'
[2025-09-11T05:02:08.081+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:02:08.876+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.825 seconds
[2025-09-11T05:02:48.735+0000] {processor.py:161} INFO - Started process (PID=143) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:02:48.740+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:02:48.745+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:02:48.743+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:02:49.241+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:02:49.223+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
ModuleNotFoundError: No module named 'snowflake.snowpark'
[2025-09-11T05:02:49.247+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:02:49.388+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.679 seconds
[2025-09-11T05:03:35.007+0000] {processor.py:161} INFO - Started process (PID=155) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:03:35.010+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:03:35.013+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:03:35.012+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:03:35.336+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:03:35.323+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
ModuleNotFoundError: No module named 'snowflake.snowpark'
[2025-09-11T05:03:35.341+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:03:35.499+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.522 seconds
[2025-09-11T05:04:16.964+0000] {processor.py:161} INFO - Started process (PID=167) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:04:16.973+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:04:16.988+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:04:16.980+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:04:19.089+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:04:18.999+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T05:04:19.113+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:04:19.518+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.805 seconds
[2025-09-11T05:05:03.109+0000] {processor.py:161} INFO - Started process (PID=181) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:05:03.113+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:05:03.116+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:05:03.115+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:05:03.445+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:05:03.432+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T05:05:03.448+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:05:03.530+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.457 seconds
[2025-09-11T05:06:18.398+0000] {processor.py:161} INFO - Started process (PID=213) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:06:18.421+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:06:18.440+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:06:18.439+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:06:19.270+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:06:19.269+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T05:06:20.426+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:06:20.720+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:06:20.719+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T05:06:20.751+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:06:20.750+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T05:06:20.923+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.579 seconds
[2025-09-11T05:07:21.441+0000] {processor.py:161} INFO - Started process (PID=237) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:07:21.456+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:07:21.472+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:07:21.470+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:07:22.187+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:07:22.185+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T05:07:24.307+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:07:24.418+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:07:24.415+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T05:07:24.482+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:07:24.481+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T05:07:24.704+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.342 seconds
[2025-09-11T05:08:29.540+0000] {processor.py:161} INFO - Started process (PID=263) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:08:29.552+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:08:29.565+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:08:29.563+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:08:30.294+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:08:30.292+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T05:08:32.525+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:08:32.847+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:08:32.844+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T05:08:33.009+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:08:33.008+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T05:08:33.635+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.132 seconds
[2025-09-11T05:09:32.746+0000] {processor.py:161} INFO - Started process (PID=278) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:09:32.762+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:09:32.777+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:09:32.774+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:09:33.357+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:09:33.356+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T05:09:35.791+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:09:35.981+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:09:35.980+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T05:09:36.053+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:09:36.052+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T05:09:36.351+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.721 seconds
[2025-09-11T05:10:32.661+0000] {processor.py:161} INFO - Started process (PID=293) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:10:32.666+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:10:32.679+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:10:32.672+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:10:33.154+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:10:33.153+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T05:10:37.064+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:10:37.205+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:10:37.204+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T05:10:37.262+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:10:37.261+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T05:10:38.878+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 6.270 seconds
[2025-09-11T05:12:17.532+0000] {processor.py:161} INFO - Started process (PID=311) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:12:17.703+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:12:17.771+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:12:17.769+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:12:19.180+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:12:19.179+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T05:12:21.717+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:12:21.948+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:12:21.947+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T05:12:22.000+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:12:22.000+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T05:12:22.195+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.689 seconds
[2025-09-11T05:13:28.029+0000] {processor.py:161} INFO - Started process (PID=330) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:13:28.032+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:13:28.047+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:13:28.045+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:13:28.448+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:13:28.447+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T05:13:30.939+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:13:31.034+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:13:31.033+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T05:13:31.073+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:13:31.072+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T05:13:31.205+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.200 seconds
[2025-09-11T05:14:21.915+0000] {processor.py:161} INFO - Started process (PID=345) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:14:21.922+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:14:21.934+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:14:21.932+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:14:22.611+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:14:22.609+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T05:14:25.322+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:14:25.558+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:14:25.556+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T05:14:25.648+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:14:25.646+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T05:14:26.779+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.905 seconds
[2025-09-11T05:15:03.478+0000] {processor.py:161} INFO - Started process (PID=360) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:15:03.494+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:15:03.518+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:15:03.513+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:15:04.387+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:15:04.385+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T05:15:06.938+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:15:07.124+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:15:07.118+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T05:15:07.220+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:15:07.219+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T05:15:07.567+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.178 seconds
[2025-09-11T05:17:00.871+0000] {processor.py:161} INFO - Started process (PID=380) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:17:00.880+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:17:00.895+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:17:00.892+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:17:01.707+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:17:01.704+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T05:17:04.753+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:17:04.875+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:17:04.874+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T05:17:04.927+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:17:04.926+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T05:17:06.477+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.703 seconds
[2025-09-11T05:17:50.204+0000] {processor.py:161} INFO - Started process (PID=395) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:17:50.209+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:17:50.221+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:17:50.219+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:17:50.860+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:17:50.858+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T05:17:52.875+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:17:53.041+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:17:53.039+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T05:17:53.112+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:17:53.111+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T05:17:53.594+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.422 seconds
[2025-09-11T05:18:51.358+0000] {processor.py:161} INFO - Started process (PID=414) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:18:51.366+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:18:51.387+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:18:51.383+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:18:52.086+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:18:52.085+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T05:18:54.409+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:18:54.580+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:18:54.578+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T05:18:54.746+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:18:54.745+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T05:18:55.783+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.479 seconds
[2025-09-11T05:19:35.537+0000] {processor.py:161} INFO - Started process (PID=429) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:19:35.543+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:19:35.557+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:19:35.555+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:19:36.137+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:19:36.130+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T05:19:38.774+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:19:38.905+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:19:38.904+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T05:19:38.977+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:19:38.977+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T05:19:39.297+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.821 seconds
[2025-09-11T05:20:31.551+0000] {processor.py:161} INFO - Started process (PID=447) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:20:31.557+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:20:31.569+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:20:31.567+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:20:32.167+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:20:32.165+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T05:20:34.460+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:20:34.786+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:20:34.780+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T05:20:34.917+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:20:34.916+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T05:20:35.381+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.864 seconds
[2025-09-11T05:21:44.253+0000] {processor.py:161} INFO - Started process (PID=466) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:21:44.270+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:21:44.327+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:21:44.313+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:21:46.506+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:21:46.505+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T05:21:50.053+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:21:50.263+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:21:50.262+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T05:21:50.511+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:21:50.509+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T05:21:51.193+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 7.024 seconds
[2025-09-11T05:22:40.745+0000] {processor.py:161} INFO - Started process (PID=481) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:22:40.760+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:22:40.784+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:22:40.783+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:22:41.330+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:22:41.329+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T05:22:42.500+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:22:42.563+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:22:42.563+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T05:22:42.593+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:22:42.593+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T05:22:42.705+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.999 seconds
[2025-09-11T05:23:26.754+0000] {processor.py:161} INFO - Started process (PID=496) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:23:26.761+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:23:26.778+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:23:26.774+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:23:27.354+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:23:27.352+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T05:23:29.834+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:23:29.957+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:23:29.955+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T05:23:30.012+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:23:30.011+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T05:23:30.280+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.573 seconds
[2025-09-11T05:24:41.202+0000] {processor.py:161} INFO - Started process (PID=517) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:24:41.278+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:24:41.324+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:24:41.323+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:24:41.970+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:24:41.969+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T05:24:43.384+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:24:43.438+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:24:43.438+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T05:24:43.460+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:24:43.460+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T05:24:43.613+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.432 seconds
[2025-09-11T05:25:37.305+0000] {processor.py:161} INFO - Started process (PID=535) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:25:37.310+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:25:37.316+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:25:37.315+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:25:37.810+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:25:37.808+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T05:25:39.322+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:25:39.433+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:25:39.433+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T05:25:39.485+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:25:39.484+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T05:25:39.688+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.403 seconds
[2025-09-11T05:26:26.793+0000] {processor.py:161} INFO - Started process (PID=550) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:26:26.800+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:26:26.812+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:26:26.810+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:26:27.962+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:26:27.960+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T05:26:30.721+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:26:30.844+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:26:30.842+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T05:26:30.904+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:26:30.903+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T05:26:31.134+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.377 seconds
[2025-09-11T05:27:21.427+0000] {processor.py:161} INFO - Started process (PID=566) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:27:21.446+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:27:21.483+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:27:21.480+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:27:22.317+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:27:22.315+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T05:27:25.957+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:27:26.173+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:27:26.171+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T05:27:26.342+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:27:26.342+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T05:27:26.792+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.411 seconds
[2025-09-11T05:28:31.907+0000] {processor.py:161} INFO - Started process (PID=587) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:28:31.916+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:28:31.946+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:28:31.936+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:28:34.430+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:28:34.418+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T05:28:36.113+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:28:36.192+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:28:36.190+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T05:28:36.235+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:28:36.234+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T05:28:36.376+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.567 seconds
[2025-09-11T05:29:44.896+0000] {processor.py:161} INFO - Started process (PID=607) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:29:44.901+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:29:44.912+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:29:44.910+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:29:45.474+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:29:45.473+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T05:29:47.410+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:29:47.542+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:29:47.540+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T05:29:47.607+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:29:47.606+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T05:29:47.995+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.132 seconds
[2025-09-11T05:30:37.446+0000] {processor.py:161} INFO - Started process (PID=626) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:30:37.451+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:30:37.462+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:30:37.460+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:30:38.023+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:30:38.021+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T05:30:40.365+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:30:40.492+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:30:40.490+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T05:30:40.564+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:30:40.562+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T05:30:40.832+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.416 seconds
[2025-09-11T05:31:24.461+0000] {processor.py:161} INFO - Started process (PID=641) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:31:24.468+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:31:24.491+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:31:24.488+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:31:25.341+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:31:25.339+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T05:31:28.024+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:31:28.147+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:31:28.146+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T05:31:28.200+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:31:28.199+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T05:31:28.491+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.116 seconds
[2025-09-11T05:32:18.607+0000] {processor.py:161} INFO - Started process (PID=659) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:32:18.620+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:32:18.639+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:32:18.637+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:32:19.316+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:32:19.314+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T05:32:21.209+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:32:21.362+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:32:21.360+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T05:32:21.437+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:32:21.436+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T05:32:21.780+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.212 seconds
[2025-09-11T05:33:07.783+0000] {processor.py:161} INFO - Started process (PID=676) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:33:07.787+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:33:07.798+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:33:07.796+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:33:08.376+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:33:08.373+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T05:33:10.849+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:33:11.027+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:33:11.026+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T05:33:11.082+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:33:11.081+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T05:33:11.393+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.640 seconds
[2025-09-11T05:34:00.393+0000] {processor.py:161} INFO - Started process (PID=695) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:34:00.400+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:34:00.427+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:34:00.424+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:34:01.034+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:34:01.032+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T05:34:03.059+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:34:03.218+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:34:03.216+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T05:34:03.282+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:34:03.282+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T05:34:03.601+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.242 seconds
[2025-09-11T05:34:52.348+0000] {processor.py:161} INFO - Started process (PID=712) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:34:52.353+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:34:52.363+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:34:52.361+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:34:52.918+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:34:52.917+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T05:34:54.880+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:34:55.061+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:34:55.059+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T05:34:55.168+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:34:55.167+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T05:34:55.533+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.216 seconds
[2025-09-11T05:35:39.955+0000] {processor.py:161} INFO - Started process (PID=730) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:35:39.961+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:35:39.972+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:35:39.970+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:35:40.542+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:35:40.541+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T05:35:42.434+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:35:42.565+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:35:42.564+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T05:35:42.620+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:35:42.619+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T05:35:42.896+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.977 seconds
[2025-09-11T05:36:47.675+0000] {processor.py:161} INFO - Started process (PID=750) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:36:47.688+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:36:47.710+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:36:47.707+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:36:49.010+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:36:49.007+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T05:36:52.124+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:36:52.318+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:36:52.316+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T05:36:52.469+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:36:52.468+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T05:36:52.697+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.104 seconds
[2025-09-11T05:37:46.092+0000] {processor.py:161} INFO - Started process (PID=764) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:37:46.100+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:37:46.124+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:37:46.122+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:37:46.699+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:37:46.697+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T05:37:49.767+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:37:49.929+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:37:49.928+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T05:37:50.001+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:37:50.000+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T05:37:50.335+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.284 seconds
[2025-09-11T05:38:44.056+0000] {processor.py:161} INFO - Started process (PID=779) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:38:44.062+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:38:44.074+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:38:44.072+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:38:44.725+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:38:44.722+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T05:38:49.193+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:38:49.993+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:38:49.991+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T05:38:50.304+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:38:50.303+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T05:38:51.078+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 7.056 seconds
[2025-09-11T05:39:41.774+0000] {processor.py:161} INFO - Started process (PID=794) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:39:41.782+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:39:41.808+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:39:41.803+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:39:43.078+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:39:43.076+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T05:39:46.963+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:39:47.141+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:39:47.140+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T05:39:47.222+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:39:47.221+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T05:39:47.559+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.871 seconds
[2025-09-11T05:40:46.659+0000] {processor.py:161} INFO - Started process (PID=813) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:40:46.661+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:40:46.665+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:40:46.664+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:40:46.841+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:40:46.840+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T05:40:50.475+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:40:50.609+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:40:50.608+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T05:40:50.664+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:40:50.663+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T05:40:50.971+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.324 seconds
[2025-09-11T05:41:36.102+0000] {processor.py:161} INFO - Started process (PID=827) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:41:36.111+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:41:36.132+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:41:36.128+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:41:37.023+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:41:37.021+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T05:41:40.396+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:41:40.562+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:41:40.560+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T05:41:40.632+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:41:40.632+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T05:41:40.954+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.909 seconds
[2025-09-11T05:42:30.585+0000] {processor.py:161} INFO - Started process (PID=842) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:42:30.597+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:42:30.610+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:42:30.608+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:42:31.361+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:42:31.358+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T05:42:36.420+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:42:36.484+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:42:36.483+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T05:42:36.511+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:42:36.511+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T05:42:36.680+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 6.149 seconds
[2025-09-11T05:43:41.774+0000] {processor.py:161} INFO - Started process (PID=862) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:43:41.781+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:43:41.795+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:43:41.793+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:43:42.370+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:43:42.369+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T05:43:44.005+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:43:44.187+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:43:44.184+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T05:43:44.270+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:43:44.269+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T05:43:44.591+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.861 seconds
[2025-09-11T05:44:48.025+0000] {processor.py:161} INFO - Started process (PID=881) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:44:48.043+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:44:48.089+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:44:48.086+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:44:49.824+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:44:49.822+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T05:44:51.648+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:44:51.799+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:44:51.797+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T05:44:51.862+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:44:51.861+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T05:44:52.203+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.297 seconds
[2025-09-11T05:45:31.808+0000] {processor.py:161} INFO - Started process (PID=896) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:45:31.814+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:45:31.826+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:45:31.824+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:45:32.417+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:45:32.414+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T05:45:35.122+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:45:35.259+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:45:35.257+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T05:45:35.322+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:45:35.321+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T05:45:36.135+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.362 seconds
[2025-09-11T05:46:17.078+0000] {processor.py:161} INFO - Started process (PID=910) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:46:17.085+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:46:17.096+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:46:17.094+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:46:17.662+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:46:17.660+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T05:46:19.408+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:46:19.594+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:46:19.592+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T05:46:19.681+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:46:19.680+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T05:46:20.253+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.210 seconds
[2025-09-11T05:47:12.139+0000] {processor.py:161} INFO - Started process (PID=929) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:47:12.148+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:47:12.166+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:47:12.163+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:47:12.950+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:47:12.948+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T05:47:15.251+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:47:15.391+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:47:15.389+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T05:47:15.450+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:47:15.449+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T05:47:15.812+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.729 seconds
[2025-09-11T05:47:57.064+0000] {processor.py:161} INFO - Started process (PID=945) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:47:57.125+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:47:57.181+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:47:57.178+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:47:58.309+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:47:58.306+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T05:48:00.922+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:48:01.062+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:48:01.061+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T05:48:01.135+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:48:01.134+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T05:48:01.469+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.523 seconds
[2025-09-11T05:48:48.458+0000] {processor.py:161} INFO - Started process (PID=962) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:48:48.473+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:48:48.491+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:48:48.489+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:48:48.768+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:48:48.767+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T05:48:53.664+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:48:53.749+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:48:53.747+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T05:48:53.824+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:48:53.824+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T05:48:54.093+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.697 seconds
[2025-09-11T05:49:52.125+0000] {processor.py:161} INFO - Started process (PID=980) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:49:52.132+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:49:52.154+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:49:52.150+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:49:53.046+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:49:53.043+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T05:49:57.032+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:49:57.223+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:49:57.221+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T05:49:57.312+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:49:57.312+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T05:49:58.092+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 6.040 seconds
[2025-09-11T05:51:06.665+0000] {processor.py:161} INFO - Started process (PID=1000) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:51:06.669+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:51:06.678+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:51:06.677+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:51:07.172+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:51:07.169+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T05:51:11.099+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:51:11.211+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:51:11.210+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T05:51:11.264+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:51:11.263+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T05:51:11.491+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.857 seconds
[2025-09-11T05:52:27.337+0000] {processor.py:161} INFO - Started process (PID=1021) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:52:27.349+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:52:27.391+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:52:27.387+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:52:28.065+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:52:28.064+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T05:52:31.613+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:52:32.872+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:52:32.866+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T05:52:32.949+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:52:32.948+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T05:52:33.368+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 6.135 seconds
[2025-09-11T05:53:27.861+0000] {processor.py:161} INFO - Started process (PID=1040) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:53:27.868+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:53:27.884+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:53:27.881+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:53:28.751+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:53:28.745+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T05:53:32.017+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:53:32.142+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:53:32.141+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T05:53:32.198+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:53:32.197+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T05:53:32.501+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.680 seconds
[2025-09-11T05:54:39.877+0000] {processor.py:161} INFO - Started process (PID=1059) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:54:39.886+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:54:39.907+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:54:39.903+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:54:41.752+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:54:41.750+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T05:54:45.112+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:54:45.329+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:54:45.326+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T05:54:45.426+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:54:45.425+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T05:54:45.865+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 6.039 seconds
[2025-09-11T05:56:01.514+0000] {processor.py:161} INFO - Started process (PID=1080) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:56:01.551+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:56:01.602+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:56:01.589+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:56:02.705+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:56:02.702+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T05:56:05.448+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:56:05.607+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:56:05.605+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T05:56:05.742+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:56:05.741+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T05:56:06.231+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.896 seconds
[2025-09-11T05:57:00.698+0000] {processor.py:161} INFO - Started process (PID=1095) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:57:00.712+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T05:57:00.729+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:57:00.728+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:57:01.386+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:57:01.384+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T05:57:03.925+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T05:57:04.008+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:57:04.007+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T05:57:04.052+0000] {logging_mixin.py:188} INFO - [2025-09-11T05:57:04.051+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T05:57:04.201+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.552 seconds
[2025-09-11T06:00:33.193+0000] {processor.py:161} INFO - Started process (PID=1136) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:00:33.200+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:00:33.214+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:00:33.212+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:00:33.793+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:00:33.791+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:00:35.688+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:00:35.829+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:00:35.827+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:00:35.887+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:00:35.886+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:00:36.174+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.029 seconds
[2025-09-11T06:01:16.377+0000] {processor.py:161} INFO - Started process (PID=1151) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:01:16.384+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:01:16.396+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:01:16.394+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:01:16.994+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:01:16.993+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:01:18.825+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:01:18.964+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:01:18.962+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:01:19.030+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:01:19.030+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:01:19.340+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.006 seconds
[2025-09-11T06:02:04.618+0000] {processor.py:161} INFO - Started process (PID=1166) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:02:04.632+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:02:04.656+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:02:04.654+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:02:05.743+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:02:05.741+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:02:10.033+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:02:10.161+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:02:10.160+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:02:10.210+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:02:10.209+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:02:10.392+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.864 seconds
[2025-09-11T06:02:55.542+0000] {processor.py:161} INFO - Started process (PID=1181) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:02:55.550+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:02:55.562+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:02:55.560+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:02:56.651+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:02:56.637+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:03:00.420+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:03:00.494+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:03:00.492+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:03:00.531+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:03:00.530+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:03:00.671+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.168 seconds
[2025-09-11T06:03:45.620+0000] {processor.py:161} INFO - Started process (PID=1196) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:03:45.644+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:03:45.655+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:03:45.653+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:03:46.499+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:03:46.497+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:03:48.032+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:03:48.222+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:03:48.220+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:03:48.343+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:03:48.342+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:03:48.738+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.156 seconds
[2025-09-11T06:04:59.069+0000] {processor.py:161} INFO - Started process (PID=1217) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:04:59.075+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:04:59.087+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:04:59.085+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:04:59.700+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:04:59.699+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:05:01.890+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:05:02.040+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:05:02.039+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:05:02.117+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:05:02.111+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:05:02.499+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.463 seconds
[2025-09-11T06:06:13.008+0000] {processor.py:161} INFO - Started process (PID=1237) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:06:13.022+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:06:13.046+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:06:13.041+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:06:13.878+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:06:13.875+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:06:17.262+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:06:17.483+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:06:17.482+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:06:17.601+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:06:17.600+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:06:18.091+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.142 seconds
[2025-09-11T06:07:08.573+0000] {processor.py:161} INFO - Started process (PID=1252) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:07:08.582+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:07:08.601+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:07:08.597+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:07:09.648+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:07:09.646+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:07:11.883+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:07:12.023+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:07:12.021+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:07:12.080+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:07:12.079+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:07:12.407+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.886 seconds
[2025-09-11T06:07:51.499+0000] {processor.py:161} INFO - Started process (PID=1267) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:07:51.507+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:07:51.534+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:07:51.531+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:07:52.202+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:07:52.200+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:07:54.129+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:07:54.212+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:07:54.211+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:07:54.240+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:07:54.239+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:07:54.388+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.950 seconds
[2025-09-11T06:08:51.338+0000] {processor.py:161} INFO - Started process (PID=1282) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:08:51.340+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:08:51.344+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:08:51.344+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:08:51.561+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:08:51.560+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:08:52.458+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:08:52.517+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:08:52.516+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:08:52.543+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:08:52.543+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:08:53.809+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.489 seconds
[2025-09-11T06:09:53.710+0000] {processor.py:161} INFO - Started process (PID=1296) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:09:53.733+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:09:53.750+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:09:53.747+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:09:54.610+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:09:54.608+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:09:57.962+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:09:58.102+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:09:58.101+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:09:58.159+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:09:58.158+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:10:00.976+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 7.314 seconds
[2025-09-11T06:11:15.027+0000] {processor.py:161} INFO - Started process (PID=1311) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:11:15.031+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:11:15.048+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:11:15.044+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:11:15.727+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:11:15.725+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:11:17.495+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:11:17.586+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:11:17.586+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:11:17.623+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:11:17.622+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:11:18.037+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.046 seconds
[2025-09-11T06:16:00.418+0000] {processor.py:161} INFO - Started process (PID=1327) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:16:00.427+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:16:00.435+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:16:00.433+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:16:01.023+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:16:01.021+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:16:04.421+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:16:04.651+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:16:04.650+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:16:04.702+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:16:04.701+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:16:05.148+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.763 seconds
[2025-09-11T06:17:28.198+0000] {processor.py:161} INFO - Started process (PID=1342) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:17:28.202+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:17:28.213+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:17:28.205+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:17:28.768+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:17:28.765+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:17:31.316+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:17:31.684+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:17:31.681+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:17:31.889+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:17:31.888+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:17:32.375+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.207 seconds
[2025-09-11T06:18:35.861+0000] {processor.py:161} INFO - Started process (PID=1357) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:18:35.864+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:18:35.868+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:18:35.866+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:18:36.294+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:18:36.291+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:18:40.225+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:18:40.557+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:18:40.554+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:18:40.715+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:18:40.714+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:18:41.345+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.506 seconds
[2025-09-11T06:19:40.809+0000] {processor.py:161} INFO - Started process (PID=1372) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:19:40.823+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:19:40.838+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:19:40.832+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:19:42.783+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:19:42.768+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:19:45.408+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:19:45.547+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:19:45.545+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:19:45.588+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:19:45.587+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:19:45.782+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.111 seconds
[2025-09-11T06:20:47.099+0000] {processor.py:161} INFO - Started process (PID=1387) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:20:47.110+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:20:47.118+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:20:47.115+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:20:48.110+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:20:48.106+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:20:51.899+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:20:52.313+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:20:52.310+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:20:52.483+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:20:52.481+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:20:52.842+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.801 seconds
[2025-09-11T06:21:54.462+0000] {processor.py:161} INFO - Started process (PID=1402) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:21:54.469+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:21:54.477+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:21:54.474+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:21:55.389+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:21:55.383+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:21:58.939+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:21:59.238+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:21:59.235+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:21:59.407+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:21:59.406+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:22:00.075+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.672 seconds
[2025-09-11T06:23:00.150+0000] {processor.py:161} INFO - Started process (PID=1417) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:23:00.160+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:23:00.170+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:23:00.167+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:23:01.398+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:23:01.390+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:23:06.110+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:23:06.338+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:23:06.333+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:23:06.493+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:23:06.491+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:23:07.071+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 6.988 seconds
[2025-09-11T06:24:08.666+0000] {processor.py:161} INFO - Started process (PID=1432) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:24:08.676+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:24:08.686+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:24:08.682+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:24:10.057+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:24:10.054+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:24:14.486+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:24:14.722+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:24:14.719+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:24:14.837+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:24:14.836+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:24:15.368+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 6.772 seconds
[2025-09-11T06:25:20.539+0000] {processor.py:161} INFO - Started process (PID=1447) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:25:20.557+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:25:20.567+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:25:20.564+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:25:21.844+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:25:21.841+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:25:25.799+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:25:25.947+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:25:25.945+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:25:25.998+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:25:25.997+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:25:26.439+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.966 seconds
[2025-09-11T06:26:18.471+0000] {processor.py:161} INFO - Started process (PID=1462) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:26:18.483+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:26:18.494+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:26:18.489+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:26:20.098+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:26:20.095+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:26:21.737+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:26:21.859+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:26:21.857+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:26:21.902+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:26:21.901+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:26:22.155+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.772 seconds
[2025-09-11T06:27:04.106+0000] {processor.py:161} INFO - Started process (PID=1477) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:27:04.115+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:27:04.133+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:27:04.122+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:27:05.497+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:27:05.494+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:27:07.558+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:27:07.742+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:27:07.736+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:27:07.820+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:27:07.817+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:27:08.100+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.052 seconds
[2025-09-11T06:27:46.792+0000] {processor.py:161} INFO - Started process (PID=1492) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:27:46.824+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:27:46.841+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:27:46.830+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:27:48.408+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:27:48.396+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:27:50.454+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:27:50.555+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:27:50.554+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:27:50.598+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:27:50.598+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:27:50.857+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.227 seconds
[2025-09-11T06:28:36.464+0000] {processor.py:161} INFO - Started process (PID=1507) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:28:36.470+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:28:36.477+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:28:36.474+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:28:38.068+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:28:38.057+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:28:40.501+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:28:40.629+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:28:40.627+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:28:40.718+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:28:40.718+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:28:40.922+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.521 seconds
[2025-09-11T06:29:27.179+0000] {processor.py:161} INFO - Started process (PID=1522) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:29:27.187+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:29:27.195+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:29:27.191+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:29:27.715+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:29:27.713+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:29:30.187+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:29:30.288+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:29:30.287+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:29:30.353+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:29:30.352+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:29:30.593+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.442 seconds
[2025-09-11T06:30:14.596+0000] {processor.py:161} INFO - Started process (PID=1537) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:30:14.623+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:30:14.635+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:30:14.634+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:30:18.892+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:30:18.890+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:30:21.242+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:30:21.358+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:30:21.356+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:30:21.476+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:30:21.476+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:30:22.276+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 7.730 seconds
[2025-09-11T06:31:09.250+0000] {processor.py:161} INFO - Started process (PID=1552) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:31:09.269+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:31:09.272+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:31:09.271+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:31:10.052+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:31:10.050+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:31:12.119+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:31:12.270+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:31:12.268+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:31:12.321+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:31:12.321+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:31:12.525+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.312 seconds
[2025-09-11T06:32:19.763+0000] {processor.py:161} INFO - Started process (PID=1572) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:32:19.777+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:32:19.782+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:32:19.781+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:32:20.348+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:32:20.346+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:32:21.688+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:32:21.762+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:32:21.761+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:32:21.814+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:32:21.814+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:32:21.992+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.270 seconds
[2025-09-11T06:33:08.367+0000] {processor.py:161} INFO - Started process (PID=1587) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:33:08.370+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:33:08.372+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:33:08.372+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:33:08.614+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:33:08.612+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:33:11.747+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:33:11.896+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:33:11.893+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:33:11.966+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:33:11.966+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:33:12.209+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.858 seconds
[2025-09-11T06:33:58.651+0000] {processor.py:161} INFO - Started process (PID=1603) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:33:58.658+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:33:58.667+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:33:58.664+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:34:00.120+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:34:00.116+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:34:02.887+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:34:03.332+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:34:03.330+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:34:03.506+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:34:03.504+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:34:03.904+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.307 seconds
[2025-09-11T06:36:38.191+0000] {processor.py:161} INFO - Started process (PID=1622) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:36:38.203+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:36:38.207+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:36:38.205+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:36:38.863+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:36:38.861+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:36:42.438+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:36:45.089+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:36:45.084+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:36:46.680+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:36:46.679+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:36:56.317+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 18.140 seconds
[2025-09-11T06:38:08.037+0000] {processor.py:161} INFO - Started process (PID=1642) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:38:08.042+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:38:08.048+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:38:08.046+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:38:08.579+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:38:08.576+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:38:10.819+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:38:10.910+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:38:10.907+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:38:10.949+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:38:10.949+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:38:11.124+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.124 seconds
[2025-09-11T06:39:01.790+0000] {processor.py:161} INFO - Started process (PID=1660) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:39:01.810+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:39:01.818+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:39:01.817+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:39:02.184+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:39:02.183+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:39:03.577+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:39:03.703+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:39:03.701+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:39:03.765+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:39:03.764+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:39:03.962+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.202 seconds
[2025-09-11T06:39:55.693+0000] {processor.py:161} INFO - Started process (PID=1677) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:39:55.701+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:39:55.718+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:39:55.715+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:39:57.185+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:39:57.183+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:39:59.261+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:39:59.358+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:39:59.357+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:39:59.410+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:39:59.410+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:39:59.631+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.017 seconds
[2025-09-11T06:40:43.149+0000] {processor.py:161} INFO - Started process (PID=1693) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:40:43.159+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:40:43.168+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:40:43.164+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:40:44.480+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:40:44.468+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:40:47.216+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:40:47.367+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:40:47.366+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:40:47.402+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:40:47.402+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:40:47.749+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.722 seconds
[2025-09-11T06:41:22.038+0000] {processor.py:161} INFO - Started process (PID=1708) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:41:22.043+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:41:22.046+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:41:22.045+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:41:22.412+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:41:22.410+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:41:24.383+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:41:24.488+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:41:24.487+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:41:24.527+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:41:24.526+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:41:24.698+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.681 seconds
[2025-09-11T06:41:56.714+0000] {processor.py:161} INFO - Started process (PID=1723) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:41:56.718+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:41:56.721+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:41:56.720+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:41:57.109+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:41:57.106+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:41:58.653+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:41:58.751+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:41:58.751+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:41:58.793+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:41:58.793+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:41:58.972+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.286 seconds
[2025-09-11T06:42:38.010+0000] {processor.py:161} INFO - Started process (PID=1739) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:42:38.016+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:42:38.021+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:42:38.019+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:42:38.606+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:42:38.603+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:42:40.684+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:42:40.813+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:42:40.811+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:42:40.882+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:42:40.881+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:42:41.099+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.126 seconds
[2025-09-11T06:43:18.347+0000] {processor.py:161} INFO - Started process (PID=1754) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:43:18.357+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:43:18.368+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:43:18.364+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:43:19.436+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:43:19.432+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:43:21.741+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:43:21.904+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:43:21.903+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:43:21.954+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:43:21.954+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:43:22.155+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.881 seconds
[2025-09-11T06:44:00.522+0000] {processor.py:161} INFO - Started process (PID=1769) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:44:00.553+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:44:00.571+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:44:00.568+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:44:01.635+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:44:01.634+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:44:03.323+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:44:03.402+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:44:03.401+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:44:03.439+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:44:03.438+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:44:03.590+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.229 seconds
[2025-09-11T06:44:35.577+0000] {processor.py:161} INFO - Started process (PID=1784) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:44:35.584+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:44:35.589+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:44:35.587+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:44:36.044+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:44:36.042+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:44:37.789+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:44:37.903+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:44:37.902+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:44:37.942+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:44:37.941+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:44:38.142+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.591 seconds
[2025-09-11T06:45:19.125+0000] {processor.py:161} INFO - Started process (PID=1799) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:45:19.132+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:45:19.137+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:45:19.135+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:45:19.897+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:45:19.895+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:45:22.228+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:45:22.314+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:45:22.312+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:45:22.349+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:45:22.349+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:45:22.498+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.416 seconds
[2025-09-11T06:45:55.103+0000] {processor.py:161} INFO - Started process (PID=1815) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:45:55.106+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:45:55.109+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:45:55.107+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:45:55.373+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:45:55.372+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:45:56.551+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:45:56.847+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:45:56.845+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:45:56.925+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:45:56.924+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:45:57.110+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.024 seconds
[2025-09-11T06:46:39.650+0000] {processor.py:161} INFO - Started process (PID=1830) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:46:39.680+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:46:39.699+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:46:39.687+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:46:41.698+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:46:41.694+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:46:44.124+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:46:44.248+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:46:44.248+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:46:44.317+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:46:44.316+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:46:44.486+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.030 seconds
[2025-09-11T06:47:19.798+0000] {processor.py:161} INFO - Started process (PID=1845) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:47:19.803+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:47:19.809+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:47:19.807+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:47:20.665+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:47:20.661+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:47:22.520+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:47:22.620+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:47:22.618+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:47:22.670+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:47:22.670+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:47:22.906+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.136 seconds
[2025-09-11T06:47:55.480+0000] {processor.py:161} INFO - Started process (PID=1860) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:47:55.487+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:47:55.492+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:47:55.490+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:47:56.077+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:47:56.075+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:47:58.439+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:47:58.565+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:47:58.564+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:47:58.615+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:47:58.615+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:47:58.872+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.427 seconds
[2025-09-11T06:48:38.911+0000] {processor.py:161} INFO - Started process (PID=1875) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:48:38.917+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:48:38.922+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:48:38.920+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:48:39.283+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:48:39.282+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:48:40.471+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:48:40.538+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:48:40.537+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:48:40.566+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:48:40.565+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:48:40.692+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.808 seconds
[2025-09-11T06:49:12.675+0000] {processor.py:161} INFO - Started process (PID=1890) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:49:12.678+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:49:12.680+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:49:12.679+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:49:12.950+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:49:12.949+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:49:13.908+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:49:13.979+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:49:13.978+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:49:14.011+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:49:14.011+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:49:14.146+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.493 seconds
[2025-09-11T06:49:50.806+0000] {processor.py:161} INFO - Started process (PID=1905) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:49:50.842+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:49:50.868+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:49:50.864+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:49:51.896+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:49:51.892+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:49:54.110+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:49:54.201+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:49:54.199+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:49:54.244+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:49:54.243+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:49:54.442+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.800 seconds
[2025-09-11T06:50:36.057+0000] {processor.py:161} INFO - Started process (PID=1920) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:50:36.077+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:50:36.094+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:50:36.086+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:50:37.174+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:50:37.169+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:50:39.586+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:50:39.733+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:50:39.725+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:50:39.803+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:50:39.803+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:50:40.136+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.177 seconds
[2025-09-11T06:51:23.986+0000] {processor.py:161} INFO - Started process (PID=1939) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:51:23.990+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:51:23.992+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:51:23.991+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:51:24.236+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:51:24.235+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:51:25.171+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:51:25.248+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:51:25.248+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:51:25.286+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:51:25.286+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:51:25.427+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.461 seconds
[2025-09-11T06:52:05.740+0000] {processor.py:161} INFO - Started process (PID=1955) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:52:05.744+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:52:05.746+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:52:05.745+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:52:06.046+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:52:06.044+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:52:07.198+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:52:07.279+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:52:07.273+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:52:07.708+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:52:07.708+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:52:07.868+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.144 seconds
[2025-09-11T06:53:00.160+0000] {processor.py:161} INFO - Started process (PID=1974) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:53:00.165+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:53:00.183+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:53:00.181+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:53:00.909+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:53:00.905+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:53:02.584+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:53:02.674+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:53:02.673+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:53:02.715+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:53:02.714+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:53:02.874+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.765 seconds
[2025-09-11T06:53:40.670+0000] {processor.py:161} INFO - Started process (PID=1989) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:53:40.673+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:53:40.677+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:53:40.676+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:53:41.014+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:53:41.013+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:53:42.367+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:53:42.447+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:53:42.446+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:53:42.482+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:53:42.482+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:53:43.027+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.376 seconds
[2025-09-11T06:54:16.366+0000] {processor.py:161} INFO - Started process (PID=2004) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:54:16.372+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:54:16.380+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:54:16.379+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:54:16.915+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:54:16.912+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:54:18.388+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:54:18.969+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:54:18.968+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:54:19.030+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:54:19.029+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:54:19.257+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.956 seconds
[2025-09-11T06:54:53.666+0000] {processor.py:161} INFO - Started process (PID=2019) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:54:53.670+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:54:53.673+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:54:53.672+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:54:54.063+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:54:54.059+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:54:55.726+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:54:55.824+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:54:55.822+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:54:55.868+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:54:55.868+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:54:56.029+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.390 seconds
[2025-09-11T06:55:38.601+0000] {processor.py:161} INFO - Started process (PID=2035) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:55:38.605+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:55:38.610+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:55:38.608+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:55:39.224+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:55:39.221+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:55:41.309+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:55:41.890+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:55:41.409+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:55:41.924+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:55:41.924+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:55:42.064+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.499 seconds
[2025-09-11T06:56:25.976+0000] {processor.py:161} INFO - Started process (PID=2050) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:56:25.981+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:56:25.985+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:56:25.983+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:56:26.476+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:56:26.474+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:56:28.411+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:56:28.540+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:56:28.539+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:56:28.583+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:56:28.583+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:56:28.749+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.818 seconds
[2025-09-11T06:57:05.931+0000] {processor.py:161} INFO - Started process (PID=2065) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:57:05.940+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:57:05.948+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:57:05.945+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:57:06.667+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:57:06.664+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:57:08.554+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:57:08.691+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:57:08.685+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:57:09.262+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:57:09.261+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:57:09.448+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.573 seconds
[2025-09-11T06:57:59.248+0000] {processor.py:161} INFO - Started process (PID=2084) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:57:59.269+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:57:59.282+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:57:59.278+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:58:01.191+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:58:01.177+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:58:03.654+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:58:03.732+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:58:03.731+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:58:03.773+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:58:03.772+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:58:03.946+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.782 seconds
[2025-09-11T06:58:47.373+0000] {processor.py:161} INFO - Started process (PID=2101) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:58:47.377+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:58:47.385+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:58:47.380+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:58:48.066+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:58:48.063+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:58:50.375+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:58:50.468+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:58:50.467+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:58:50.518+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:58:50.517+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:58:50.771+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.438 seconds
[2025-09-11T06:59:43.471+0000] {processor.py:161} INFO - Started process (PID=2120) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:59:43.476+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T06:59:43.480+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:59:43.478+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:59:43.866+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:59:43.865+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T06:59:45.822+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T06:59:45.906+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:59:45.905+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T06:59:45.940+0000] {logging_mixin.py:188} INFO - [2025-09-11T06:59:45.939+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T06:59:46.088+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.647 seconds
[2025-09-11T07:00:35.705+0000] {processor.py:161} INFO - Started process (PID=2137) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:00:35.710+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:00:35.713+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:00:35.711+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:00:36.112+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:00:36.110+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:00:38.060+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:00:38.157+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:00:38.156+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:00:38.195+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:00:38.195+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:00:38.376+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.696 seconds
[2025-09-11T07:01:18.691+0000] {processor.py:161} INFO - Started process (PID=2152) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:01:18.694+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:01:18.696+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:01:18.695+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:01:19.048+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:01:19.046+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:01:20.731+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:01:20.858+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:01:20.856+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:01:20.944+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:01:20.943+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:01:21.131+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.465 seconds
[2025-09-11T07:01:54.968+0000] {processor.py:161} INFO - Started process (PID=2166) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:01:54.971+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:01:54.973+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:01:54.972+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:01:55.226+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:01:55.224+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:01:56.519+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:01:56.584+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:01:56.584+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:01:56.607+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:01:56.607+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:01:56.739+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.786 seconds
[2025-09-11T07:02:30.629+0000] {processor.py:161} INFO - Started process (PID=2181) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:02:30.635+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:02:30.641+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:02:30.638+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:02:31.376+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:02:31.373+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:02:33.699+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:02:33.788+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:02:33.787+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:02:33.828+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:02:33.827+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:02:34.023+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.430 seconds
[2025-09-11T07:03:09.320+0000] {processor.py:161} INFO - Started process (PID=2196) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:03:09.323+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:03:09.326+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:03:09.325+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:03:09.807+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:03:09.805+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:03:11.226+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:03:11.289+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:03:11.288+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:03:11.313+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:03:11.312+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:03:11.443+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.139 seconds
[2025-09-11T07:03:49.951+0000] {processor.py:161} INFO - Started process (PID=2211) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:03:49.957+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:03:49.962+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:03:49.961+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:03:50.689+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:03:50.684+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:03:53.718+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:03:53.806+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:03:53.804+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:03:53.850+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:03:53.850+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:03:54.032+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.135 seconds
[2025-09-11T07:04:28.890+0000] {processor.py:161} INFO - Started process (PID=2226) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:04:28.894+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:04:28.904+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:04:28.902+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:04:29.282+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:04:29.281+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:04:31.325+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:04:31.403+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:04:31.403+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:04:31.443+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:04:31.443+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:04:31.591+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.728 seconds
[2025-09-11T07:05:04.068+0000] {processor.py:161} INFO - Started process (PID=2241) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:05:04.071+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:05:04.073+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:05:04.072+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:05:04.332+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:05:04.329+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:05:05.567+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:05:05.625+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:05:05.625+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:05:05.649+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:05:05.648+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:05:05.783+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.733 seconds
[2025-09-11T07:05:46.609+0000] {processor.py:161} INFO - Started process (PID=2256) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:05:46.625+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:05:46.628+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:05:46.627+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:05:46.995+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:05:46.990+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:05:48.260+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:05:48.328+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:05:48.327+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:05:48.349+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:05:48.349+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:05:48.477+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.891 seconds
[2025-09-11T07:06:28.144+0000] {processor.py:161} INFO - Started process (PID=2271) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:06:28.148+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:06:28.152+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:06:28.150+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:06:28.492+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:06:28.491+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:06:30.125+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:06:30.204+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:06:30.203+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:06:30.242+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:06:30.242+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:06:30.422+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.294 seconds
[2025-09-11T07:07:02.703+0000] {processor.py:161} INFO - Started process (PID=2286) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:07:02.707+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:07:02.710+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:07:02.709+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:07:03.092+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:07:03.090+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:07:05.055+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:07:05.196+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:07:05.195+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:07:05.253+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:07:05.252+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:07:05.428+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.760 seconds
[2025-09-11T07:07:40.483+0000] {processor.py:161} INFO - Started process (PID=2301) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:07:40.491+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:07:40.495+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:07:40.494+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:07:40.922+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:07:40.920+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:07:43.049+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:07:43.138+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:07:43.137+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:07:43.162+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:07:43.162+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:07:43.320+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.883 seconds
[2025-09-11T07:08:24.538+0000] {processor.py:161} INFO - Started process (PID=2315) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:08:24.545+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:08:24.557+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:08:24.555+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:08:26.457+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:08:26.454+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:08:28.282+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:08:28.389+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:08:28.387+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:08:28.444+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:08:28.443+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:08:28.661+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.164 seconds
[2025-09-11T07:09:03.698+0000] {processor.py:161} INFO - Started process (PID=2330) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:09:03.700+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:09:03.705+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:09:03.704+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:09:03.931+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:09:03.930+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:09:05.208+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:09:05.275+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:09:05.275+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:09:05.298+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:09:05.298+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:09:05.430+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.748 seconds
[2025-09-11T07:09:45.926+0000] {processor.py:161} INFO - Started process (PID=2345) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:09:45.937+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:09:45.949+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:09:45.943+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:09:48.926+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:09:48.924+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:09:50.772+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:09:50.842+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:09:50.841+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:09:50.882+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:09:50.881+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:09:51.029+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.175 seconds
[2025-09-11T07:10:26.337+0000] {processor.py:161} INFO - Started process (PID=2360) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:10:26.350+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:10:26.362+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:10:26.357+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:10:27.421+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:10:27.416+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:10:30.683+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:10:30.812+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:10:30.810+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:10:30.859+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:10:30.858+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:10:31.067+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.821 seconds
[2025-09-11T07:11:05.944+0000] {processor.py:161} INFO - Started process (PID=2375) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:11:05.978+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:11:05.998+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:11:05.990+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:11:09.866+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:11:09.865+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:11:11.627+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:11:11.701+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:11:11.700+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:11:11.738+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:11:11.737+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:11:11.879+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 6.112 seconds
[2025-09-11T07:11:46.452+0000] {processor.py:161} INFO - Started process (PID=2390) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:11:46.468+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:11:46.483+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:11:46.476+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:11:48.496+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:11:48.495+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:11:50.365+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:11:50.580+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:11:50.578+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:11:50.619+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:11:50.618+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:11:50.807+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.439 seconds
[2025-09-11T07:12:23.293+0000] {processor.py:161} INFO - Started process (PID=2405) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:12:23.296+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:12:23.300+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:12:23.298+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:12:23.711+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:12:23.710+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:12:25.591+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:12:25.649+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:12:25.648+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:12:25.675+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:12:25.674+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:12:25.798+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.556 seconds
[2025-09-11T07:13:02.434+0000] {processor.py:161} INFO - Started process (PID=2420) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:13:02.438+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:13:02.441+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:13:02.440+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:13:03.414+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:13:03.412+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:13:05.106+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:13:05.268+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:13:05.267+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:13:05.310+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:13:05.309+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:13:05.463+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.049 seconds
[2025-09-11T07:13:40.126+0000] {processor.py:161} INFO - Started process (PID=2435) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:13:40.134+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:13:40.139+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:13:40.137+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:13:41.990+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:13:41.988+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:13:43.722+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:13:43.817+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:13:43.816+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:13:43.853+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:13:43.853+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:13:44.013+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.935 seconds
[2025-09-11T07:14:20.423+0000] {processor.py:161} INFO - Started process (PID=2450) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:14:20.429+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:14:20.434+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:14:20.432+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:14:21.637+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:14:21.635+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:14:22.913+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:14:22.992+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:14:22.990+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:14:23.023+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:14:23.023+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:14:23.184+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.796 seconds
[2025-09-11T07:14:53.428+0000] {processor.py:161} INFO - Started process (PID=2465) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:14:53.431+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:14:53.433+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:14:53.432+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:14:54.075+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:14:54.074+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:14:55.529+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:14:55.587+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:14:55.586+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:14:55.608+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:14:55.608+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:14:55.737+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.329 seconds
[2025-09-11T07:15:28.479+0000] {processor.py:161} INFO - Started process (PID=2480) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:15:28.492+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:15:28.505+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:15:28.501+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:15:30.606+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:15:30.605+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:15:32.789+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:15:32.882+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:15:32.879+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:15:32.921+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:15:32.921+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:15:33.119+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.715 seconds
[2025-09-11T07:16:12.204+0000] {processor.py:161} INFO - Started process (PID=2495) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:16:12.208+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:16:12.211+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:16:12.210+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:16:12.512+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:16:12.510+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:16:13.718+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:16:13.789+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:16:13.788+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:16:13.817+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:16:13.816+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:16:13.948+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.760 seconds
[2025-09-11T07:16:47.208+0000] {processor.py:161} INFO - Started process (PID=2509) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:16:47.210+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:16:47.213+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:16:47.212+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:16:47.454+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:16:47.452+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:16:48.389+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:16:48.451+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:16:48.450+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:16:48.481+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:16:48.480+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:16:48.653+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.458 seconds
[2025-09-11T07:17:23.675+0000] {processor.py:161} INFO - Started process (PID=2524) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:17:23.678+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:17:23.681+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:17:23.680+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:17:23.959+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:17:23.957+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:17:24.961+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:17:25.027+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:17:25.026+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:17:25.060+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:17:25.059+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:17:25.183+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.524 seconds
[2025-09-11T07:18:01.523+0000] {processor.py:161} INFO - Started process (PID=2539) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:18:01.530+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:18:01.539+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:18:01.536+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:18:02.415+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:18:02.413+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:18:04.004+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:18:04.110+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:18:04.109+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:18:04.160+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:18:04.160+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:18:04.384+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.927 seconds
[2025-09-11T07:18:39.442+0000] {processor.py:161} INFO - Started process (PID=2554) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:18:39.445+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:18:39.447+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:18:39.446+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:18:39.758+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:18:39.757+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:18:40.850+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:18:40.928+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:18:40.927+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:18:40.961+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:18:40.961+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:18:41.131+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.707 seconds
[2025-09-11T07:19:18.933+0000] {processor.py:161} INFO - Started process (PID=2569) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:19:18.938+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:19:18.940+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:19:18.939+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:19:19.276+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:19:19.275+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:19:20.592+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:19:20.720+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:19:20.719+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:19:20.773+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:19:20.773+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:19:20.948+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.032 seconds
[2025-09-11T07:19:56.980+0000] {processor.py:161} INFO - Started process (PID=2584) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:19:56.983+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:19:56.988+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:19:56.986+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:19:57.508+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:19:57.506+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:19:59.126+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:19:59.186+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:19:59.185+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:19:59.211+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:19:59.211+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:19:59.375+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.426 seconds
[2025-09-11T07:20:40.324+0000] {processor.py:161} INFO - Started process (PID=2599) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:20:40.328+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:20:40.334+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:20:40.332+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:20:40.915+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:20:40.912+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:20:42.723+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:20:42.816+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:20:42.812+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:20:42.855+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:20:42.853+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:20:43.069+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.781 seconds
[2025-09-11T07:21:13.326+0000] {processor.py:161} INFO - Started process (PID=2614) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:21:13.329+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:21:13.332+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:21:13.331+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:21:13.632+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:21:13.631+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:21:14.741+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:21:14.816+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:21:14.815+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:21:14.853+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:21:14.852+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:21:15.002+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.701 seconds
[2025-09-11T07:21:55.039+0000] {processor.py:161} INFO - Started process (PID=2629) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:21:55.048+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:21:55.052+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:21:55.050+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:21:55.543+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:21:55.541+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:21:56.840+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:21:56.915+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:21:56.914+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:21:56.952+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:21:56.952+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:21:57.113+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.121 seconds
[2025-09-11T07:22:36.398+0000] {processor.py:161} INFO - Started process (PID=2644) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:22:36.408+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:22:36.421+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:22:36.417+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:22:37.402+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:22:37.398+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:22:40.047+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:22:40.370+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:22:40.368+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:22:40.614+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:22:40.613+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:22:41.169+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.840 seconds
[2025-09-11T07:23:12.296+0000] {processor.py:161} INFO - Started process (PID=2659) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:23:12.302+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:23:12.305+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:23:12.304+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:23:12.723+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:23:12.721+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:23:13.850+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:23:13.908+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:23:13.907+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:23:13.935+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:23:13.935+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:23:14.052+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.787 seconds
[2025-09-11T07:23:52.088+0000] {processor.py:161} INFO - Started process (PID=2674) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:23:52.096+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:23:52.104+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:23:52.101+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:23:52.485+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:23:52.484+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:23:54.053+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:23:54.121+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:23:54.118+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:23:54.154+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:23:54.153+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:23:54.311+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.281 seconds
[2025-09-11T07:24:30.550+0000] {processor.py:161} INFO - Started process (PID=2689) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:24:30.554+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:24:30.557+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:24:30.556+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:24:30.931+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:24:30.929+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:24:32.189+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:24:32.273+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:24:32.272+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:24:32.302+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:24:32.301+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:24:32.435+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.906 seconds
[2025-09-11T07:25:10.892+0000] {processor.py:161} INFO - Started process (PID=2704) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:25:10.900+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:25:10.907+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:25:10.904+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:25:11.629+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:25:11.626+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:25:13.807+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:25:13.917+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:25:13.910+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:25:13.999+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:25:13.998+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:25:14.202+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.394 seconds
[2025-09-11T07:25:45.583+0000] {processor.py:161} INFO - Started process (PID=2719) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:25:45.587+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:25:45.591+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:25:45.590+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:25:45.936+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:25:45.934+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:25:47.166+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:25:47.257+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:25:47.255+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:25:47.296+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:25:47.295+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:25:47.465+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.915 seconds
[2025-09-11T07:26:22.194+0000] {processor.py:161} INFO - Started process (PID=2734) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:26:22.198+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:26:22.210+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:26:22.200+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:26:22.437+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:26:22.436+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:26:23.382+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:26:23.450+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:26:23.449+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:26:23.484+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:26:23.484+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:26:23.609+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.447 seconds
[2025-09-11T07:27:02.426+0000] {processor.py:161} INFO - Started process (PID=2749) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:27:02.429+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:27:02.432+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:27:02.431+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:27:02.811+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:27:02.810+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:27:04.344+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:27:04.447+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:27:04.445+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:27:04.489+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:27:04.489+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:27:04.693+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.290 seconds
[2025-09-11T07:27:40.373+0000] {processor.py:161} INFO - Started process (PID=2764) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:27:40.384+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:27:40.396+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:27:40.392+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:27:41.371+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:27:41.367+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:27:43.945+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:27:44.061+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:27:44.060+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:27:44.115+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:27:44.115+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:27:44.363+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.062 seconds
[2025-09-11T07:28:17.291+0000] {processor.py:161} INFO - Started process (PID=2779) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:28:17.305+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:28:17.323+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:28:17.319+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:28:18.381+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:28:18.376+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:28:21.151+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:28:21.301+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:28:21.298+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:28:21.376+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:28:21.375+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:28:21.641+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.449 seconds
[2025-09-11T07:28:52.949+0000] {processor.py:161} INFO - Started process (PID=2794) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:28:52.954+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:28:52.958+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:28:52.957+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:28:53.365+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:28:53.362+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:28:54.845+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:28:54.940+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:28:54.938+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:28:54.981+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:28:54.981+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:28:55.181+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.256 seconds
[2025-09-11T07:29:32.976+0000] {processor.py:161} INFO - Started process (PID=2809) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:29:32.978+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:29:32.980+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:29:32.979+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:29:33.340+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:29:33.338+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:29:34.601+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:29:34.678+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:29:34.676+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:29:34.713+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:29:34.713+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:29:34.890+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.933 seconds
[2025-09-11T07:30:11.672+0000] {processor.py:161} INFO - Started process (PID=2824) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:30:11.686+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:30:11.690+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:30:11.689+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:30:11.950+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:30:11.949+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:30:13.164+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:30:13.249+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:30:13.248+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:30:13.287+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:30:13.286+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:30:13.423+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.780 seconds
[2025-09-11T07:30:48.837+0000] {processor.py:161} INFO - Started process (PID=2839) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:30:48.844+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:30:48.848+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:30:48.847+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:30:49.407+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:30:49.404+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:30:51.678+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:30:51.867+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:30:51.864+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:30:51.945+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:30:51.945+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:30:52.211+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.412 seconds
[2025-09-11T07:31:22.688+0000] {processor.py:161} INFO - Started process (PID=2854) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:31:22.696+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:31:22.716+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:31:22.714+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:31:23.191+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:31:23.187+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:31:24.491+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:31:24.603+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:31:24.602+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:31:24.647+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:31:24.647+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:31:24.839+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.221 seconds
[2025-09-11T07:32:02.678+0000] {processor.py:161} INFO - Started process (PID=2869) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:32:02.681+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:32:02.684+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:32:02.683+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:32:02.976+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:32:02.974+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:32:04.307+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:32:04.418+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:32:04.417+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:32:04.458+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:32:04.458+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:32:04.612+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.954 seconds
[2025-09-11T07:32:41.725+0000] {processor.py:161} INFO - Started process (PID=2884) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:32:41.733+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:32:41.740+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:32:41.737+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:32:42.608+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:32:42.594+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:32:45.143+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:32:45.265+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:32:45.263+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:32:45.317+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:32:45.317+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:32:45.509+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.832 seconds
[2025-09-11T07:33:16.461+0000] {processor.py:161} INFO - Started process (PID=2899) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:33:16.466+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:33:16.469+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:33:16.468+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:33:16.723+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:33:16.722+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:33:17.606+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:33:17.682+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:33:17.681+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:33:17.714+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:33:17.714+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:33:17.853+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.423 seconds
[2025-09-11T07:33:48.963+0000] {processor.py:161} INFO - Started process (PID=2914) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:33:48.966+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:33:48.971+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:33:48.969+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:33:49.348+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:33:49.341+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:33:52.436+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:33:52.602+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:33:52.597+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:33:52.650+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:33:52.650+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:33:52.866+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.927 seconds
[2025-09-11T07:34:30.525+0000] {processor.py:161} INFO - Started process (PID=2929) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:34:30.540+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:34:30.572+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:34:30.569+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:34:31.355+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:34:31.350+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:34:35.295+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:34:35.478+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:34:35.476+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:34:35.522+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:34:35.522+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:34:35.659+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.212 seconds
[2025-09-11T07:35:13.256+0000] {processor.py:161} INFO - Started process (PID=2944) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:35:13.260+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:35:13.270+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:35:13.268+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:35:13.646+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:35:13.644+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:35:15.140+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:35:15.264+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:35:15.262+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:35:15.315+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:35:15.315+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:35:15.518+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.302 seconds
[2025-09-11T07:35:47.406+0000] {processor.py:161} INFO - Started process (PID=2959) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:35:47.419+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:35:47.427+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:35:47.424+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:35:48.634+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:35:48.631+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:35:51.290+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:35:51.435+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:35:51.430+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:35:51.509+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:35:51.508+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:35:51.739+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.398 seconds
[2025-09-11T07:36:27.011+0000] {processor.py:161} INFO - Started process (PID=2973) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:36:27.018+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:36:27.024+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:36:27.022+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:36:27.817+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:36:27.812+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:36:30.026+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:36:30.202+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:36:30.198+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:36:30.282+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:36:30.281+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:36:30.644+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.672 seconds
[2025-09-11T07:37:13.448+0000] {processor.py:161} INFO - Started process (PID=2988) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:37:13.455+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:37:13.461+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:37:13.458+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:37:14.166+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:37:14.162+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:37:16.687+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:37:16.855+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:37:16.853+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:37:16.924+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:37:16.923+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:37:17.255+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.854 seconds
[2025-09-11T07:37:59.703+0000] {processor.py:161} INFO - Started process (PID=3003) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:37:59.710+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:37:59.717+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:37:59.714+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:38:00.416+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:38:00.412+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:38:03.209+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:38:03.436+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:38:03.433+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:38:03.550+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:38:03.549+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:38:03.926+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.274 seconds
[2025-09-11T07:38:53.827+0000] {processor.py:161} INFO - Started process (PID=3022) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:38:53.841+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:38:53.854+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:38:53.847+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:38:54.933+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:38:54.928+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:38:57.460+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:38:57.613+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:38:57.611+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:38:57.678+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:38:57.677+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:38:58.010+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.245 seconds
[2025-09-11T07:39:40.906+0000] {processor.py:161} INFO - Started process (PID=3037) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:39:40.912+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:39:40.918+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:39:40.916+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:39:41.608+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:39:41.604+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:39:44.813+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:39:44.960+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:39:44.959+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:39:45.022+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:39:45.022+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:39:45.249+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.388 seconds
[2025-09-11T07:40:29.349+0000] {processor.py:161} INFO - Started process (PID=3054) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:40:29.355+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:40:29.363+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:40:29.360+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:40:30.028+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:40:30.025+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:40:32.281+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:40:32.453+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:40:32.451+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:40:32.531+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:40:32.530+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:40:32.912+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.603 seconds
[2025-09-11T07:41:22.439+0000] {processor.py:161} INFO - Started process (PID=3072) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:41:22.449+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:41:22.455+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:41:22.453+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:41:23.777+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:41:23.772+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:41:26.208+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:41:26.364+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:41:26.361+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:41:26.436+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:41:26.435+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:41:26.727+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.332 seconds
[2025-09-11T07:42:06.070+0000] {processor.py:161} INFO - Started process (PID=3087) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:42:06.073+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:42:06.075+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:42:06.074+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:42:06.304+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:42:06.303+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:42:07.190+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:42:07.252+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:42:07.251+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:42:07.279+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:42:07.278+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:42:07.644+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.587 seconds
[2025-09-11T07:42:54.991+0000] {processor.py:161} INFO - Started process (PID=3102) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:42:54.994+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:42:54.997+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:42:54.996+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:42:55.337+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:42:55.335+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:42:57.465+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:42:57.548+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:42:57.546+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T07:42:57.595+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:42:57.595+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T07:42:57.762+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.791 seconds
[2025-09-11T07:45:29.016+0000] {processor.py:161} INFO - Started process (PID=3117) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:45:29.040+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:45:29.061+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:45:29.060+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:45:30.290+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:45:30.288+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T07:55:59.639+0000] {processor.py:161} INFO - Started process (PID=92) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:55:59.649+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:55:59.696+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:55:59.694+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:56:01.313+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:56:01.299+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
ModuleNotFoundError: No module named 'snowflake.snowpark'
[2025-09-11T07:56:01.319+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:56:01.772+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.192 seconds
[2025-09-11T07:56:42.103+0000] {processor.py:161} INFO - Started process (PID=107) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:56:42.112+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:56:42.120+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:56:42.117+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:56:42.814+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:56:42.786+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
ModuleNotFoundError: No module named 'snowflake.snowpark'
[2025-09-11T07:56:42.825+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:56:43.028+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.969 seconds
[2025-09-11T07:57:20.488+0000] {processor.py:161} INFO - Started process (PID=142) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:57:20.495+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:57:20.502+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:57:20.500+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:57:21.249+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:57:21.222+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
ModuleNotFoundError: No module named 'snowflake.snowpark'
[2025-09-11T07:57:21.259+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:57:21.514+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.070 seconds
[2025-09-11T07:58:07.345+0000] {processor.py:161} INFO - Started process (PID=154) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:58:07.351+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:58:07.357+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:58:07.355+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:58:08.144+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:58:08.118+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
ModuleNotFoundError: No module named 'snowflake.snowpark'
[2025-09-11T07:58:08.152+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:58:08.357+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.082 seconds
[2025-09-11T07:58:49.479+0000] {processor.py:161} INFO - Started process (PID=166) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:58:49.483+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:58:49.488+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:58:49.486+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:58:50.670+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:58:50.428+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
ModuleNotFoundError: No module named 'snowflake.snowpark'
[2025-09-11T07:58:50.721+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:58:51.279+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.869 seconds
[2025-09-11T07:59:32.044+0000] {processor.py:161} INFO - Started process (PID=178) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:59:32.058+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T07:59:32.062+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:59:32.060+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:59:32.519+0000] {logging_mixin.py:188} INFO - [2025-09-11T07:59:32.503+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T07:59:32.522+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T07:59:32.895+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.944 seconds
[2025-09-11T08:00:07.918+0000] {processor.py:161} INFO - Started process (PID=191) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:00:07.979+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:00:07.985+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:00:07.983+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:00:09.100+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:00:09.045+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:00:09.109+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:00:09.449+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.662 seconds
[2025-09-11T08:01:00.859+0000] {processor.py:161} INFO - Started process (PID=214) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:01:00.871+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:01:00.888+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:01:00.884+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:01:01.747+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:01:01.704+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:01:01.754+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:01:02.066+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.306 seconds
[2025-09-11T08:01:43.644+0000] {processor.py:161} INFO - Started process (PID=231) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:01:43.647+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:01:43.651+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:01:43.650+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:01:44.288+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:01:44.254+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:01:44.293+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:01:44.505+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.892 seconds
[2025-09-11T08:02:18.640+0000] {processor.py:161} INFO - Started process (PID=244) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:02:18.645+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:02:18.652+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:02:18.649+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:02:19.373+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:02:19.339+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:02:19.380+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:02:19.616+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.045 seconds
[2025-09-11T08:03:10.282+0000] {processor.py:161} INFO - Started process (PID=265) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:03:10.287+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:03:10.291+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:03:10.289+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:03:10.699+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:03:10.672+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:03:10.702+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:03:10.817+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.581 seconds
[2025-09-11T08:03:53.715+0000] {processor.py:161} INFO - Started process (PID=277) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:03:53.722+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:03:53.728+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:03:53.726+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:03:55.544+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:03:55.502+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:03:55.550+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:03:56.137+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.479 seconds
[2025-09-11T08:04:43.143+0000] {processor.py:161} INFO - Started process (PID=289) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:04:43.150+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:04:43.156+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:04:43.154+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:04:43.878+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:04:43.848+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:04:43.882+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:04:44.074+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.011 seconds
[2025-09-11T08:05:19.919+0000] {processor.py:161} INFO - Started process (PID=301) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:05:19.921+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:05:19.924+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:05:19.923+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:05:20.174+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:05:20.163+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:05:20.176+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:05:20.253+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.364 seconds
[2025-09-11T08:05:58.701+0000] {processor.py:161} INFO - Started process (PID=312) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:05:58.710+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:05:58.718+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:05:58.715+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:05:59.410+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:05:59.378+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:05:59.415+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:05:59.637+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.072 seconds
[2025-09-11T08:06:41.590+0000] {processor.py:161} INFO - Started process (PID=325) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:06:41.595+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:06:41.600+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:06:41.598+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:06:42.237+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:06:42.217+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:06:42.241+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:06:42.421+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.928 seconds
[2025-09-11T08:07:51.839+0000] {processor.py:161} INFO - Started process (PID=338) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:07:51.846+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:07:51.852+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:07:51.850+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:07:53.044+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:07:52.943+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:07:53.061+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:07:53.743+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.018 seconds
[2025-09-11T08:08:38.331+0000] {processor.py:161} INFO - Started process (PID=351) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:08:38.339+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:08:38.347+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:08:38.344+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:08:39.705+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:08:39.672+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:08:39.715+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:08:39.883+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.636 seconds
[2025-09-11T08:09:14.423+0000] {processor.py:161} INFO - Started process (PID=363) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:09:14.431+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:09:14.439+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:09:14.436+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:09:15.074+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:09:15.042+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:09:15.078+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:09:15.301+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.982 seconds
[2025-09-11T08:10:02.474+0000] {processor.py:161} INFO - Started process (PID=377) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:10:02.480+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:10:02.486+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:10:02.483+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:10:03.089+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:10:03.059+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:10:03.094+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:10:04.174+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.761 seconds
[2025-09-11T08:10:39.419+0000] {processor.py:161} INFO - Started process (PID=389) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:10:39.425+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:10:39.435+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:10:39.431+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:10:41.292+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:10:41.251+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:10:41.296+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:10:41.544+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.225 seconds
[2025-09-11T08:11:21.599+0000] {processor.py:161} INFO - Started process (PID=402) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:11:21.604+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:11:21.610+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:11:21.608+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:11:23.016+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:11:22.984+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:11:23.020+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:11:23.187+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.642 seconds
[2025-09-11T08:12:05.177+0000] {processor.py:161} INFO - Started process (PID=416) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:12:05.183+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:12:05.189+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:12:05.186+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:12:06.566+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:12:06.537+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:12:06.570+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:12:06.737+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.625 seconds
[2025-09-11T08:12:45.749+0000] {processor.py:161} INFO - Started process (PID=430) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:12:45.754+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:12:45.760+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:12:45.758+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:12:47.496+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:12:47.467+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:12:47.500+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:12:47.656+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.961 seconds
[2025-09-11T08:13:27.615+0000] {processor.py:161} INFO - Started process (PID=443) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:13:27.622+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:13:27.628+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:13:27.625+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:13:29.210+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:13:29.178+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:13:29.220+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:13:29.389+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.835 seconds
[2025-09-11T08:14:15.178+0000] {processor.py:161} INFO - Started process (PID=456) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:14:15.188+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:14:15.200+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:14:15.193+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:14:17.488+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:14:17.461+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:14:17.493+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:14:17.717+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.612 seconds
[2025-09-11T08:14:52.550+0000] {processor.py:161} INFO - Started process (PID=468) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:14:52.555+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:14:52.560+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:14:52.558+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:14:53.867+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:14:53.840+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:14:53.871+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:14:54.039+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.535 seconds
[2025-09-11T08:15:33.646+0000] {processor.py:161} INFO - Started process (PID=480) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:15:33.651+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:15:33.656+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:15:33.654+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:15:35.120+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:15:35.094+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:15:35.124+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:15:35.293+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.697 seconds
[2025-09-11T08:16:07.588+0000] {processor.py:161} INFO - Started process (PID=492) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:16:07.606+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:16:07.627+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:16:07.612+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:16:09.040+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:16:09.008+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:16:09.044+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:16:09.229+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.822 seconds
[2025-09-11T08:16:53.409+0000] {processor.py:161} INFO - Started process (PID=504) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:16:53.416+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:16:53.421+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:16:53.419+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:16:54.902+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:16:54.873+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:16:54.906+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:16:55.076+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.731 seconds
[2025-09-11T08:17:34.744+0000] {processor.py:161} INFO - Started process (PID=518) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:17:34.750+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:17:34.756+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:17:34.753+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:17:36.039+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:17:36.013+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:17:36.043+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:17:36.206+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.511 seconds
[2025-09-11T08:18:18.683+0000] {processor.py:161} INFO - Started process (PID=531) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:18:18.687+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:18:18.690+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:18:18.689+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:18:20.399+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:18:20.382+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:18:20.403+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:18:20.530+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.923 seconds
[2025-09-11T08:19:07.322+0000] {processor.py:161} INFO - Started process (PID=545) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:19:07.337+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:19:07.350+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:19:07.346+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:19:08.222+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:19:08.177+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:19:08.231+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:19:08.545+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.427 seconds
[2025-09-11T08:19:54.681+0000] {processor.py:161} INFO - Started process (PID=557) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:19:54.687+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:19:54.693+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:19:54.691+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:19:55.326+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:19:55.295+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:19:55.330+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:19:55.523+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.904 seconds
[2025-09-11T08:20:27.332+0000] {processor.py:161} INFO - Started process (PID=569) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:20:27.338+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:20:27.345+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:20:27.342+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:20:28.103+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:20:28.072+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:20:28.108+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:20:28.290+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.052 seconds
[2025-09-11T08:21:03.593+0000] {processor.py:161} INFO - Started process (PID=582) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:21:03.601+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:21:03.609+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:21:03.606+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:21:04.232+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:21:04.205+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:21:04.236+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:21:04.416+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.027 seconds
[2025-09-11T08:21:40.005+0000] {processor.py:161} INFO - Started process (PID=594) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:21:40.012+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:21:40.019+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:21:40.016+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:21:40.678+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:21:40.647+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:21:40.682+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:21:40.900+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.965 seconds
[2025-09-11T08:22:23.132+0000] {processor.py:161} INFO - Started process (PID=606) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:22:23.137+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:22:23.143+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:22:23.141+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:22:23.754+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:22:23.723+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:22:23.758+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:22:23.934+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.854 seconds
[2025-09-11T08:22:55.041+0000] {processor.py:161} INFO - Started process (PID=618) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:22:55.050+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:22:55.058+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:22:55.055+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:22:55.898+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:22:55.861+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:22:55.906+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:22:56.175+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.215 seconds
[2025-09-11T08:23:30.135+0000] {processor.py:161} INFO - Started process (PID=630) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:23:30.143+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:23:30.149+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:23:30.146+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:23:31.197+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:23:31.163+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:23:31.201+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:23:31.403+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.330 seconds
[2025-09-11T08:24:09.031+0000] {processor.py:161} INFO - Started process (PID=642) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:24:09.046+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:24:09.067+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:24:09.053+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:24:09.858+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:24:09.832+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:24:09.868+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:24:10.087+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.202 seconds
[2025-09-11T08:24:49.382+0000] {processor.py:161} INFO - Started process (PID=653) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:24:49.390+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:24:49.398+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:24:49.395+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:24:50.048+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:24:50.022+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:24:50.053+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:24:50.239+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.918 seconds
[2025-09-11T08:25:24.313+0000] {processor.py:161} INFO - Started process (PID=665) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:25:24.318+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:25:24.323+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:25:24.321+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:25:24.908+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:25:24.881+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:25:24.912+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:25:25.084+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.827 seconds
[2025-09-11T08:25:56.717+0000] {processor.py:161} INFO - Started process (PID=677) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:25:56.722+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:25:56.727+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:25:56.725+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:25:57.282+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:25:57.255+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:25:57.286+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:25:57.469+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.802 seconds
[2025-09-11T08:26:30.549+0000] {processor.py:161} INFO - Started process (PID=689) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:26:30.554+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:26:30.559+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:26:30.557+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:26:31.115+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:26:31.087+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:26:31.119+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:26:31.297+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.805 seconds
[2025-09-11T08:27:18.212+0000] {processor.py:161} INFO - Started process (PID=703) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:27:18.218+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:27:18.223+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:27:18.221+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:27:18.816+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:27:18.788+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:27:18.820+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:27:18.994+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.835 seconds
[2025-09-11T08:27:56.112+0000] {processor.py:161} INFO - Started process (PID=715) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:27:56.120+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:27:56.127+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:27:56.124+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:27:56.712+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:27:56.689+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:27:56.716+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:27:56.996+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.969 seconds
[2025-09-11T08:28:49.928+0000] {processor.py:161} INFO - Started process (PID=729) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:28:49.940+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:28:49.950+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:28:49.947+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:28:51.098+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:28:51.053+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:28:51.103+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:28:51.352+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.557 seconds
[2025-09-11T08:29:35.825+0000] {processor.py:161} INFO - Started process (PID=741) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:29:35.833+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:29:35.842+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:29:35.838+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:29:36.883+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:29:36.841+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:29:36.889+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:29:37.177+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.440 seconds
[2025-09-11T08:30:19.886+0000] {processor.py:161} INFO - Started process (PID=752) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:30:19.890+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:30:19.893+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:30:19.892+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:30:21.153+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:30:21.099+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:30:21.161+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:30:21.475+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.619 seconds
[2025-09-11T08:31:08.978+0000] {processor.py:161} INFO - Started process (PID=765) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:31:08.985+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:31:08.993+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:31:08.989+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:31:09.737+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:31:09.684+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:31:09.743+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:31:10.174+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.356 seconds
[2025-09-11T08:32:01.223+0000] {processor.py:161} INFO - Started process (PID=778) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:32:01.232+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:32:01.243+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:32:01.240+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:32:02.610+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:32:02.550+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:32:02.616+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:32:02.859+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.763 seconds
[2025-09-11T08:32:52.168+0000] {processor.py:161} INFO - Started process (PID=791) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:32:52.180+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:32:52.192+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:32:52.188+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:32:53.046+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:32:53.011+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:32:53.056+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:32:53.305+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.275 seconds
[2025-09-11T08:33:43.178+0000] {processor.py:161} INFO - Started process (PID=805) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:33:43.186+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:33:43.199+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:33:43.197+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:33:44.094+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:33:44.043+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:33:44.102+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:33:44.523+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.416 seconds
[2025-09-11T08:34:24.881+0000] {processor.py:161} INFO - Started process (PID=817) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:34:24.895+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:34:24.906+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:34:24.902+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:34:25.851+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:34:25.806+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:34:25.856+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:34:26.198+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.412 seconds
[2025-09-11T08:35:16.931+0000] {processor.py:161} INFO - Started process (PID=831) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:35:16.944+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:35:16.959+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:35:16.954+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:35:18.200+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:35:18.144+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:35:18.212+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:35:18.556+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.757 seconds
[2025-09-11T08:36:04.864+0000] {processor.py:161} INFO - Started process (PID=845) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:36:04.872+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:36:04.878+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:36:04.876+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:36:05.768+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:36:05.718+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:36:05.776+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:36:06.147+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.353 seconds
[2025-09-11T08:36:49.262+0000] {processor.py:161} INFO - Started process (PID=857) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:36:49.278+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:36:49.300+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:36:49.293+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:36:50.655+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:36:50.598+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:36:50.661+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:36:50.947+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.902 seconds
[2025-09-11T08:37:45.399+0000] {processor.py:161} INFO - Started process (PID=871) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:37:45.406+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:37:45.419+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:37:45.414+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:37:46.720+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:37:46.681+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:37:46.726+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:37:46.995+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.667 seconds
[2025-09-11T08:38:35.894+0000] {processor.py:161} INFO - Started process (PID=884) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:38:35.910+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:38:35.930+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:38:35.924+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:38:36.995+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:38:36.952+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:38:37.001+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:38:37.270+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.681 seconds
[2025-09-11T08:39:22.675+0000] {processor.py:161} INFO - Started process (PID=896) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:39:22.684+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:39:22.693+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:39:22.690+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:39:23.546+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:39:23.513+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:39:23.551+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:39:23.849+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.311 seconds
[2025-09-11T08:40:15.741+0000] {processor.py:161} INFO - Started process (PID=910) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:40:15.749+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:40:15.757+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:40:15.754+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:40:16.740+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:40:16.697+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:40:16.746+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:40:16.952+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.315 seconds
[2025-09-11T08:40:52.846+0000] {processor.py:161} INFO - Started process (PID=922) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:40:52.851+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:40:52.861+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:40:52.858+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:40:53.615+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:40:53.589+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:40:53.620+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:40:53.885+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.104 seconds
[2025-09-11T08:41:26.235+0000] {processor.py:161} INFO - Started process (PID=934) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:41:26.244+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:41:26.253+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:41:26.249+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:41:27.042+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:41:27.004+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:41:27.046+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:41:27.247+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.192 seconds
[2025-09-11T08:41:58.410+0000] {processor.py:161} INFO - Started process (PID=945) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:41:58.422+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:41:58.430+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:41:58.427+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:41:59.731+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:41:59.661+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:41:59.737+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:42:00.028+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.724 seconds
[2025-09-11T08:42:33.402+0000] {processor.py:161} INFO - Started process (PID=957) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:42:33.409+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:42:33.416+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:42:33.413+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:42:34.132+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:42:34.098+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:42:34.141+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:42:34.347+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.024 seconds
[2025-09-11T08:43:09.231+0000] {processor.py:161} INFO - Started process (PID=969) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:43:09.238+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:43:09.243+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:43:09.241+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:43:09.636+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:43:09.621+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:43:09.646+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:43:09.765+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.585 seconds
[2025-09-11T08:43:42.916+0000] {processor.py:161} INFO - Started process (PID=981) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:43:42.922+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:43:42.930+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:43:42.926+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:43:43.571+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:43:43.537+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:43:43.576+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:43:43.754+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.920 seconds
[2025-09-11T08:44:20.279+0000] {processor.py:161} INFO - Started process (PID=993) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:44:20.288+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:44:20.299+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:44:20.295+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:44:21.232+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:44:21.195+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:44:21.237+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:44:21.516+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.306 seconds
[2025-09-11T08:45:04.011+0000] {processor.py:161} INFO - Started process (PID=1007) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:45:04.017+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:45:04.023+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:45:04.021+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:45:04.611+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:45:04.583+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:45:04.615+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:45:04.800+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.847 seconds
[2025-09-11T08:45:36.856+0000] {processor.py:161} INFO - Started process (PID=1019) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:45:36.868+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:45:36.874+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:45:36.872+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:45:37.592+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:45:37.559+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:45:37.596+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:45:37.787+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.010 seconds
[2025-09-11T08:46:12.602+0000] {processor.py:161} INFO - Started process (PID=1031) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:46:12.608+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:46:12.615+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:46:12.612+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:46:13.313+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:46:13.284+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:46:13.318+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:46:13.519+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.988 seconds
[2025-09-11T08:46:46.041+0000] {processor.py:161} INFO - Started process (PID=1043) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:46:46.048+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:46:46.054+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:46:46.051+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:46:46.676+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:46:46.647+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:46:46.680+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:46:46.863+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.878 seconds
[2025-09-11T08:47:19.623+0000] {processor.py:161} INFO - Started process (PID=1055) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:47:19.629+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:47:19.635+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:47:19.632+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:47:20.302+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:47:20.266+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:47:20.309+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:47:20.514+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.949 seconds
[2025-09-11T08:47:52.456+0000] {processor.py:161} INFO - Started process (PID=1067) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:47:52.461+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:47:52.466+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:47:52.464+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:47:53.080+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:47:53.049+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:47:53.085+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:47:53.309+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.906 seconds
[2025-09-11T08:48:29.591+0000] {processor.py:161} INFO - Started process (PID=1080) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:48:29.597+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:48:29.607+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:48:29.604+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:48:30.422+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:48:30.377+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:48:30.430+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:48:30.690+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.226 seconds
[2025-09-11T08:49:07.328+0000] {processor.py:161} INFO - Started process (PID=1092) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:49:07.333+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:49:07.339+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:49:07.337+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:49:07.965+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:49:07.932+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:49:07.969+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:49:08.165+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.894 seconds
[2025-09-11T08:49:57.932+0000] {processor.py:161} INFO - Started process (PID=1107) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:49:57.937+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:49:57.942+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:49:57.940+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:49:58.509+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:49:58.482+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:49:58.513+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:49:58.695+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.813 seconds
[2025-09-11T08:50:33.982+0000] {processor.py:161} INFO - Started process (PID=1119) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:50:33.987+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:50:33.993+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:50:33.991+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:50:34.600+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:50:34.570+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:50:34.605+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:50:34.804+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.887 seconds
[2025-09-11T08:51:08.331+0000] {processor.py:161} INFO - Started process (PID=1131) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:51:08.336+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:51:08.344+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:51:08.341+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:51:08.978+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:51:08.949+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:51:08.982+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:51:09.204+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.937 seconds
[2025-09-11T08:51:59.461+0000] {processor.py:161} INFO - Started process (PID=1144) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:51:59.467+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:51:59.476+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:51:59.470+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:52:00.607+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:52:00.588+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:52:00.621+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:52:01.001+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.611 seconds
[2025-09-11T08:52:45.371+0000] {processor.py:161} INFO - Started process (PID=1157) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:52:45.379+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:52:45.384+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:52:45.382+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:52:46.414+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:52:46.146+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:52:46.430+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:52:48.201+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.882 seconds
[2025-09-11T08:53:42.873+0000] {processor.py:161} INFO - Started process (PID=1169) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:53:42.909+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:53:42.931+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:53:42.927+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:53:44.091+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:53:44.062+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:53:44.095+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:53:44.399+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.882 seconds
[2025-09-11T08:54:18.418+0000] {processor.py:161} INFO - Started process (PID=1181) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:54:18.426+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:54:18.433+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:54:18.430+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:54:19.198+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:54:19.165+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:54:19.204+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:54:19.438+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.092 seconds
[2025-09-11T08:55:33.658+0000] {processor.py:161} INFO - Started process (PID=1198) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:55:33.668+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:55:33.672+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:55:33.670+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:55:34.229+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:55:34.210+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:55:34.234+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:55:37.118+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.533 seconds
[2025-09-11T08:56:32.545+0000] {processor.py:161} INFO - Started process (PID=1211) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:56:32.566+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:56:32.598+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:56:32.584+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:56:35.025+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:56:34.993+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:56:35.030+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:56:35.256+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.779 seconds
[2025-09-11T08:57:15.682+0000] {processor.py:161} INFO - Started process (PID=1223) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:57:15.695+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:57:15.702+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:57:15.698+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:57:16.421+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:57:16.400+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:57:16.424+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:57:16.584+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.053 seconds
[2025-09-11T08:58:06.619+0000] {processor.py:161} INFO - Started process (PID=1233) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:58:06.631+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:58:06.634+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:58:06.633+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:58:07.279+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:58:07.253+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:58:07.282+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:58:07.436+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.890 seconds
[2025-09-11T08:58:52.438+0000] {processor.py:161} INFO - Started process (PID=1246) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:58:52.447+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T08:58:52.457+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:58:52.451+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:58:53.495+0000] {logging_mixin.py:188} INFO - [2025-09-11T08:58:53.449+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T08:58:53.505+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T08:58:53.792+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.485 seconds
[2025-09-11T09:00:25.146+0000] {processor.py:161} INFO - Started process (PID=1261) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:00:25.152+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:00:25.159+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:00:25.158+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:00:25.615+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:00:25.592+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T09:00:25.626+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:00:25.798+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.707 seconds
[2025-09-11T09:04:07.302+0000] {processor.py:161} INFO - Started process (PID=1278) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:04:07.331+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:04:07.344+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:04:07.343+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:04:11.436+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:04:10.671+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T09:04:11.523+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:04:12.657+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.438 seconds
[2025-09-11T09:04:53.369+0000] {processor.py:161} INFO - Started process (PID=1290) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:04:53.383+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:04:53.387+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:04:53.385+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:04:54.440+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:04:54.315+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T09:04:54.443+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:04:54.689+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.410 seconds
[2025-09-11T09:05:37.113+0000] {processor.py:161} INFO - Started process (PID=1302) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:05:37.122+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:05:37.126+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:05:37.124+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:05:37.766+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:05:37.744+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T09:05:37.778+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:05:38.230+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.147 seconds
[2025-09-11T09:06:09.077+0000] {processor.py:161} INFO - Started process (PID=1314) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:06:09.090+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:06:09.098+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:06:09.095+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:06:10.437+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:06:10.375+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T09:06:10.442+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:06:11.582+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.705 seconds
[2025-09-11T09:06:57.114+0000] {processor.py:161} INFO - Started process (PID=1327) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:06:57.252+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:06:57.258+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:06:57.256+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:06:58.147+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:06:58.137+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T09:06:58.149+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:06:58.233+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.336 seconds
[2025-09-11T09:08:26.817+0000] {processor.py:161} INFO - Started process (PID=1341) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:08:26.821+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:08:26.824+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:08:26.823+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:08:27.372+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:08:27.338+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T09:08:27.375+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:08:27.525+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.755 seconds
[2025-09-11T09:08:58.863+0000] {processor.py:161} INFO - Started process (PID=1353) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:08:58.866+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:08:58.870+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:08:58.868+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:08:59.177+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:08:59.160+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T09:08:59.180+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:08:59.274+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.443 seconds
[2025-09-11T09:09:47.320+0000] {processor.py:161} INFO - Started process (PID=1366) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:09:47.333+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:09:47.337+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:09:47.336+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:09:48.023+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:09:47.997+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T09:09:48.028+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:09:48.221+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.968 seconds
[2025-09-11T09:10:43.541+0000] {processor.py:161} INFO - Started process (PID=1378) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:10:43.546+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:10:43.558+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:10:43.556+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:10:44.600+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:10:44.491+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T09:10:44.603+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:10:44.792+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.317 seconds
[2025-09-11T09:13:07.007+0000] {processor.py:161} INFO - Started process (PID=1390) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:13:07.011+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:13:07.016+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:13:07.015+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:13:07.815+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:13:07.754+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T09:13:07.818+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:13:08.040+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.109 seconds
[2025-09-11T09:14:11.580+0000] {processor.py:161} INFO - Started process (PID=1404) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:14:11.619+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:14:11.654+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:14:11.652+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:14:13.680+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:14:13.595+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T09:14:13.687+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:14:14.689+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.194 seconds
[2025-09-11T09:14:45.503+0000] {processor.py:161} INFO - Started process (PID=1416) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:14:45.507+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:14:45.510+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:14:45.509+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:14:45.979+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:14:45.959+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T09:14:45.982+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:14:46.107+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.657 seconds
[2025-09-11T09:15:20.303+0000] {processor.py:161} INFO - Started process (PID=1428) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:15:20.309+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:15:20.315+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:15:20.312+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:15:20.920+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:15:20.896+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T09:15:20.925+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:15:21.070+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.857 seconds
[2025-09-11T09:15:58.601+0000] {processor.py:161} INFO - Started process (PID=1441) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:15:58.610+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:15:58.619+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:15:58.615+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:15:59.551+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:15:59.519+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T09:15:59.555+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:15:59.760+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.292 seconds
[2025-09-11T09:16:31.929+0000] {processor.py:161} INFO - Started process (PID=1453) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:16:31.955+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:16:31.965+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:16:31.962+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:16:32.691+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:16:32.667+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T09:16:32.695+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:16:32.874+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.187 seconds
[2025-09-11T09:17:06.584+0000] {processor.py:161} INFO - Started process (PID=1464) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:17:06.589+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:17:06.596+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:17:06.593+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:17:07.321+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:17:07.288+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T09:17:07.325+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:17:07.551+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.043 seconds
[2025-09-11T09:17:40.941+0000] {processor.py:161} INFO - Started process (PID=1476) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:17:40.948+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:17:40.955+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:17:40.952+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:17:41.655+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:17:41.625+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T09:17:41.659+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:17:41.855+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.003 seconds
[2025-09-11T09:18:13.329+0000] {processor.py:161} INFO - Started process (PID=1487) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:18:13.343+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:18:13.347+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:18:13.345+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:18:13.672+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:18:13.657+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T09:18:13.674+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:18:13.772+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.532 seconds
[2025-09-11T09:18:49.631+0000] {processor.py:161} INFO - Started process (PID=1499) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:18:49.639+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:18:49.645+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:18:49.642+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:18:50.374+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:18:50.337+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T09:18:50.378+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:18:50.663+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.101 seconds
[2025-09-11T09:19:22.320+0000] {processor.py:161} INFO - Started process (PID=1511) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:19:22.331+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:19:22.338+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:19:22.335+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:19:23.043+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:19:23.006+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T09:19:23.050+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:19:23.272+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.039 seconds
[2025-09-11T09:20:01.879+0000] {processor.py:161} INFO - Started process (PID=1524) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:20:01.883+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:20:01.887+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:20:01.885+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:20:02.138+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:20:02.128+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T09:20:02.140+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:20:02.223+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.397 seconds
[2025-09-11T09:20:38.505+0000] {processor.py:161} INFO - Started process (PID=1536) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:20:38.512+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:20:38.519+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:20:38.516+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:20:39.719+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:20:39.684+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T09:20:39.724+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:20:39.941+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.506 seconds
[2025-09-11T09:21:14.682+0000] {processor.py:161} INFO - Started process (PID=1548) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:21:14.688+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:21:14.694+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:21:14.690+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:21:15.299+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:21:15.272+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T09:21:15.303+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:21:15.503+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.886 seconds
[2025-09-11T09:21:48.525+0000] {processor.py:161} INFO - Started process (PID=1560) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:21:48.532+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:21:48.539+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:21:48.536+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:21:49.679+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:21:49.645+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T09:21:49.684+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:21:49.894+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.442 seconds
[2025-09-11T09:22:25.134+0000] {processor.py:161} INFO - Started process (PID=1573) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:22:25.137+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:22:25.139+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:22:25.138+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:22:25.443+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:22:25.428+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T09:22:25.446+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:22:25.545+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.437 seconds
[2025-09-11T09:23:05.887+0000] {processor.py:161} INFO - Started process (PID=1585) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:23:05.894+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:23:05.898+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:23:05.896+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:23:06.362+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:23:06.341+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T09:23:06.365+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:23:06.518+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.680 seconds
[2025-09-11T09:23:41.780+0000] {processor.py:161} INFO - Started process (PID=1598) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:23:41.786+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:23:41.792+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:23:41.790+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:23:42.482+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:23:42.449+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T09:23:42.487+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:23:42.705+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.990 seconds
[2025-09-11T09:24:21.642+0000] {processor.py:161} INFO - Started process (PID=1610) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:24:21.646+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:24:21.650+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:24:21.648+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:24:22.006+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:24:21.988+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T09:24:22.008+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:24:22.122+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.513 seconds
[2025-09-11T09:25:04.737+0000] {processor.py:161} INFO - Started process (PID=1623) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:25:04.751+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:25:04.776+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:25:04.775+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:25:05.257+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:25:05.241+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T09:25:05.262+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:25:05.377+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.709 seconds
[2025-09-11T09:26:04.150+0000] {processor.py:161} INFO - Started process (PID=1637) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:26:04.160+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:26:04.168+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:26:04.165+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:26:05.019+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:26:04.978+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T09:26:05.027+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:26:05.254+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.372 seconds
[2025-09-11T09:26:44.317+0000] {processor.py:161} INFO - Started process (PID=1649) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:26:44.324+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:26:44.328+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:26:44.326+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:26:44.638+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:26:44.627+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T09:26:44.640+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:26:44.719+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.442 seconds
[2025-09-11T09:29:41.400+0000] {processor.py:161} INFO - Started process (PID=1704) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:29:41.415+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:29:41.433+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:29:41.422+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:29:41.878+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:29:41.877+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T09:29:43.677+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:29:44.163+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:29:44.162+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T09:29:44.219+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:29:44.219+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T09:29:44.417+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.037 seconds
[2025-09-11T09:30:27.749+0000] {processor.py:161} INFO - Started process (PID=1719) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:30:27.761+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:30:27.785+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:30:27.772+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:30:28.876+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:30:28.874+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T09:30:33.344+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:30:33.432+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:30:33.431+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T09:30:33.492+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:30:33.491+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T09:30:33.602+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.896 seconds
[2025-09-11T09:32:56.125+0000] {processor.py:161} INFO - Started process (PID=1780) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:32:56.138+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:32:56.153+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:32:56.151+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:32:56.669+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:32:56.667+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T09:32:57.593+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:32:57.681+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:32:57.681+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T09:32:57.706+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:32:57.706+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T09:32:58.665+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.583 seconds
[2025-09-11T09:33:38.422+0000] {processor.py:161} INFO - Started process (PID=1802) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:33:38.459+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:33:38.483+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:33:38.482+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:33:39.166+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:33:39.165+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T09:33:39.966+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:33:40.068+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:33:40.066+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T09:33:40.107+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:33:40.107+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T09:33:40.312+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.927 seconds
[2025-09-11T09:34:24.037+0000] {processor.py:161} INFO - Started process (PID=1817) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:34:24.040+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:34:24.050+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:34:24.048+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:34:24.473+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:34:24.472+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T09:34:25.615+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:34:25.674+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:34:25.674+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T09:34:25.703+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:34:25.703+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T09:34:26.552+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.551 seconds
[2025-09-11T09:35:11.158+0000] {processor.py:161} INFO - Started process (PID=1832) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:35:11.165+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:35:11.173+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:35:11.171+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:35:12.211+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:35:12.209+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T09:35:14.315+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:35:14.445+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:35:14.444+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T09:35:14.492+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:35:14.492+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T09:35:14.727+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.623 seconds
[2025-09-11T09:36:03.550+0000] {processor.py:161} INFO - Started process (PID=1847) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:36:03.563+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:36:03.587+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:36:03.584+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:36:04.619+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:36:04.616+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T09:36:08.920+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:36:08.992+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:36:08.992+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T09:36:09.020+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:36:09.019+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T09:36:09.169+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.666 seconds
[2025-09-11T09:36:46.772+0000] {processor.py:161} INFO - Started process (PID=1862) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:36:46.775+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:36:46.789+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:36:46.788+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:36:47.204+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:36:47.203+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T09:36:49.194+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:36:49.277+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:36:49.276+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T09:36:49.313+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:36:49.313+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T09:36:49.445+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.691 seconds
[2025-09-11T09:37:24.383+0000] {processor.py:161} INFO - Started process (PID=1877) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:37:24.387+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:37:24.393+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:37:24.392+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:37:24.682+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:37:24.681+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T09:37:27.268+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:37:27.444+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:37:27.442+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T09:37:27.522+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:37:27.521+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T09:37:27.885+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.525 seconds
[2025-09-11T09:38:08.853+0000] {processor.py:161} INFO - Started process (PID=1892) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:38:08.857+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:38:08.866+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:38:08.864+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:38:09.236+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:38:09.235+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T09:38:11.502+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:38:11.827+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:38:11.820+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T09:38:11.981+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:38:11.980+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T09:38:12.662+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.836 seconds
[2025-09-11T09:38:56.486+0000] {processor.py:161} INFO - Started process (PID=1907) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:38:56.490+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:38:56.498+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:38:56.496+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:38:56.814+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:38:56.813+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T09:38:58.740+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:38:58.889+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:38:58.887+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T09:38:58.964+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:38:58.963+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T09:38:59.332+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.875 seconds
[2025-09-11T09:39:41.759+0000] {processor.py:161} INFO - Started process (PID=1922) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:39:41.765+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:39:41.778+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:39:41.776+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:39:42.417+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:39:42.415+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T09:39:44.802+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:39:44.968+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:39:44.966+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T09:39:45.035+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:39:45.035+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T09:39:45.395+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.671 seconds
[2025-09-11T09:40:24.328+0000] {processor.py:161} INFO - Started process (PID=1937) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:40:24.335+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:40:24.351+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:40:24.349+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:40:24.988+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:40:24.987+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T09:40:27.293+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:40:27.451+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:40:27.449+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T09:40:27.517+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:40:27.517+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T09:40:27.945+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.668 seconds
[2025-09-11T09:41:07.734+0000] {processor.py:161} INFO - Started process (PID=1952) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:41:07.740+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:41:07.753+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:41:07.751+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:41:08.375+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:41:08.373+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T09:41:12.127+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:41:12.572+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:41:12.569+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T09:41:12.690+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:41:12.689+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T09:41:12.902+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.229 seconds
[2025-09-11T09:41:51.382+0000] {processor.py:161} INFO - Started process (PID=1967) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:41:51.390+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:41:51.400+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:41:51.399+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:41:52.085+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:41:52.083+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T09:41:53.725+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:41:53.890+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:41:53.888+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T09:41:53.957+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:41:53.957+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T09:41:54.375+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.029 seconds
[2025-09-11T09:42:43.451+0000] {processor.py:161} INFO - Started process (PID=1982) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:42:43.457+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:42:43.470+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:42:43.469+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:42:43.964+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:42:43.963+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T09:42:45.665+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:42:45.740+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:42:45.738+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T09:42:45.774+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:42:45.774+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T09:42:45.925+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.503 seconds
[2025-09-11T09:43:29.938+0000] {processor.py:161} INFO - Started process (PID=1997) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:43:29.943+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:43:29.952+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:43:29.950+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:43:30.483+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:43:30.481+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T09:43:32.231+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:43:32.323+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:43:32.322+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T09:43:32.361+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:43:32.360+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T09:43:32.555+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.639 seconds
[2025-09-11T09:44:15.092+0000] {processor.py:161} INFO - Started process (PID=2012) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:44:15.100+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:44:15.113+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:44:15.110+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:44:15.729+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:44:15.726+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T09:44:18.013+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:44:18.173+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:44:18.170+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T09:44:18.239+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:44:18.237+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T09:44:18.582+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.536 seconds
[2025-09-11T09:44:56.899+0000] {processor.py:161} INFO - Started process (PID=2027) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:44:56.902+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:44:56.907+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:44:56.906+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:44:57.158+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:44:57.157+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T09:44:58.126+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:44:58.291+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:44:58.289+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T09:44:58.357+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:44:58.356+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T09:44:58.667+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.788 seconds
[2025-09-11T09:45:42.666+0000] {processor.py:161} INFO - Started process (PID=2042) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:45:42.672+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:45:42.685+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:45:42.683+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:45:43.401+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:45:43.399+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T09:45:45.513+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:45:45.678+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:45:45.676+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T09:45:45.746+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:45:45.745+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T09:45:46.118+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.495 seconds
[2025-09-11T09:46:28.498+0000] {processor.py:161} INFO - Started process (PID=2057) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:46:28.504+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:46:28.518+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:46:28.516+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:46:29.118+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:46:29.117+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T09:46:31.839+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:46:31.977+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:46:31.975+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T09:46:32.052+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:46:32.050+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T09:46:32.380+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.924 seconds
[2025-09-11T09:47:13.684+0000] {processor.py:161} INFO - Started process (PID=2072) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:47:13.687+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:47:13.693+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:47:13.692+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:47:14.047+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:47:14.045+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T09:47:16.592+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:47:16.753+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:47:16.750+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T09:47:16.822+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:47:16.821+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T09:47:17.207+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.538 seconds
[2025-09-11T09:48:14.400+0000] {processor.py:161} INFO - Started process (PID=2091) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:48:14.404+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:48:14.412+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:48:14.410+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:48:14.827+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:48:14.826+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T09:48:15.962+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:48:16.043+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:48:16.042+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T09:48:16.081+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:48:16.080+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T09:48:16.336+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.965 seconds
[2025-09-11T09:48:59.692+0000] {processor.py:161} INFO - Started process (PID=2106) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:48:59.695+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:48:59.703+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:48:59.701+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:49:00.011+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:49:00.010+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T09:49:01.606+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:49:01.766+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:49:01.764+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T09:49:01.834+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:49:01.833+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T09:49:02.257+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.583 seconds
[2025-09-11T09:49:49.415+0000] {processor.py:161} INFO - Started process (PID=2123) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:49:49.423+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:49:49.437+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:49:49.435+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:49:50.084+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:49:50.082+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T09:49:52.611+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:49:52.748+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:49:52.746+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T09:49:52.806+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:49:52.805+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T09:49:53.201+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.834 seconds
[2025-09-11T09:50:39.842+0000] {processor.py:161} INFO - Started process (PID=2139) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:50:39.849+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:50:39.866+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:50:39.863+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:50:40.515+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:50:40.511+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T09:50:43.299+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:50:43.498+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:50:43.495+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T09:50:43.568+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:50:43.567+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T09:50:44.005+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.206 seconds
[2025-09-11T09:51:32.362+0000] {processor.py:161} INFO - Started process (PID=2156) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:51:32.369+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:51:32.382+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:51:32.380+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:51:32.960+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:51:32.954+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T09:51:35.225+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:51:35.367+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:51:35.365+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T09:51:35.483+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:51:35.482+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T09:51:35.860+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.538 seconds
[2025-09-11T09:52:29.730+0000] {processor.py:161} INFO - Started process (PID=2173) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:52:29.734+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:52:29.742+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:52:29.740+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:52:30.071+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:52:30.070+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T09:52:31.183+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:52:31.258+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:52:31.255+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T09:52:31.286+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:52:31.285+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T09:52:31.438+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.735 seconds
[2025-09-11T09:53:28.232+0000] {processor.py:161} INFO - Started process (PID=2192) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:53:28.239+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:53:28.251+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:53:28.249+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:53:28.867+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:53:28.865+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T09:53:32.233+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:53:32.405+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:53:32.403+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T09:53:32.497+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:53:32.496+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T09:53:32.866+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.670 seconds
[2025-09-11T09:54:16.551+0000] {processor.py:161} INFO - Started process (PID=2207) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:54:16.555+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:54:16.562+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:54:16.561+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:54:16.922+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:54:16.921+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T09:54:18.927+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:54:19.093+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:54:19.091+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T09:54:19.167+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:54:19.166+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T09:54:19.563+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.036 seconds
[2025-09-11T09:55:03.839+0000] {processor.py:161} INFO - Started process (PID=2222) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:55:03.856+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:55:03.894+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:55:03.891+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:55:04.947+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:55:04.943+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T09:55:07.987+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:55:08.080+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:55:08.079+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T09:55:08.119+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:55:08.119+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T09:55:08.315+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.513 seconds
[2025-09-11T09:55:47.641+0000] {processor.py:161} INFO - Started process (PID=2237) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:55:47.649+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:55:47.670+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:55:47.663+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:55:48.424+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:55:48.423+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T09:55:50.750+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:55:50.901+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:55:50.899+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T09:55:50.981+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:55:50.981+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T09:55:51.544+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.952 seconds
[2025-09-11T09:56:40.675+0000] {processor.py:161} INFO - Started process (PID=2253) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:56:40.678+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:56:40.685+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:56:40.684+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:56:41.033+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:56:41.031+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T09:56:42.370+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:56:42.504+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:56:42.502+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T09:56:42.575+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:56:42.575+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T09:56:43.555+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.898 seconds
[2025-09-11T09:57:29.731+0000] {processor.py:161} INFO - Started process (PID=2268) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:57:29.741+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:57:29.760+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:57:29.757+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:57:30.685+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:57:30.683+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T09:57:33.451+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:57:33.652+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:57:33.649+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T09:57:33.723+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:57:33.722+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T09:57:34.110+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.442 seconds
[2025-09-11T09:58:26.163+0000] {processor.py:161} INFO - Started process (PID=2286) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:58:26.169+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:58:26.182+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:58:26.180+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:58:26.829+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:58:26.827+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T09:58:28.924+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:58:29.108+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:58:29.106+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T09:58:29.194+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:58:29.193+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T09:58:29.695+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.575 seconds
[2025-09-11T09:59:17.010+0000] {processor.py:161} INFO - Started process (PID=2302) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:59:17.015+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T09:59:17.026+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:59:17.024+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:59:17.703+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:59:17.702+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T09:59:19.755+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T09:59:19.913+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:59:19.910+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T09:59:19.992+0000] {logging_mixin.py:188} INFO - [2025-09-11T09:59:19.991+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T09:59:20.352+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.375 seconds
[2025-09-11T10:00:13.279+0000] {processor.py:161} INFO - Started process (PID=2320) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:00:13.287+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:00:13.305+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:00:13.300+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:00:14.030+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:00:14.028+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:00:16.234+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:00:16.498+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:00:16.487+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:00:16.635+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:00:16.633+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:00:16.995+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.753 seconds
[2025-09-11T10:00:59.255+0000] {processor.py:161} INFO - Started process (PID=2335) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:00:59.260+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:00:59.268+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:00:59.267+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:00:59.741+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:00:59.740+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:01:01.990+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:01:02.125+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:01:02.123+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:01:02.173+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:01:02.172+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:01:02.356+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.127 seconds
[2025-09-11T10:01:39.523+0000] {processor.py:161} INFO - Started process (PID=2350) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:01:39.530+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:01:39.542+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:01:39.539+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:01:40.170+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:01:40.169+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:01:43.033+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:01:43.221+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:01:43.218+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:01:43.287+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:01:43.286+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:01:43.751+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.266 seconds
[2025-09-11T10:02:39.287+0000] {processor.py:161} INFO - Started process (PID=2369) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:02:39.290+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:02:39.305+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:02:39.304+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:02:39.721+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:02:39.720+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:02:40.543+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:02:40.599+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:02:40.598+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:02:40.622+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:02:40.622+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:02:40.755+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.515 seconds
[2025-09-11T10:03:27.853+0000] {processor.py:161} INFO - Started process (PID=2387) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:03:27.861+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:03:27.880+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:03:27.877+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:03:28.588+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:03:28.586+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:03:31.039+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:03:31.215+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:03:31.213+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:03:31.281+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:03:31.280+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:03:31.702+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.902 seconds
[2025-09-11T10:04:18.107+0000] {processor.py:161} INFO - Started process (PID=2402) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:04:18.112+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:04:18.122+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:04:18.121+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:04:18.581+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:04:18.579+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:04:19.780+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:04:20.620+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:04:19.944+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:04:20.683+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:04:20.682+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:04:21.042+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.966 seconds
[2025-09-11T10:05:08.856+0000] {processor.py:161} INFO - Started process (PID=2418) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:05:08.862+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:05:08.877+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:05:08.874+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:05:09.496+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:05:09.494+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:05:11.958+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:05:12.686+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:05:12.684+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:05:12.834+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:05:12.832+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:05:13.222+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.401 seconds
[2025-09-11T10:05:55.145+0000] {processor.py:161} INFO - Started process (PID=2433) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:05:55.149+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:05:55.166+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:05:55.164+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:05:55.542+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:05:55.540+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:05:57.912+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:05:58.083+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:05:58.081+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:05:58.815+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:05:58.814+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:05:59.197+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.113 seconds
[2025-09-11T10:06:45.579+0000] {processor.py:161} INFO - Started process (PID=2449) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:06:45.583+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:06:45.592+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:06:45.591+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:06:46.036+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:06:46.035+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:06:48.306+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:06:48.495+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:06:48.493+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:06:48.569+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:06:48.567+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:06:48.990+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.438 seconds
[2025-09-11T10:07:31.835+0000] {processor.py:161} INFO - Started process (PID=2464) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:07:31.841+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:07:31.851+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:07:31.849+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:07:32.530+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:07:32.528+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:07:34.264+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:07:34.358+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:07:34.356+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:07:34.401+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:07:34.400+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:07:34.578+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.773 seconds
[2025-09-11T10:08:26.615+0000] {processor.py:161} INFO - Started process (PID=2479) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:08:26.623+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:08:26.635+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:08:26.632+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:08:27.253+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:08:27.251+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:08:29.476+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:08:30.290+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:08:30.288+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:08:30.354+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:08:30.353+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:08:31.065+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.493 seconds
[2025-09-11T10:09:15.225+0000] {processor.py:161} INFO - Started process (PID=2494) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:09:15.230+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:09:15.241+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:09:15.238+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:09:15.638+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:09:15.636+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:09:18.164+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:09:18.316+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:09:18.314+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:09:18.379+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:09:18.378+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:09:18.770+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.580 seconds
[2025-09-11T10:10:02.438+0000] {processor.py:161} INFO - Started process (PID=2509) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:10:02.456+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:10:02.479+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:10:02.477+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:10:02.840+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:10:02.839+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:10:04.893+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:10:05.043+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:10:05.042+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:10:05.105+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:10:05.104+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:10:05.512+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.113 seconds
[2025-09-11T10:10:50.243+0000] {processor.py:161} INFO - Started process (PID=2524) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:10:50.252+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:10:50.277+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:10:50.273+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:10:50.993+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:10:50.991+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:10:54.274+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:10:54.446+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:10:54.444+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:10:54.505+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:10:54.504+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:10:54.850+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.654 seconds
[2025-09-11T10:11:38.246+0000] {processor.py:161} INFO - Started process (PID=2538) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:11:38.251+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:11:38.265+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:11:38.264+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:11:38.688+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:11:38.687+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:11:40.436+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:11:40.525+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:11:40.524+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:11:40.558+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:11:40.558+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:11:40.790+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.589 seconds
[2025-09-11T10:12:36.513+0000] {processor.py:161} INFO - Started process (PID=2557) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:12:36.520+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:12:36.534+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:12:36.531+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:12:37.164+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:12:37.161+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:12:39.505+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:12:40.314+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:12:40.312+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:12:40.371+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:12:40.370+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:12:40.730+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.281 seconds
[2025-09-11T10:13:36.005+0000] {processor.py:161} INFO - Started process (PID=2575) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:13:36.014+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:13:36.029+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:13:36.027+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:13:36.681+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:13:36.680+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:13:39.685+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:13:39.819+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:13:39.817+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:13:39.875+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:13:39.874+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:13:40.241+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.292 seconds
[2025-09-11T10:14:19.374+0000] {processor.py:161} INFO - Started process (PID=2590) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:14:19.377+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:14:19.383+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:14:19.382+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:14:19.658+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:14:19.657+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:14:21.292+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:14:21.353+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:14:21.352+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:14:21.381+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:14:21.380+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:14:21.539+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.181 seconds
[2025-09-11T10:15:05.548+0000] {processor.py:161} INFO - Started process (PID=2607) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:15:05.551+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:15:05.559+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:15:05.558+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:15:05.982+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:15:05.979+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:15:07.155+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:15:07.215+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:15:07.214+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:15:07.237+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:15:07.237+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:15:07.367+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.847 seconds
[2025-09-11T10:15:48.231+0000] {processor.py:161} INFO - Started process (PID=2622) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:15:48.239+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:15:48.253+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:15:48.250+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:15:48.873+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:15:48.871+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:15:51.907+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:15:52.047+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:15:52.045+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:15:52.111+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:15:52.110+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:15:52.543+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.349 seconds
[2025-09-11T10:16:37.975+0000] {processor.py:161} INFO - Started process (PID=2637) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:16:37.980+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:16:37.987+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:16:37.985+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:16:38.289+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:16:38.288+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:16:40.787+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:16:40.944+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:16:40.941+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:16:41.007+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:16:41.006+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:16:41.382+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.429 seconds
[2025-09-11T10:17:20.244+0000] {processor.py:161} INFO - Started process (PID=2652) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:17:20.252+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:17:20.266+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:17:20.264+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:17:20.895+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:17:20.893+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:17:24.183+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:17:24.306+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:17:24.303+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:17:24.361+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:17:24.360+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:17:24.708+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.513 seconds
[2025-09-11T10:18:17.639+0000] {processor.py:161} INFO - Started process (PID=2668) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:18:17.642+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:18:17.650+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:18:17.648+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:18:18.019+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:18:18.017+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:18:19.977+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:18:20.040+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:18:20.039+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:18:20.064+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:18:20.063+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:18:20.213+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.600 seconds
[2025-09-11T10:19:05.247+0000] {processor.py:161} INFO - Started process (PID=2683) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:19:05.252+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:19:05.261+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:19:05.260+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:19:05.679+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:19:05.678+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:19:07.863+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:19:08.007+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:19:08.006+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:19:08.063+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:19:08.062+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:19:08.464+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.244 seconds
[2025-09-11T10:20:05.651+0000] {processor.py:161} INFO - Started process (PID=2702) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:20:05.659+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:20:05.677+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:20:05.675+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:20:06.215+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:20:06.214+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:20:08.905+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:20:09.045+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:20:09.044+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:20:09.095+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:20:09.094+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:20:09.396+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.792 seconds
[2025-09-11T10:20:53.444+0000] {processor.py:161} INFO - Started process (PID=2717) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:20:53.452+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:20:53.469+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:20:53.466+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:20:54.101+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:20:54.098+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:20:57.453+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:20:57.556+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:20:57.554+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:20:57.595+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:20:57.595+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:20:57.838+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.434 seconds
[2025-09-11T10:21:42.129+0000] {processor.py:161} INFO - Started process (PID=2732) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:21:42.135+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:21:42.148+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:21:42.146+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:21:42.894+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:21:42.891+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:21:45.980+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:21:46.121+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:21:46.119+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:21:46.179+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:21:46.178+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:21:46.560+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.474 seconds
[2025-09-11T10:24:25.436+0000] {processor.py:161} INFO - Started process (PID=2786) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:24:25.451+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:24:25.467+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:24:25.464+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:24:26.161+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:24:26.160+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:24:27.362+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:24:27.473+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:24:27.472+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:24:27.514+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:24:27.513+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:24:27.699+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.322 seconds
[2025-09-11T10:25:38.353+0000] {processor.py:161} INFO - Started process (PID=2806) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:25:38.364+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:25:38.374+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:25:38.372+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:25:38.965+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:25:38.964+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:25:41.331+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:25:41.491+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:25:41.484+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:25:41.568+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:25:41.567+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:25:41.804+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.498 seconds
[2025-09-11T10:26:33.896+0000] {processor.py:161} INFO - Started process (PID=2824) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:26:33.900+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:26:33.908+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:26:33.907+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:26:34.284+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:26:34.283+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:26:36.799+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:26:36.971+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:26:36.969+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:26:37.042+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:26:37.041+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:26:37.461+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.586 seconds
[2025-09-11T10:27:30.076+0000] {processor.py:161} INFO - Started process (PID=2840) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:27:30.097+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:27:30.147+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:27:30.133+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:27:31.003+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:27:30.999+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:27:34.477+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:27:34.786+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:27:34.784+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:27:34.841+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:27:34.840+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:27:35.090+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.117 seconds
[2025-09-11T10:28:22.375+0000] {processor.py:161} INFO - Started process (PID=2855) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:28:22.429+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:28:22.479+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:28:22.470+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:28:25.443+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:28:25.442+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:28:27.486+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:28:27.569+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:28:27.568+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:28:27.602+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:28:27.602+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:28:27.764+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.568 seconds
[2025-09-11T10:29:19.421+0000] {processor.py:161} INFO - Started process (PID=2874) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:29:19.434+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:29:19.442+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:29:19.441+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:29:19.858+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:29:19.857+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:29:21.379+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:29:21.482+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:29:21.481+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:29:21.525+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:29:21.525+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:29:21.727+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.350 seconds
[2025-09-11T10:30:23.552+0000] {processor.py:161} INFO - Started process (PID=2893) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:30:23.580+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:30:23.649+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:30:23.645+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:30:24.825+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:30:24.823+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:30:27.224+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:30:27.350+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:30:27.349+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:30:27.401+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:30:27.401+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:30:27.636+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.241 seconds
[2025-09-11T10:31:04.685+0000] {processor.py:161} INFO - Started process (PID=2908) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:31:04.687+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:31:04.692+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:31:04.691+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:31:04.964+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:31:04.963+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:31:06.310+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:31:06.387+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:31:06.386+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:31:06.432+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:31:06.431+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:31:06.581+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.914 seconds
[2025-09-11T10:32:16.417+0000] {processor.py:161} INFO - Started process (PID=2929) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:32:16.429+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:32:16.446+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:32:16.438+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:32:17.297+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:32:17.296+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:32:20.882+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:32:21.042+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:32:21.041+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:32:21.118+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:32:21.112+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:32:21.324+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.946 seconds
[2025-09-11T10:33:22.980+0000] {processor.py:161} INFO - Started process (PID=2945) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:33:22.984+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:33:22.993+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:33:22.991+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:33:23.492+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:33:23.491+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:33:25.235+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:33:25.329+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:33:25.327+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:33:25.361+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:33:25.361+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:33:25.512+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.558 seconds
[2025-09-11T10:34:09.579+0000] {processor.py:161} INFO - Started process (PID=2960) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:34:09.585+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:34:09.599+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:34:09.596+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:34:10.455+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:34:10.452+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:34:14.637+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:34:14.709+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:34:14.709+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:34:14.742+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:34:14.742+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:34:14.899+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.360 seconds
[2025-09-11T10:34:59.625+0000] {processor.py:161} INFO - Started process (PID=2976) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:34:59.634+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:34:59.654+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:34:59.651+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:35:00.563+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:35:00.559+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:35:03.983+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:35:04.199+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:35:04.197+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:35:05.429+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:35:05.428+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:35:05.630+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 6.056 seconds
[2025-09-11T10:35:55.087+0000] {processor.py:161} INFO - Started process (PID=2993) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:35:55.090+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:35:55.103+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:35:55.102+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:35:55.694+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:35:55.693+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:35:57.033+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:35:57.112+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:35:57.111+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:35:57.142+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:35:57.142+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:35:57.277+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.227 seconds
[2025-09-11T10:36:44.037+0000] {processor.py:161} INFO - Started process (PID=3009) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:36:44.049+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:36:44.078+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:36:44.076+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:36:45.101+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:36:45.099+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:36:46.980+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:36:47.068+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:36:47.067+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:36:47.103+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:36:47.102+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:36:47.251+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.273 seconds
[2025-09-11T10:37:23.867+0000] {processor.py:161} INFO - Started process (PID=3024) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:37:23.885+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:37:23.910+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:37:23.907+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:37:24.956+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:37:24.954+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:37:27.889+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:37:28.753+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:37:28.752+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:37:28.805+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:37:28.805+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:37:29.061+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.366 seconds
[2025-09-11T10:38:22.505+0000] {processor.py:161} INFO - Started process (PID=3044) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:38:22.522+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:38:22.541+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:38:22.539+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:38:23.264+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:38:23.263+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:38:24.463+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:38:24.536+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:38:24.534+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:38:24.571+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:38:24.570+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:38:24.701+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.279 seconds
[2025-09-11T10:39:13.409+0000] {processor.py:161} INFO - Started process (PID=3060) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:39:13.413+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:39:13.428+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:39:13.426+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:39:13.800+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:39:13.799+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:39:15.095+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:39:15.632+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:39:15.631+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:39:15.663+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:39:15.663+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:39:16.146+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.774 seconds
[2025-09-11T10:40:02.243+0000] {processor.py:161} INFO - Started process (PID=3075) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:40:02.248+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:40:02.266+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:40:02.255+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:40:03.070+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:40:03.069+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:40:04.388+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:40:04.507+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:40:04.506+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:40:04.569+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:40:04.568+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:40:04.812+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.606 seconds
[2025-09-11T10:40:53.377+0000] {processor.py:161} INFO - Started process (PID=3091) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:40:53.385+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:40:53.403+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:40:53.401+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:40:54.232+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:40:54.230+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:40:57.955+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:40:58.067+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:40:58.062+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:40:58.677+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:40:58.676+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:40:58.837+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.518 seconds
[2025-09-11T10:41:58.777+0000] {processor.py:161} INFO - Started process (PID=3110) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:41:58.786+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:41:58.803+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:41:58.800+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:42:00.081+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:42:00.068+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:42:03.881+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:42:03.987+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:42:03.985+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:42:04.033+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:42:04.032+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:42:04.219+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.496 seconds
[2025-09-11T10:43:02.094+0000] {processor.py:161} INFO - Started process (PID=3130) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:43:02.100+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:43:02.113+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:43:02.111+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:43:02.737+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:43:02.735+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:43:06.065+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:43:06.276+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:43:06.270+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:43:07.267+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:43:07.266+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:43:07.582+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.531 seconds
[2025-09-11T10:44:16.249+0000] {processor.py:161} INFO - Started process (PID=3150) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:44:16.256+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:44:16.269+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:44:16.266+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:44:16.956+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:44:16.954+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:44:19.963+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:44:20.101+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:44:20.099+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:44:20.166+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:44:20.165+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:44:20.521+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.308 seconds
[2025-09-11T10:45:07.589+0000] {processor.py:161} INFO - Started process (PID=3166) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:45:07.595+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:45:07.605+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:45:07.603+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:45:08.048+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:45:08.046+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:45:09.697+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:45:09.843+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:45:09.842+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:45:09.910+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:45:09.909+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:45:10.259+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.703 seconds
[2025-09-11T10:45:52.951+0000] {processor.py:161} INFO - Started process (PID=3181) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:45:52.958+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:45:52.970+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:45:52.968+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:45:53.606+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:45:53.604+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:45:56.588+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:45:57.593+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:45:57.591+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:45:57.645+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:45:57.644+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:45:58.090+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.179 seconds
[2025-09-11T10:46:41.519+0000] {processor.py:161} INFO - Started process (PID=3196) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:46:41.522+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:46:41.527+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:46:41.526+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:46:41.727+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:46:41.726+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:46:43.752+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:46:43.896+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:46:43.894+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:46:43.957+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:46:43.956+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:46:44.372+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.872 seconds
[2025-09-11T10:47:29.956+0000] {processor.py:161} INFO - Started process (PID=3211) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:47:29.962+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:47:29.976+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:47:29.973+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:47:30.631+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:47:30.627+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:47:33.497+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:47:33.641+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:47:33.635+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:47:33.699+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:47:33.697+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:47:34.109+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.197 seconds
[2025-09-11T10:48:18.527+0000] {processor.py:161} INFO - Started process (PID=3227) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:48:18.534+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:48:18.546+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:48:18.544+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:48:19.248+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:48:19.244+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:48:21.923+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:48:22.064+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:48:22.062+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:48:22.123+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:48:22.121+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:48:22.517+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.028 seconds
[2025-09-11T10:49:10.759+0000] {processor.py:161} INFO - Started process (PID=3242) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:49:10.770+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:49:10.785+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:49:10.782+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:49:11.378+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:49:11.376+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:49:14.730+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:49:14.865+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:49:14.862+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:49:14.924+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:49:14.924+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:49:15.333+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.643 seconds
[2025-09-11T10:50:00.201+0000] {processor.py:161} INFO - Started process (PID=3258) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:50:00.207+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:50:00.221+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:50:00.218+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:50:00.861+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:50:00.859+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:50:03.879+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:50:04.034+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:50:04.032+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:50:04.118+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:50:04.117+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:50:04.488+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.337 seconds
[2025-09-11T10:50:43.880+0000] {processor.py:161} INFO - Started process (PID=3272) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:50:43.885+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:50:43.894+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:50:43.893+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:50:44.353+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:50:44.351+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:50:46.241+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:50:46.407+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:50:46.394+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:50:46.484+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:50:46.483+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:50:46.844+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.988 seconds
[2025-09-11T10:51:29.506+0000] {processor.py:161} INFO - Started process (PID=3287) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:51:29.510+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:51:29.516+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:51:29.515+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:51:29.831+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:51:29.829+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:51:31.645+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:51:31.885+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:51:31.882+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:51:31.985+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:51:31.984+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:51:32.344+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.861 seconds
[2025-09-11T10:52:17.420+0000] {processor.py:161} INFO - Started process (PID=3302) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:52:17.427+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:52:17.440+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:52:17.437+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:52:18.067+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:52:18.065+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:52:21.100+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:52:21.236+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:52:21.234+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:52:21.294+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:52:21.293+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:52:21.652+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.268 seconds
[2025-09-11T10:53:05.517+0000] {processor.py:161} INFO - Started process (PID=3317) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:53:05.525+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:53:05.545+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:53:05.542+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:53:06.283+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:53:06.281+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:53:09.165+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:53:09.310+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:53:09.302+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:53:09.359+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:53:09.358+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:53:09.673+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.223 seconds
[2025-09-11T10:53:54.369+0000] {processor.py:161} INFO - Started process (PID=3332) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:53:54.374+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:53:54.383+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:53:54.381+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:53:54.988+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:53:54.986+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:53:57.299+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:53:57.382+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:53:57.381+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:53:57.413+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:53:57.412+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:53:57.573+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.229 seconds
[2025-09-11T10:54:48.583+0000] {processor.py:161} INFO - Started process (PID=3351) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:54:48.586+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:54:48.591+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:54:48.590+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:54:48.861+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:54:48.860+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:54:51.037+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:54:51.100+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:54:51.096+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:54:51.130+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:54:51.129+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:54:51.424+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.866 seconds
[2025-09-11T10:55:28.581+0000] {processor.py:161} INFO - Started process (PID=3368) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:55:28.596+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:55:28.624+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:55:28.613+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:55:30.378+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:55:30.367+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:55:33.655+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:55:33.723+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:55:33.722+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:55:33.752+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:55:33.752+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:55:33.878+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.372 seconds
[2025-09-11T10:58:46.115+0000] {processor.py:161} INFO - Started process (PID=3460) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:58:46.120+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:58:46.128+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:58:46.126+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:58:46.568+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:58:46.567+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:58:48.579+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:58:48.647+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:58:48.646+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:58:48.672+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:58:48.672+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:58:48.825+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.743 seconds
[2025-09-11T10:59:31.014+0000] {processor.py:161} INFO - Started process (PID=3475) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:59:31.017+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T10:59:31.030+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:59:31.028+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:59:31.412+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:59:31.410+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T10:59:33.400+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T10:59:33.476+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:59:33.475+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T10:59:33.497+0000] {logging_mixin.py:188} INFO - [2025-09-11T10:59:33.497+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T10:59:33.640+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.663 seconds
[2025-09-11T11:00:23.190+0000] {processor.py:161} INFO - Started process (PID=3491) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:00:23.198+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:00:23.205+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:00:23.204+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:00:23.939+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:00:23.938+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T11:00:27.674+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:00:27.737+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:00:27.736+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T11:00:27.758+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:00:27.758+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T11:00:27.895+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.732 seconds
[2025-09-11T11:01:05.281+0000] {processor.py:161} INFO - Started process (PID=3506) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:01:05.283+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:01:05.289+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:01:05.288+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:01:05.625+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:01:05.624+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T11:01:07.703+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:01:07.837+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:01:07.833+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T11:01:07.867+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:01:07.866+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T11:01:08.036+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.772 seconds
[2025-09-11T11:02:08.675+0000] {processor.py:161} INFO - Started process (PID=3525) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:02:08.685+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:02:08.716+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:02:08.705+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:02:09.942+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:02:09.939+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T11:02:12.616+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:02:12.765+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:02:12.764+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T11:02:12.797+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:02:12.797+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T11:02:13.041+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.439 seconds
[2025-09-11T11:02:54.998+0000] {processor.py:161} INFO - Started process (PID=3540) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:02:55.002+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:02:55.018+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:02:55.017+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:02:55.341+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:02:55.340+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T11:02:57.109+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:02:57.168+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:02:57.167+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T11:02:57.244+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:02:57.244+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T11:02:57.470+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.504 seconds
[2025-09-11T11:03:56.701+0000] {processor.py:161} INFO - Started process (PID=3558) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:03:56.708+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:03:56.722+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:03:56.719+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:03:57.491+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:03:57.488+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T11:04:00.467+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:04:00.606+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:04:00.605+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T11:04:00.667+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:04:00.667+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T11:04:01.080+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.421 seconds
[2025-09-11T11:04:41.780+0000] {processor.py:161} INFO - Started process (PID=3573) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:04:41.784+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:04:41.797+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:04:41.795+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:04:42.331+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:04:42.329+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T11:04:44.928+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:04:44.981+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:04:44.980+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T11:04:45.004+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:04:45.003+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T11:04:45.133+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.379 seconds
[2025-09-11T11:05:29.512+0000] {processor.py:161} INFO - Started process (PID=3588) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:05:29.524+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:05:29.539+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:05:29.536+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:05:30.176+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:05:30.174+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T11:05:33.051+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:05:33.194+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:05:33.193+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T11:05:33.256+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:05:33.255+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T11:05:33.616+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.158 seconds
[2025-09-11T11:06:45.806+0000] {processor.py:161} INFO - Started process (PID=3609) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:06:45.810+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:06:45.826+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:06:45.825+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:06:47.391+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:06:47.390+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T11:06:51.555+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:06:51.904+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:06:51.903+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T11:06:52.527+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:06:52.527+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T11:06:53.861+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 8.115 seconds
[2025-09-11T11:07:34.080+0000] {processor.py:161} INFO - Started process (PID=3625) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:07:34.091+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:07:34.099+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:07:34.097+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:07:34.437+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:07:34.436+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T11:07:35.641+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:07:35.700+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:07:35.700+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T11:07:35.727+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:07:35.727+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T11:07:35.868+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.821 seconds
[2025-09-11T11:08:26.649+0000] {processor.py:161} INFO - Started process (PID=3640) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:08:26.656+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:08:26.668+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:08:26.666+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:08:27.616+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:08:27.614+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T11:08:30.784+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:08:30.943+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:08:30.941+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T11:08:31.014+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:08:31.013+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T11:08:31.549+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.947 seconds
[2025-09-11T11:09:19.355+0000] {processor.py:161} INFO - Started process (PID=3657) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:09:19.362+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:09:19.376+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:09:19.374+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:09:20.925+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:09:20.922+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T11:09:23.170+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:09:23.319+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:09:23.317+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T11:09:23.379+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:09:23.378+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T11:09:23.867+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.547 seconds
[2025-09-11T11:10:05.820+0000] {processor.py:161} INFO - Started process (PID=3672) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:10:05.827+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:10:05.840+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:10:05.837+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:10:06.389+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:10:06.388+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T11:10:08.778+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:10:08.880+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:10:08.879+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T11:10:08.908+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:10:08.907+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T11:10:09.046+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.265 seconds
[2025-09-11T11:10:44.231+0000] {processor.py:161} INFO - Started process (PID=3688) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:10:44.234+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:10:44.240+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:10:44.239+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:10:44.930+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:10:44.930+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T11:10:45.930+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:10:45.996+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:10:45.996+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T11:10:46.024+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:10:46.024+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T11:10:46.180+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.968 seconds
[2025-09-11T11:11:16.690+0000] {processor.py:161} INFO - Started process (PID=3703) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:11:16.692+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:11:16.697+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:11:16.696+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:11:17.432+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:11:17.431+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T11:11:18.430+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:11:18.500+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:11:18.499+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T11:11:18.525+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:11:18.525+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T11:11:18.660+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.988 seconds
[2025-09-11T11:11:54.988+0000] {processor.py:161} INFO - Started process (PID=3718) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:11:54.993+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:11:55.003+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:11:55.001+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:11:55.377+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:11:55.374+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T11:11:58.248+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:11:58.349+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:11:58.347+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T11:11:58.383+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:11:58.383+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T11:11:58.525+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.569 seconds
[2025-09-11T11:13:08.549+0000] {processor.py:161} INFO - Started process (PID=3739) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:13:08.551+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:13:08.557+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:13:08.556+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:13:09.319+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:13:09.318+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T11:13:10.907+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:13:11.294+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:13:11.291+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T11:13:11.487+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:13:11.485+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T11:13:12.053+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.523 seconds
[2025-09-11T11:13:57.781+0000] {processor.py:161} INFO - Started process (PID=3755) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:13:57.788+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:13:57.801+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:13:57.798+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:13:59.959+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:13:59.956+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T11:14:03.155+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:14:03.314+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:14:03.311+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T11:14:03.372+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:14:03.371+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T11:14:03.671+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.932 seconds
[2025-09-11T11:15:16.791+0000] {processor.py:161} INFO - Started process (PID=3774) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:15:16.797+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:15:16.810+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:15:16.808+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:15:18.813+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:15:18.810+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T11:15:21.712+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:15:21.878+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:15:21.875+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T11:15:21.937+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:15:21.937+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T11:15:22.255+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.500 seconds
[2025-09-11T11:16:12.015+0000] {processor.py:161} INFO - Started process (PID=3789) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:16:12.024+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:16:12.040+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:16:12.037+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:16:14.503+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:16:14.500+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T11:16:16.699+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:16:16.831+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:16:16.830+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T11:16:16.881+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:16:16.880+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T11:16:17.177+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.204 seconds
[2025-09-11T11:17:29.704+0000] {processor.py:161} INFO - Started process (PID=3809) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:17:29.716+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:17:29.732+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:17:29.731+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:17:31.585+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:17:31.574+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T11:17:37.672+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:17:38.264+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:17:38.263+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T11:17:38.476+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:17:38.476+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T11:17:39.146+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 9.486 seconds
[2025-09-11T11:22:47.677+0000] {processor.py:161} INFO - Started process (PID=94) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:22:47.681+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:22:47.684+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:22:47.683+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:22:48.027+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:22:48.010+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
ModuleNotFoundError: No module named 'snowflake.snowpark'
[2025-09-11T11:22:48.031+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:22:48.110+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.458 seconds
[2025-09-11T11:23:23.608+0000] {processor.py:161} INFO - Started process (PID=108) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:23:23.615+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:23:23.621+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:23:23.619+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:23:24.402+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:23:24.348+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
ModuleNotFoundError: No module named 'snowflake.snowpark'
[2025-09-11T11:23:24.413+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:23:24.670+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.106 seconds
[2025-09-11T11:24:15.702+0000] {processor.py:161} INFO - Started process (PID=145) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:24:15.742+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:24:15.768+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:24:15.755+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:24:17.668+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:24:17.601+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
ModuleNotFoundError: No module named 'snowflake.snowpark'
[2025-09-11T11:24:17.686+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:24:18.719+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.439 seconds
[2025-09-11T11:25:03.601+0000] {processor.py:161} INFO - Started process (PID=157) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:25:03.607+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:25:03.617+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:25:03.613+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:25:04.322+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:25:04.293+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
ModuleNotFoundError: No module named 'snowflake.snowpark'
[2025-09-11T11:25:04.332+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:25:04.558+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.030 seconds
[2025-09-11T11:25:46.224+0000] {processor.py:161} INFO - Started process (PID=169) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:25:46.232+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:25:46.241+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:25:46.237+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:25:46.979+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:25:46.947+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T11:25:46.984+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:25:47.199+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.050 seconds
[2025-09-11T11:27:15.558+0000] {processor.py:161} INFO - Started process (PID=200) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:27:15.571+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:27:15.580+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:27:15.577+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:27:16.575+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:27:16.541+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T11:27:16.579+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:27:16.853+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.404 seconds
[2025-09-11T11:28:07.193+0000] {processor.py:161} INFO - Started process (PID=217) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:28:07.199+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:28:07.206+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:28:07.203+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:28:07.937+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:28:07.902+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T11:28:07.942+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:28:08.140+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.007 seconds
[2025-09-11T11:28:45.743+0000] {processor.py:161} INFO - Started process (PID=229) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:28:45.751+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:28:45.758+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:28:45.756+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:28:46.541+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:28:46.505+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T11:28:46.546+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:28:46.751+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.078 seconds
[2025-09-11T11:29:24.408+0000] {processor.py:161} INFO - Started process (PID=242) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:29:24.417+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:29:24.427+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:29:24.423+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:29:25.067+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:29:25.035+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T11:29:25.072+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:29:25.265+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.939 seconds
[2025-09-11T11:29:59.749+0000] {processor.py:161} INFO - Started process (PID=254) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:29:59.755+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:29:59.761+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:29:59.758+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:30:00.454+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:30:00.418+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T11:30:00.460+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:30:00.656+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.968 seconds
[2025-09-11T11:30:37.819+0000] {processor.py:161} INFO - Started process (PID=267) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:30:37.826+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:30:37.837+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:30:37.832+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:30:38.845+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:30:38.803+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T11:30:38.850+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:30:39.092+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.374 seconds
[2025-09-11T11:31:15.196+0000] {processor.py:161} INFO - Started process (PID=279) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:31:15.202+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:31:15.208+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:31:15.205+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:31:15.871+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:31:15.839+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T11:31:15.876+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:31:16.070+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.942 seconds
[2025-09-11T11:31:54.793+0000] {processor.py:161} INFO - Started process (PID=291) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:31:54.799+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:31:54.804+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:31:54.802+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:31:55.707+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:31:55.679+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T11:31:55.712+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:31:55.919+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.201 seconds
[2025-09-11T11:32:28.831+0000] {processor.py:161} INFO - Started process (PID=303) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:32:28.837+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:32:28.843+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:32:28.841+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:32:29.467+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:32:29.436+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T11:32:29.472+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:32:29.684+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.911 seconds
[2025-09-11T11:33:05.751+0000] {processor.py:161} INFO - Started process (PID=316) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:33:05.757+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:33:05.763+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:33:05.761+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:33:06.402+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:33:06.370+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T11:33:06.406+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:33:06.626+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.937 seconds
[2025-09-11T11:33:40.505+0000] {processor.py:161} INFO - Started process (PID=328) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:33:40.512+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:33:40.522+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:33:40.517+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:33:41.907+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:33:41.875+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T11:33:41.913+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:33:42.130+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.772 seconds
[2025-09-11T11:34:21.721+0000] {processor.py:161} INFO - Started process (PID=341) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:34:21.726+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:34:21.733+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:34:21.730+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:34:22.273+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:34:22.248+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T11:34:22.277+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:34:22.470+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.821 seconds
[2025-09-11T11:34:54.823+0000] {processor.py:161} INFO - Started process (PID=353) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:34:54.832+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:34:54.840+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:34:54.837+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:34:56.527+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:34:56.496+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T11:34:56.532+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:34:56.714+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.983 seconds
[2025-09-11T11:35:56.918+0000] {processor.py:161} INFO - Started process (PID=369) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:35:56.926+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:35:56.931+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:35:56.929+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:35:58.325+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:35:58.294+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T11:35:58.329+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:35:58.651+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.806 seconds
[2025-09-11T11:36:36.371+0000] {processor.py:161} INFO - Started process (PID=381) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:36:36.378+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:36:36.385+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:36:36.383+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:36:38.469+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:36:38.433+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T11:36:38.476+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:36:38.653+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.351 seconds
[2025-09-11T11:37:19.296+0000] {processor.py:161} INFO - Started process (PID=394) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:37:19.302+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:37:19.308+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:37:19.306+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:37:20.846+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:37:20.815+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T11:37:20.850+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:37:21.037+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.803 seconds
[2025-09-11T11:37:57.919+0000] {processor.py:161} INFO - Started process (PID=406) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:37:57.925+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:37:57.930+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:37:57.928+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:37:59.555+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:37:59.526+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T11:37:59.559+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:37:59.772+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.918 seconds
[2025-09-11T11:38:53.947+0000] {processor.py:161} INFO - Started process (PID=419) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:38:53.955+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:38:53.962+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:38:53.960+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:38:55.793+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:38:55.770+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T11:38:55.796+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:38:56.836+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.100 seconds
[2025-09-11T11:39:32.134+0000] {processor.py:161} INFO - Started process (PID=431) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:39:32.140+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:39:32.144+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:39:32.143+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:39:33.707+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:39:33.675+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T11:39:33.711+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:39:33.897+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.834 seconds
[2025-09-11T11:40:16.050+0000] {processor.py:161} INFO - Started process (PID=444) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:40:16.056+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:40:16.062+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:40:16.060+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:40:17.417+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:40:17.390+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T11:40:17.422+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:40:17.595+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.603 seconds
[2025-09-11T11:40:54.067+0000] {processor.py:161} INFO - Started process (PID=456) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:40:54.072+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:40:54.078+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:40:54.076+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:40:55.706+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:40:55.679+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T11:40:55.710+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:40:55.880+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.871 seconds
[2025-09-11T11:41:30.992+0000] {processor.py:161} INFO - Started process (PID=468) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:41:30.997+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:41:31.003+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:41:31.001+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:41:32.544+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:41:32.516+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T11:41:32.548+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:41:32.710+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.784 seconds
[2025-09-11T11:42:13.588+0000] {processor.py:161} INFO - Started process (PID=480) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:42:13.594+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:42:13.599+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:42:13.597+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:42:14.870+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:42:14.847+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T11:42:14.873+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:42:15.014+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.485 seconds
[2025-09-11T11:42:50.462+0000] {processor.py:161} INFO - Started process (PID=492) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:42:50.468+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:42:50.475+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:42:50.472+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:42:52.196+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:42:52.165+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T11:42:52.201+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:42:52.422+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.043 seconds
[2025-09-11T11:43:34.532+0000] {processor.py:161} INFO - Started process (PID=505) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:43:34.539+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:43:34.547+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:43:34.544+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:43:35.879+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:43:35.852+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T11:43:35.883+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:43:36.044+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.579 seconds
[2025-09-11T11:44:26.038+0000] {processor.py:161} INFO - Started process (PID=519) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:44:26.044+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:44:26.050+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:44:26.047+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:44:26.699+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:44:26.672+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T11:44:26.703+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:44:26.888+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.912 seconds
[2025-09-11T11:45:04.119+0000] {processor.py:161} INFO - Started process (PID=532) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:45:04.125+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:45:04.131+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:45:04.129+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:45:04.758+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:45:04.729+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T11:45:04.763+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:45:05.060+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.004 seconds
[2025-09-11T11:45:41.010+0000] {processor.py:161} INFO - Started process (PID=545) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:45:41.018+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:45:41.024+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:45:41.022+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:45:41.684+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:45:41.650+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T11:45:41.693+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:45:41.939+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.989 seconds
[2025-09-11T11:46:15.835+0000] {processor.py:161} INFO - Started process (PID=557) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:46:15.841+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:46:15.847+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:46:15.844+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:46:16.511+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:46:16.479+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T11:46:16.516+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:46:16.705+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.932 seconds
[2025-09-11T11:46:49.904+0000] {processor.py:161} INFO - Started process (PID=569) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:46:49.910+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:46:49.916+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:46:49.914+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:46:50.795+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:46:50.761+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T11:46:50.799+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:46:50.997+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.159 seconds
[2025-09-11T11:47:27.461+0000] {processor.py:161} INFO - Started process (PID=581) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:47:27.467+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:47:27.473+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:47:27.471+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:47:28.371+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:47:28.335+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T11:47:28.377+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:47:28.574+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.174 seconds
[2025-09-11T11:48:04.609+0000] {processor.py:161} INFO - Started process (PID=594) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:48:04.614+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:48:04.621+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:48:04.618+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:48:05.214+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:48:05.185+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T11:48:05.219+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:48:05.439+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.888 seconds
[2025-09-11T11:48:37.916+0000] {processor.py:161} INFO - Started process (PID=606) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:48:37.923+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:48:37.931+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:48:37.927+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:48:38.598+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:48:38.565+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T11:48:38.603+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:48:38.796+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.960 seconds
[2025-09-11T11:49:15.067+0000] {processor.py:161} INFO - Started process (PID=619) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:49:15.073+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:49:15.079+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:49:15.076+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:49:15.808+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:49:15.775+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T11:49:15.812+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:49:16.011+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.014 seconds
[2025-09-11T11:49:48.707+0000] {processor.py:161} INFO - Started process (PID=631) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:49:48.713+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:49:48.719+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:49:48.716+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:49:49.358+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:49:49.326+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T11:49:49.363+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:49:49.548+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.903 seconds
[2025-09-11T11:50:22.506+0000] {processor.py:161} INFO - Started process (PID=643) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:50:22.512+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:50:22.518+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:50:22.516+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:50:23.121+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:50:23.091+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T11:50:23.126+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:50:23.324+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.889 seconds
[2025-09-11T11:50:55.882+0000] {processor.py:161} INFO - Started process (PID=655) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:50:55.888+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:50:55.894+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:50:55.891+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:50:56.638+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:50:56.605+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T11:50:56.642+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:50:56.840+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.018 seconds
[2025-09-11T11:51:30.700+0000] {processor.py:161} INFO - Started process (PID=667) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:51:30.708+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:51:30.717+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:51:30.714+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:51:31.626+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:51:31.589+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T11:51:31.635+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:51:31.974+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.355 seconds
[2025-09-11T11:52:18.352+0000] {processor.py:161} INFO - Started process (PID=681) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:52:18.359+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:52:18.366+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:52:18.362+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:52:19.210+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:52:19.177+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T11:52:19.215+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:52:19.415+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.140 seconds
[2025-09-11T11:52:51.438+0000] {processor.py:161} INFO - Started process (PID=693) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:52:51.445+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:52:51.457+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:52:51.450+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:52:52.143+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:52:52.106+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T11:52:52.147+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:52:52.518+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.163 seconds
[2025-09-11T11:53:24.393+0000] {processor.py:161} INFO - Started process (PID=705) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:53:24.399+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:53:24.405+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:53:24.403+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:53:25.030+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:53:25.002+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T11:53:25.035+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:53:25.229+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.892 seconds
[2025-09-11T11:54:01.853+0000] {processor.py:161} INFO - Started process (PID=718) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:54:01.858+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:54:01.864+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:54:01.862+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:54:02.767+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:54:02.735+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T11:54:02.771+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:54:02.977+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.194 seconds
[2025-09-11T11:54:36.595+0000] {processor.py:161} INFO - Started process (PID=730) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:54:36.601+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:54:36.607+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:54:36.605+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:54:37.236+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:54:37.204+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T11:54:37.241+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:54:37.439+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.904 seconds
[2025-09-11T11:55:11.791+0000] {processor.py:161} INFO - Started process (PID=742) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:55:11.798+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:55:11.804+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:55:11.801+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:55:12.759+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:55:12.706+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T11:55:12.768+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:55:13.103+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.373 seconds
[2025-09-11T11:55:45.421+0000] {processor.py:161} INFO - Started process (PID=754) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:55:45.427+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:55:45.434+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:55:45.431+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:55:46.084+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:55:46.050+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T11:55:46.088+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:55:46.379+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.035 seconds
[2025-09-11T11:56:20.389+0000] {processor.py:161} INFO - Started process (PID=766) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:56:20.396+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:56:20.404+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:56:20.400+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:56:21.076+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:56:21.045+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T11:56:21.080+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:56:21.275+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.029 seconds
[2025-09-11T11:56:57.162+0000] {processor.py:161} INFO - Started process (PID=779) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:56:57.168+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:56:57.175+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:56:57.172+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:56:57.928+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:56:57.895+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T11:56:57.932+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:56:58.126+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.027 seconds
[2025-09-11T11:57:37.978+0000] {processor.py:161} INFO - Started process (PID=792) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:57:37.984+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:57:37.990+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:57:37.988+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:57:38.626+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:57:38.594+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T11:57:38.630+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:57:38.820+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.902 seconds
[2025-09-11T11:58:16.095+0000] {processor.py:161} INFO - Started process (PID=805) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:58:16.100+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:58:16.106+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:58:16.104+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:58:16.757+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:58:16.728+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T11:58:16.761+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:58:17.045+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.003 seconds
[2025-09-11T11:58:47.913+0000] {processor.py:161} INFO - Started process (PID=817) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:58:47.918+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:58:47.925+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:58:47.922+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:58:48.555+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:58:48.522+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T11:58:48.560+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:58:48.756+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.905 seconds
[2025-09-11T11:59:28.792+0000] {processor.py:161} INFO - Started process (PID=831) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:59:28.797+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T11:59:28.802+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:59:28.800+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:59:29.409+0000] {logging_mixin.py:188} INFO - [2025-09-11T11:59:29.380+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T11:59:29.413+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T11:59:29.700+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.966 seconds
[2025-09-11T12:00:02.643+0000] {processor.py:161} INFO - Started process (PID=843) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:00:02.650+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:00:02.657+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:00:02.654+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:00:03.434+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:00:03.403+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T12:00:03.439+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:00:03.636+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.075 seconds
[2025-09-11T12:00:37.519+0000] {processor.py:161} INFO - Started process (PID=855) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:00:37.526+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:00:37.531+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:00:37.529+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:00:38.278+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:00:38.244+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T12:00:38.282+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:00:38.575+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.114 seconds
[2025-09-11T12:01:11.420+0000] {processor.py:161} INFO - Started process (PID=867) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:01:11.434+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:01:11.446+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:01:11.443+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:01:12.233+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:01:12.202+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T12:01:12.238+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:01:12.436+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.085 seconds
[2025-09-11T12:01:52.252+0000] {processor.py:161} INFO - Started process (PID=880) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:01:52.257+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:01:52.264+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:01:52.261+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:01:53.397+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:01:53.367+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T12:01:53.401+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:01:53.599+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.407 seconds
[2025-09-11T12:02:29.340+0000] {processor.py:161} INFO - Started process (PID=893) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:02:29.345+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:02:29.351+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:02:29.349+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:02:29.994+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:02:29.962+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T12:02:29.998+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:02:30.246+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.966 seconds
[2025-09-11T12:03:02.601+0000] {processor.py:161} INFO - Started process (PID=905) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:03:02.619+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:03:02.630+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:03:02.626+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:03:03.635+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:03:03.603+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T12:03:03.640+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:03:03.839+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.359 seconds
[2025-09-11T12:03:36.870+0000] {processor.py:161} INFO - Started process (PID=917) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:03:36.875+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:03:36.881+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:03:36.879+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:03:37.509+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:03:37.478+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T12:03:37.513+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:03:37.719+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.904 seconds
[2025-09-11T12:04:11.461+0000] {processor.py:161} INFO - Started process (PID=929) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:04:11.476+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:04:11.490+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:04:11.483+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:04:12.149+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:04:12.114+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T12:04:12.154+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:04:12.453+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.085 seconds
[2025-09-11T12:04:53.363+0000] {processor.py:161} INFO - Started process (PID=942) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:04:53.369+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:04:53.374+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:04:53.372+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:04:54.069+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:04:54.028+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T12:04:54.084+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:04:54.389+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.104 seconds
[2025-09-11T12:05:25.939+0000] {processor.py:161} INFO - Started process (PID=954) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:05:25.945+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:05:25.951+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:05:25.948+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:05:26.602+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:05:26.571+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T12:05:26.607+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:05:26.799+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.922 seconds
[2025-09-11T12:06:00.563+0000] {processor.py:161} INFO - Started process (PID=966) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:06:00.569+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:06:00.575+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:06:00.573+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:06:01.226+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:06:01.193+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T12:06:01.231+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:06:01.455+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.958 seconds
[2025-09-11T12:06:34.038+0000] {processor.py:161} INFO - Started process (PID=978) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:06:34.045+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:06:34.051+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:06:34.049+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:06:34.726+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:06:34.695+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T12:06:34.731+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:06:34.973+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.002 seconds
[2025-09-11T12:07:13.735+0000] {processor.py:161} INFO - Started process (PID=991) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:07:13.741+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:07:13.747+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:07:13.744+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:07:14.437+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:07:14.377+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T12:07:14.443+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:07:14.667+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.993 seconds
[2025-09-11T12:07:46.426+0000] {processor.py:161} INFO - Started process (PID=1003) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:07:46.434+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:07:46.442+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:07:46.439+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:07:47.017+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:07:46.987+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T12:07:47.022+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:07:47.230+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.862 seconds
[2025-09-11T12:08:21.973+0000] {processor.py:161} INFO - Started process (PID=1015) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:08:21.979+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:08:21.985+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:08:21.983+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:08:22.622+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:08:22.590+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T12:08:22.627+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:08:22.822+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.911 seconds
[2025-09-11T12:08:54.768+0000] {processor.py:161} INFO - Started process (PID=1027) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:08:54.773+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:08:54.779+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:08:54.777+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:08:55.469+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:08:55.436+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T12:08:55.474+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:08:55.667+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.956 seconds
[2025-09-11T12:09:37.189+0000] {processor.py:161} INFO - Started process (PID=1040) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:09:37.196+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:09:37.203+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:09:37.199+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:09:38.169+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:09:38.111+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T12:09:38.183+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:09:38.610+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.500 seconds
[2025-09-11T12:11:50.338+0000] {processor.py:161} INFO - Started process (PID=76) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:11:50.344+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:11:50.358+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:11:50.355+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:11:51.011+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:11:50.984+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
ModuleNotFoundError: No module named 'snowflake.snowpark'
[2025-09-11T12:11:51.021+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:11:51.250+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.949 seconds
[2025-09-11T12:12:30.837+0000] {processor.py:161} INFO - Started process (PID=109) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:12:30.845+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:12:30.862+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:12:30.859+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:12:31.524+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:12:31.506+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
ModuleNotFoundError: No module named 'snowflake.snowpark'
[2025-09-11T12:12:31.533+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:12:31.686+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.889 seconds
[2025-09-11T12:13:08.522+0000] {processor.py:161} INFO - Started process (PID=137) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:13:08.525+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:13:08.530+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:13:08.529+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:13:08.831+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:13:08.822+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
ModuleNotFoundError: No module named 'snowflake.snowpark'
[2025-09-11T12:13:08.835+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:13:08.918+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.419 seconds
[2025-09-11T12:13:44.301+0000] {processor.py:161} INFO - Started process (PID=157) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:13:44.307+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:13:44.321+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:13:44.319+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:13:45.083+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:13:45.028+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
ModuleNotFoundError: No module named 'snowflake.snowpark'
[2025-09-11T12:13:45.095+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:13:45.351+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.138 seconds
[2025-09-11T12:14:18.203+0000] {processor.py:161} INFO - Started process (PID=169) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:14:18.211+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:14:18.231+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:14:18.226+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:14:18.921+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:14:18.892+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
ModuleNotFoundError: No module named 'snowflake.snowpark'
[2025-09-11T12:14:18.932+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:14:19.163+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.056 seconds
[2025-09-11T12:14:52.501+0000] {processor.py:161} INFO - Started process (PID=181) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:14:52.507+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:14:52.523+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:14:52.520+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:14:53.562+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:14:53.527+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T12:14:53.569+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:14:53.792+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.363 seconds
[2025-09-11T12:15:29.632+0000] {processor.py:161} INFO - Started process (PID=194) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:15:29.637+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:15:29.650+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:15:29.648+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:15:30.358+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:15:30.327+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T12:15:30.364+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:15:30.582+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.026 seconds
[2025-09-11T12:16:22.452+0000] {processor.py:161} INFO - Started process (PID=216) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:16:22.458+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:16:22.474+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:16:22.471+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:16:23.348+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:16:23.267+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T12:16:23.355+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:16:23.629+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.244 seconds
[2025-09-11T12:17:17.113+0000] {processor.py:161} INFO - Started process (PID=235) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:17:17.123+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:17:17.130+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:17:17.127+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:17:17.864+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:17:17.821+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T12:17:17.870+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:17:18.192+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.169 seconds
[2025-09-11T12:17:58.781+0000] {processor.py:161} INFO - Started process (PID=248) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:17:58.787+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:17:58.794+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:17:58.792+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:17:59.360+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:17:59.337+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T12:17:59.366+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:17:59.505+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.836 seconds
[2025-09-11T12:18:34.089+0000] {processor.py:161} INFO - Started process (PID=270) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:18:34.095+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:18:34.101+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:18:34.099+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:18:35.050+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:18:35.018+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T12:18:35.054+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:18:35.254+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.232 seconds
[2025-09-11T12:19:09.309+0000] {processor.py:161} INFO - Started process (PID=282) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:19:09.315+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:19:09.321+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:19:09.319+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:19:09.921+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:19:09.889+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T12:19:09.925+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:19:10.126+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.882 seconds
[2025-09-11T12:19:42.164+0000] {processor.py:161} INFO - Started process (PID=294) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:19:42.170+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:19:42.183+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:19:42.180+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:19:43.209+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:19:43.168+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T12:19:43.214+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:19:43.546+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.513 seconds
[2025-09-11T12:20:17.986+0000] {processor.py:161} INFO - Started process (PID=306) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:20:17.992+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:20:17.997+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:20:17.995+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:20:18.522+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:20:18.495+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T12:20:18.526+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:20:18.788+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.973 seconds
[2025-09-11T12:20:52.011+0000] {processor.py:161} INFO - Started process (PID=318) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:20:52.016+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:20:52.021+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:20:52.020+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:20:52.611+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:20:52.583+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T12:20:52.615+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:20:52.796+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.833 seconds
[2025-09-11T12:21:32.480+0000] {processor.py:161} INFO - Started process (PID=331) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:21:32.485+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:21:32.490+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:21:32.488+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:21:33.031+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:21:33.000+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T12:21:33.036+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:21:33.213+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.790 seconds
[2025-09-11T12:22:09.271+0000] {processor.py:161} INFO - Started process (PID=344) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:22:09.278+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:22:09.293+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:22:09.290+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:22:10.687+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:22:10.658+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T12:22:10.691+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:22:10.859+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.673 seconds
[2025-09-11T12:22:44.187+0000] {processor.py:161} INFO - Started process (PID=356) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:22:44.192+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:22:44.197+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:22:44.195+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:22:44.798+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:22:44.767+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T12:22:44.809+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:22:44.994+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.857 seconds
[2025-09-11T12:23:18.993+0000] {processor.py:161} INFO - Started process (PID=368) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:23:18.999+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:23:19.004+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:23:19.002+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:23:20.336+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:23:20.307+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T12:23:20.341+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:23:20.512+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.579 seconds
[2025-09-11T12:23:58.651+0000] {processor.py:161} INFO - Started process (PID=381) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:23:58.657+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:23:58.665+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:23:58.662+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:24:00.339+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:24:00.311+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T12:24:00.343+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:24:00.518+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.923 seconds
[2025-09-11T12:24:39.598+0000] {processor.py:161} INFO - Started process (PID=394) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:24:39.604+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:24:39.609+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:24:39.607+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:24:40.865+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:24:40.833+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T12:24:40.870+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:24:41.046+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.505 seconds
[2025-09-11T12:25:19.523+0000] {processor.py:161} INFO - Started process (PID=406) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:25:19.529+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:25:19.534+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:25:19.532+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:25:21.109+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:25:21.077+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T12:25:21.113+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:25:21.273+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.805 seconds
[2025-09-11T12:25:55.546+0000] {processor.py:161} INFO - Started process (PID=418) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:25:55.563+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:25:55.570+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:25:55.567+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:25:57.105+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:25:57.073+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T12:25:57.109+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:25:57.285+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.816 seconds
[2025-09-11T12:26:37.395+0000] {processor.py:161} INFO - Started process (PID=431) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:26:37.401+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:26:37.406+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:26:37.404+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:26:39.300+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:26:39.257+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T12:26:39.306+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:26:39.566+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.228 seconds
[2025-09-11T12:27:19.204+0000] {processor.py:161} INFO - Started process (PID=443) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:27:19.208+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:27:19.213+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:27:19.212+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:27:20.430+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:27:20.402+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T12:27:20.434+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:27:20.593+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.442 seconds
[2025-09-11T12:28:07.740+0000] {processor.py:161} INFO - Started process (PID=457) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:28:07.751+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:28:07.756+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:28:07.754+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:28:08.919+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:28:08.892+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T12:28:08.923+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:28:09.079+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.388 seconds
[2025-09-11T12:28:51.519+0000] {processor.py:161} INFO - Started process (PID=470) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:28:51.524+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:28:51.528+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:28:51.527+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:28:52.057+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:28:52.028+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T12:28:52.062+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:28:52.219+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.633 seconds
[2025-09-11T12:29:29.955+0000] {processor.py:161} INFO - Started process (PID=482) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:29:29.961+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:29:29.967+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:29:29.965+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:29:30.729+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:29:30.699+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T12:29:30.733+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:29:30.915+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.017 seconds
[2025-09-11T12:30:02.963+0000] {processor.py:161} INFO - Started process (PID=494) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:30:02.970+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:30:02.981+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:30:02.977+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:30:03.883+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:30:03.833+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T12:30:03.891+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:30:04.295+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.420 seconds
[2025-09-11T12:30:37.573+0000] {processor.py:161} INFO - Started process (PID=506) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:30:37.579+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:30:37.587+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:30:37.583+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:30:38.162+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:30:38.134+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T12:30:38.166+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:30:38.349+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.841 seconds
[2025-09-11T12:31:18.085+0000] {processor.py:161} INFO - Started process (PID=519) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:31:18.091+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:31:18.097+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:31:18.095+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:31:18.674+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:31:18.643+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T12:31:18.678+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:31:18.864+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.832 seconds
[2025-09-11T12:31:50.798+0000] {processor.py:161} INFO - Started process (PID=531) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:31:50.804+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:31:50.809+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:31:50.807+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:31:51.448+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:31:51.408+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T12:31:51.453+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:31:51.634+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.903 seconds
[2025-09-11T12:33:40.358+0000] {processor.py:161} INFO - Started process (PID=550) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:33:40.362+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:33:40.371+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:33:40.369+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:33:40.889+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:33:40.869+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T12:33:40.892+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:33:41.051+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 0.776 seconds
[2025-09-11T12:34:52.899+0000] {processor.py:161} INFO - Started process (PID=567) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:34:52.906+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:34:52.911+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:34:52.909+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:34:53.716+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:34:53.685+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T12:34:53.723+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:34:54.241+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.424 seconds
[2025-09-11T12:39:03.908+0000] {processor.py:161} INFO - Started process (PID=583) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:39:03.840+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:39:03.883+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:39:03.882+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:39:12.305+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:39:12.123+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/snowspark-dataframe-ETL.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/snowspark-dataframe-ETL.py", line 8, in <module>
    from snowflake.snowpark import Session, functions as F
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/__init__.py", line 52, in <module>
    from snowflake.snowpark.async_job import AsyncJob
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/async_job.py", line 13, in <module>
    from snowflake.snowpark._internal.analyzer.analyzer_utils import result_scan_statement
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/analyzer_utils.py", line 16, in <module>
    from snowflake.connector.pandas_tools import (
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/pandas_tools.py", line 29, in <module>
    from .constants import _PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS
ImportError: cannot import name '_PARAM_USE_SCOPED_TEMP_FOR_PANDAS_TOOLS' from 'snowflake.connector.constants' (/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/constants.py)
[2025-09-11T12:39:12.348+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:39:13.185+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 9.488 seconds
[2025-09-11T12:45:38.369+0000] {processor.py:161} INFO - Started process (PID=874) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:45:38.374+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:45:38.383+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:45:38.382+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:45:38.784+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:45:38.782+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T12:45:41.457+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:45:42.111+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:45:42.109+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T12:45:42.177+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:45:42.176+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T12:45:42.703+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.355 seconds
[2025-09-11T12:46:24.946+0000] {processor.py:161} INFO - Started process (PID=890) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:46:24.960+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:46:24.991+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:46:24.983+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:46:26.731+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:46:26.720+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T12:46:29.013+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:46:29.086+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:46:29.085+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T12:46:29.117+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:46:29.117+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T12:46:29.322+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.469 seconds
[2025-09-11T12:47:12.475+0000] {processor.py:161} INFO - Started process (PID=905) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:47:12.485+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:47:12.506+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:47:12.502+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:47:14.027+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:47:14.025+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T12:47:16.080+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:47:16.176+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:47:16.175+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T12:47:16.211+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:47:16.211+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T12:47:16.414+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.095 seconds
[2025-09-11T12:48:24.561+0000] {processor.py:161} INFO - Started process (PID=926) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:48:24.567+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:48:24.593+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:48:24.590+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:48:25.228+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:48:25.225+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T12:48:28.731+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:48:28.830+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:48:28.829+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T12:48:28.869+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:48:28.869+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T12:48:29.101+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.578 seconds
[2025-09-11T12:49:11.216+0000] {processor.py:161} INFO - Started process (PID=942) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:49:11.223+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:49:11.236+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:49:11.233+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:49:12.161+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:49:12.159+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T12:49:14.944+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:49:15.122+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:49:15.118+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T12:49:15.192+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:49:15.192+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T12:49:15.552+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.372 seconds
[2025-09-11T12:50:09.142+0000] {processor.py:161} INFO - Started process (PID=961) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:50:09.145+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:50:09.151+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:50:09.150+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:50:09.438+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:50:09.437+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T12:50:10.700+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:50:10.792+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:50:10.792+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T12:50:10.825+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:50:10.824+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T12:50:10.984+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.864 seconds
[2025-09-11T12:50:58.510+0000] {processor.py:161} INFO - Started process (PID=977) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:50:58.517+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:50:58.532+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:50:58.529+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:50:59.300+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:50:59.297+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T12:51:01.695+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:51:01.861+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:51:01.859+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T12:51:01.934+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:51:01.933+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T12:51:02.239+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.789 seconds
[2025-09-11T12:51:58.516+0000] {processor.py:161} INFO - Started process (PID=996) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:51:58.520+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:51:58.532+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:51:58.530+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:51:59.083+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:51:59.081+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T12:52:01.027+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:52:01.147+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:52:01.145+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T12:52:01.214+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:52:01.213+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T12:52:01.466+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.007 seconds
[2025-09-11T12:53:00.979+0000] {processor.py:161} INFO - Started process (PID=1016) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:53:01.012+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:53:01.034+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:53:01.032+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:53:01.892+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:53:01.891+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T12:53:03.600+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:53:03.667+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:53:03.666+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T12:53:03.703+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:53:03.703+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T12:53:03.837+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.899 seconds
[2025-09-11T12:53:53.352+0000] {processor.py:161} INFO - Started process (PID=1034) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:53:53.358+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:53:53.371+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:53:53.369+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:53:53.955+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:53:53.952+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T12:53:57.119+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:53:57.403+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:53:57.399+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T12:53:57.494+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:53:57.494+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T12:53:57.870+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.557 seconds
[2025-09-11T12:54:37.040+0000] {processor.py:161} INFO - Started process (PID=1049) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:54:37.046+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:54:37.074+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:54:37.065+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:54:37.745+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:54:37.743+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T12:54:40.678+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:54:40.958+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:54:40.955+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T12:54:41.071+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:54:41.069+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T12:54:41.592+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.590 seconds
[2025-09-11T12:55:35.602+0000] {processor.py:161} INFO - Started process (PID=1069) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:55:35.607+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:55:35.616+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:55:35.614+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:55:36.210+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:55:36.207+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T12:55:38.765+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:55:38.921+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:55:38.919+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T12:55:38.995+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:55:38.994+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T12:55:39.502+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.926 seconds
[2025-09-11T12:56:22.570+0000] {processor.py:161} INFO - Started process (PID=1084) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:56:22.575+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:56:22.589+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:56:22.587+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:56:23.206+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:56:23.204+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T12:56:25.363+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:56:25.548+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:56:25.546+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T12:56:25.625+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:56:25.624+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T12:56:26.113+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.589 seconds
[2025-09-11T12:57:13.566+0000] {processor.py:161} INFO - Started process (PID=1100) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:57:13.580+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:57:13.612+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:57:13.600+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:57:14.464+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:57:14.462+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T12:57:16.762+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:57:16.874+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:57:16.873+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T12:57:16.922+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:57:16.922+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T12:57:17.213+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.714 seconds
[2025-09-11T12:58:05.730+0000] {processor.py:161} INFO - Started process (PID=1116) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:58:05.737+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:58:05.749+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:58:05.747+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:58:06.694+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:58:06.692+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T12:58:08.931+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:58:09.096+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:58:09.086+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T12:58:09.180+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:58:09.178+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T12:58:09.660+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.966 seconds
[2025-09-11T12:59:02.769+0000] {processor.py:161} INFO - Started process (PID=1135) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:59:02.773+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T12:59:02.787+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:59:02.785+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:59:03.331+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:59:03.329+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T12:59:04.636+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T12:59:04.708+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:59:04.707+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T12:59:04.740+0000] {logging_mixin.py:188} INFO - [2025-09-11T12:59:04.739+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T12:59:04.891+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.149 seconds
[2025-09-11T13:00:53.067+0000] {processor.py:161} INFO - Started process (PID=1159) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:00:53.071+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:00:53.080+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:00:53.077+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:00:53.430+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:00:53.429+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:00:54.427+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:00:54.503+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:00:54.502+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:00:54.537+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:00:54.536+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:00:54.676+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.629 seconds
[2025-09-11T13:01:41.154+0000] {processor.py:161} INFO - Started process (PID=1174) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:01:41.156+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:01:41.162+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:01:41.161+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:01:41.398+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:01:41.397+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:01:42.219+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:01:42.587+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:01:42.586+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:01:42.869+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:01:42.869+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:01:43.137+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.996 seconds
[2025-09-11T13:02:33.756+0000] {processor.py:161} INFO - Started process (PID=1190) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:02:33.763+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:02:33.776+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:02:33.774+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:02:34.496+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:02:34.494+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:02:37.272+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:02:37.487+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:02:37.485+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:02:37.567+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:02:37.566+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:02:37.943+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.230 seconds
[2025-09-11T13:03:21.261+0000] {processor.py:161} INFO - Started process (PID=1205) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:03:21.265+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:03:21.272+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:03:21.271+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:03:21.736+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:03:21.733+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:03:23.547+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:03:23.686+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:03:23.684+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:03:23.750+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:03:23.749+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:03:23.934+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.702 seconds
[2025-09-11T13:04:18.105+0000] {processor.py:161} INFO - Started process (PID=1224) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:04:18.112+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:04:18.126+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:04:18.124+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:04:19.089+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:04:19.085+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:04:21.959+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:04:22.091+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:04:22.089+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:04:22.149+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:04:22.149+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:04:22.469+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.403 seconds
[2025-09-11T13:05:08.902+0000] {processor.py:161} INFO - Started process (PID=1239) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:05:08.904+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:05:08.919+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:05:08.918+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:05:09.276+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:05:09.275+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:05:10.112+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:05:10.182+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:05:10.181+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:05:10.217+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:05:10.217+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:05:10.360+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.518 seconds
[2025-09-11T13:05:48.014+0000] {processor.py:161} INFO - Started process (PID=1254) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:05:48.031+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:05:48.073+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:05:48.061+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:05:48.980+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:05:48.978+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:05:50.700+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:05:50.780+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:05:50.779+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:05:50.819+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:05:50.819+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:05:50.999+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.126 seconds
[2025-09-11T13:06:41.249+0000] {processor.py:161} INFO - Started process (PID=1271) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:06:41.252+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:06:41.259+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:06:41.257+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:06:41.552+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:06:41.551+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:06:42.433+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:06:42.488+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:06:42.487+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:06:42.518+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:06:42.518+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:06:42.631+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.410 seconds
[2025-09-11T13:07:32.066+0000] {processor.py:161} INFO - Started process (PID=1288) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:07:32.080+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:07:32.095+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:07:32.094+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:07:33.220+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:07:33.209+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:07:36.576+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:07:36.714+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:07:36.713+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:07:36.783+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:07:36.782+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:07:37.030+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.018 seconds
[2025-09-11T13:08:30.829+0000] {processor.py:161} INFO - Started process (PID=1306) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:08:30.843+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:08:30.861+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:08:30.858+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:08:32.082+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:08:32.080+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:08:35.722+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:08:35.808+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:08:35.806+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:08:35.849+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:08:35.848+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:08:36.021+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.281 seconds
[2025-09-11T13:09:36.870+0000] {processor.py:161} INFO - Started process (PID=1324) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:09:36.879+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:09:36.900+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:09:36.896+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:09:37.774+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:09:37.771+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:09:40.599+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:09:40.718+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:09:40.717+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:09:40.761+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:09:40.761+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:09:40.994+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.193 seconds
[2025-09-11T13:10:41.278+0000] {processor.py:161} INFO - Started process (PID=1344) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:10:41.281+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:10:41.287+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:10:41.286+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:10:41.764+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:10:41.763+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:10:43.030+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:10:43.105+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:10:43.104+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:10:43.145+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:10:43.144+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:10:43.341+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.096 seconds
[2025-09-11T13:11:24.164+0000] {processor.py:161} INFO - Started process (PID=1359) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:11:24.168+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:11:24.185+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:11:24.184+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:11:24.622+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:11:24.619+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:11:25.802+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:11:25.871+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:11:25.870+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:11:25.899+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:11:25.898+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:11:26.046+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.930 seconds
[2025-09-11T13:12:16.978+0000] {processor.py:161} INFO - Started process (PID=1374) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:12:16.983+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:12:16.996+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:12:16.995+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:12:17.711+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:12:17.699+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:12:19.771+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:12:19.826+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:12:19.825+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:12:19.850+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:12:19.849+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:12:19.973+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.034 seconds
[2025-09-11T13:13:18.942+0000] {processor.py:161} INFO - Started process (PID=1394) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:13:18.951+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:13:18.962+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:13:18.959+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:13:19.505+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:13:19.503+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:13:21.847+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:13:21.967+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:13:21.963+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:13:21.993+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:13:21.993+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:13:22.146+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.244 seconds
[2025-09-11T13:14:07.693+0000] {processor.py:161} INFO - Started process (PID=1413) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:14:07.696+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:14:07.700+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:14:07.699+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:14:07.890+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:14:07.889+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:14:11.327+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:14:11.468+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:14:11.466+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:14:11.521+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:14:11.520+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:14:12.004+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.323 seconds
[2025-09-11T13:15:01.607+0000] {processor.py:161} INFO - Started process (PID=1428) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:15:01.610+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:15:01.623+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:15:01.620+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:15:02.062+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:15:02.061+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:15:03.128+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:15:03.188+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:15:03.187+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:15:03.213+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:15:03.212+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:15:03.334+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.750 seconds
[2025-09-11T13:15:46.919+0000] {processor.py:161} INFO - Started process (PID=1443) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:15:46.927+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:15:46.951+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:15:46.946+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:15:47.906+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:15:47.905+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:15:50.052+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:15:50.186+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:15:50.184+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:15:50.276+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:15:50.275+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:15:50.631+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.784 seconds
[2025-09-11T13:16:30.179+0000] {processor.py:161} INFO - Started process (PID=1458) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:16:30.189+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:16:30.220+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:16:30.215+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:16:31.346+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:16:31.344+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:16:33.669+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:16:33.775+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:16:33.773+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:16:33.821+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:16:33.820+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:16:34.112+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.037 seconds
[2025-09-11T13:17:25.486+0000] {processor.py:161} INFO - Started process (PID=1473) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:17:25.505+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:17:25.541+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:17:25.536+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:17:26.907+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:17:26.903+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:17:29.715+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:17:29.900+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:17:29.899+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:17:29.977+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:17:29.976+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:17:30.178+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.824 seconds
[2025-09-11T13:18:27.242+0000] {processor.py:161} INFO - Started process (PID=1492) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:18:27.260+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:18:27.285+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:18:27.281+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:18:28.248+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:18:28.244+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:18:30.735+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:18:30.853+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:18:30.851+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:18:30.909+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:18:30.909+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:18:31.181+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.013 seconds
[2025-09-11T13:19:23.504+0000] {processor.py:161} INFO - Started process (PID=1511) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:19:23.524+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:19:23.552+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:19:23.550+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:19:24.054+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:19:24.052+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:19:25.879+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:19:25.985+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:19:25.983+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:19:26.034+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:19:26.033+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:19:26.278+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.853 seconds
[2025-09-11T13:20:21.736+0000] {processor.py:161} INFO - Started process (PID=1529) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:20:21.739+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:20:21.751+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:20:21.749+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:20:22.328+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:20:22.325+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:20:23.795+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:20:23.883+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:20:23.882+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:20:23.921+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:20:23.921+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:20:24.172+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.459 seconds
[2025-09-11T13:21:23.377+0000] {processor.py:161} INFO - Started process (PID=1547) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:21:23.385+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:21:23.401+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:21:23.399+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:21:24.320+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:21:24.317+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:21:26.746+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:21:26.885+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:21:26.884+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:21:26.934+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:21:26.933+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:21:27.248+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.928 seconds
[2025-09-11T13:22:14.322+0000] {processor.py:161} INFO - Started process (PID=1563) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:22:14.326+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:22:14.341+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:22:14.340+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:22:14.745+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:22:14.744+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:22:15.896+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:22:15.973+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:22:15.972+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:22:16.006+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:22:16.005+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:22:16.161+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.907 seconds
[2025-09-11T13:22:59.463+0000] {processor.py:161} INFO - Started process (PID=1578) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:22:59.470+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:22:59.486+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:22:59.484+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:23:00.115+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:23:00.112+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:23:02.212+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:23:02.489+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:23:02.487+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:23:02.644+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:23:02.643+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:23:03.072+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.651 seconds
[2025-09-11T13:23:53.405+0000] {processor.py:161} INFO - Started process (PID=1593) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:23:53.437+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:23:53.479+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:23:53.474+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:23:54.227+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:23:54.225+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:23:57.285+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:23:57.390+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:23:57.388+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:23:57.447+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:23:57.446+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:23:57.784+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.481 seconds
[2025-09-11T13:24:51.803+0000] {processor.py:161} INFO - Started process (PID=1612) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:24:51.818+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:24:51.855+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:24:51.846+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:24:53.626+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:24:53.624+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:24:56.037+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:24:56.128+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:24:56.127+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:24:56.173+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:24:56.172+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:24:56.430+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.741 seconds
[2025-09-11T13:25:55.176+0000] {processor.py:161} INFO - Started process (PID=1630) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:25:55.181+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:25:55.193+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:25:55.190+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:25:55.703+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:25:55.702+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:25:57.305+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:25:57.402+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:25:57.401+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:25:57.446+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:25:57.445+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:25:57.633+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.491 seconds
[2025-09-11T13:26:57.257+0000] {processor.py:161} INFO - Started process (PID=1650) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:26:57.260+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:26:57.267+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:26:57.265+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:26:57.612+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:26:57.611+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:26:59.450+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:26:59.530+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:26:59.529+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:26:59.563+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:26:59.562+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:26:59.776+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.544 seconds
[2025-09-11T13:28:01.502+0000] {processor.py:161} INFO - Started process (PID=1669) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:28:01.511+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:28:01.526+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:28:01.522+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:28:02.224+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:28:02.222+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:28:04.595+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:28:04.820+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:28:04.819+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:28:04.895+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:28:04.895+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:28:05.197+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.743 seconds
[2025-09-11T13:28:48.609+0000] {processor.py:161} INFO - Started process (PID=1685) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:28:48.629+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:28:48.650+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:28:48.647+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:28:49.574+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:28:49.569+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:28:52.305+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:28:52.555+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:28:52.550+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:28:52.849+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:28:52.847+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:28:53.413+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.862 seconds
[2025-09-11T13:29:40.777+0000] {processor.py:161} INFO - Started process (PID=1700) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:29:40.781+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:29:40.788+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:29:40.786+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:29:41.185+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:29:41.184+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:29:42.564+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:29:42.720+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:29:42.718+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:29:42.801+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:29:42.800+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:29:43.049+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.304 seconds
[2025-09-11T13:30:34.224+0000] {processor.py:161} INFO - Started process (PID=1719) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:30:34.234+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:30:34.264+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:30:34.257+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:30:35.731+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:30:35.726+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:30:38.085+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:30:38.262+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:30:38.261+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:30:38.329+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:30:38.329+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:30:38.545+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.409 seconds
[2025-09-11T13:31:32.310+0000] {processor.py:161} INFO - Started process (PID=1735) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:31:32.317+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:31:32.326+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:31:32.324+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:31:32.759+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:31:32.758+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:31:33.910+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:31:33.969+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:31:33.968+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:31:33.992+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:31:33.991+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:31:34.124+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.842 seconds
[2025-09-11T13:32:31.015+0000] {processor.py:161} INFO - Started process (PID=1753) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:32:31.037+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:32:31.081+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:32:31.076+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:32:32.166+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:32:32.164+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:32:35.360+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:32:35.514+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:32:35.512+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:32:35.588+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:32:35.587+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:32:35.808+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.866 seconds
[2025-09-11T13:33:16.837+0000] {processor.py:161} INFO - Started process (PID=1768) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:33:16.840+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:33:16.849+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:33:16.848+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:33:17.180+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:33:17.179+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:33:18.257+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:33:18.364+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:33:18.363+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:33:18.427+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:33:18.426+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:33:18.646+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.839 seconds
[2025-09-11T13:34:09.321+0000] {processor.py:161} INFO - Started process (PID=1785) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:34:09.325+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:34:09.334+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:34:09.332+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:34:09.721+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:34:09.720+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:34:11.399+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:34:11.493+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:34:11.492+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:34:11.532+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:34:11.532+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:34:11.693+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.401 seconds
[2025-09-11T13:35:06.702+0000] {processor.py:161} INFO - Started process (PID=1802) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:35:06.716+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:35:06.737+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:35:06.735+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:35:07.572+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:35:07.570+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:35:10.018+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:35:10.203+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:35:10.201+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:35:10.310+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:35:10.309+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:35:10.563+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.959 seconds
[2025-09-11T13:36:03.511+0000] {processor.py:161} INFO - Started process (PID=1817) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:36:03.514+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:36:03.519+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:36:03.518+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:36:03.762+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:36:03.761+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:36:05.001+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:36:05.082+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:36:05.081+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:36:05.123+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:36:05.120+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:36:05.266+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.769 seconds
[2025-09-11T13:37:20.081+0000] {processor.py:161} INFO - Started process (PID=1838) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:37:20.090+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:37:20.096+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:37:20.095+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:37:20.558+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:37:20.556+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:37:21.572+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:37:21.651+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:37:21.651+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:37:21.691+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:37:21.690+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:37:21.853+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.785 seconds
[2025-09-11T13:37:52.456+0000] {processor.py:161} INFO - Started process (PID=1853) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:37:52.461+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:37:52.477+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:37:52.475+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:37:52.885+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:37:52.883+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:37:54.261+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:37:54.373+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:37:54.372+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:37:54.437+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:37:54.436+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:37:54.594+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.186 seconds
[2025-09-11T13:38:27.219+0000] {processor.py:161} INFO - Started process (PID=1868) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:38:27.223+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:38:27.228+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:38:27.227+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:38:27.493+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:38:27.492+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:38:28.643+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:38:28.737+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:38:28.736+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:38:28.782+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:38:28.782+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:38:28.986+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.783 seconds
[2025-09-11T13:39:16.771+0000] {processor.py:161} INFO - Started process (PID=1886) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:39:16.774+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:39:16.780+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:39:16.779+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:39:17.055+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:39:17.054+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:39:18.057+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:39:18.139+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:39:18.138+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:39:18.695+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:39:18.694+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:39:18.845+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.094 seconds
[2025-09-11T13:39:56.237+0000] {processor.py:161} INFO - Started process (PID=1901) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:39:56.247+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:39:56.258+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:39:56.256+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:39:56.673+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:39:56.671+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:39:57.844+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:39:57.953+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:39:57.951+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:39:58.009+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:39:58.008+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:39:58.204+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.993 seconds
[2025-09-11T13:41:04.931+0000] {processor.py:161} INFO - Started process (PID=1922) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:41:04.939+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:41:04.979+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:41:04.975+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:41:05.990+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:41:05.988+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:41:09.130+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:41:09.321+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:41:09.319+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:41:10.040+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:41:10.039+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:41:10.620+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.760 seconds
[2025-09-11T13:41:51.834+0000] {processor.py:161} INFO - Started process (PID=1938) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:41:51.839+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:41:51.851+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:41:51.849+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:41:52.483+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:41:52.482+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:41:55.085+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:41:55.216+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:41:55.215+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:41:55.282+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:41:55.281+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:41:55.434+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.645 seconds
[2025-09-11T13:42:39.086+0000] {processor.py:161} INFO - Started process (PID=1953) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:42:39.105+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:42:39.141+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:42:39.138+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:42:39.996+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:42:39.989+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:42:42.414+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:42:42.581+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:42:42.579+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:42:42.650+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:42:42.649+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:42:42.989+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.998 seconds
[2025-09-11T13:43:29.880+0000] {processor.py:161} INFO - Started process (PID=1969) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:43:29.884+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:43:29.891+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:43:29.890+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:43:30.280+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:43:30.278+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:43:31.669+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:43:32.270+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:43:32.269+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:43:32.329+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:43:32.328+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:43:32.545+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.684 seconds
[2025-09-11T13:44:19.799+0000] {processor.py:161} INFO - Started process (PID=1985) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:44:19.802+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:44:19.809+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:44:19.808+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:44:20.220+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:44:20.219+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:44:22.510+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:44:22.639+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:44:22.637+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:44:22.694+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:44:22.694+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:44:22.963+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.189 seconds
[2025-09-11T13:45:06.364+0000] {processor.py:161} INFO - Started process (PID=2000) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:45:06.372+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:45:06.391+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:45:06.387+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:45:07.398+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:45:07.395+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:45:10.867+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:45:11.003+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:45:11.001+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:45:11.052+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:45:11.051+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:45:11.337+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.048 seconds
[2025-09-11T13:46:06.539+0000] {processor.py:161} INFO - Started process (PID=2019) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:46:06.560+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:46:06.580+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:46:06.576+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:46:07.710+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:46:07.708+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:46:10.500+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:46:10.621+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:46:10.620+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:46:10.668+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:46:10.667+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:46:10.881+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.553 seconds
[2025-09-11T13:47:18.728+0000] {processor.py:161} INFO - Started process (PID=2039) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:47:18.734+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:47:18.750+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:47:18.747+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:47:19.309+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:47:19.308+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:47:21.891+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:47:21.996+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:47:21.994+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:47:22.042+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:47:22.041+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:47:22.364+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.675 seconds
[2025-09-11T13:48:05.678+0000] {processor.py:161} INFO - Started process (PID=2054) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:48:05.685+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:48:05.702+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:48:05.699+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:48:07.032+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:48:07.030+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:48:10.780+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:48:10.900+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:48:10.898+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:48:10.958+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:48:10.957+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:48:11.218+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.610 seconds
[2025-09-11T13:48:55.833+0000] {processor.py:161} INFO - Started process (PID=2070) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:48:55.836+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:48:55.842+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:48:55.841+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:48:56.193+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:48:56.192+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:48:57.916+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:48:57.988+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:48:57.987+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:48:58.026+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:48:58.026+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:48:58.215+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.398 seconds
[2025-09-11T13:49:54.467+0000] {processor.py:161} INFO - Started process (PID=2089) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:49:54.470+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:49:54.480+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:49:54.478+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:49:54.870+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:49:54.868+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:49:56.659+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:49:56.735+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:49:56.734+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:49:56.773+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:49:56.773+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:49:56.962+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.523 seconds
[2025-09-11T13:50:56.131+0000] {processor.py:161} INFO - Started process (PID=2108) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:50:56.133+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:50:56.138+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:50:56.137+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:50:56.521+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:50:56.520+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:50:57.776+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:50:57.830+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:50:57.829+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:50:57.850+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:50:57.850+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:50:57.982+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.866 seconds
[2025-09-11T13:51:58.313+0000] {processor.py:161} INFO - Started process (PID=2125) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:51:58.317+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:51:58.324+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:51:58.322+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:51:58.719+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:51:58.718+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:52:00.254+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:52:00.316+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:52:00.315+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:52:00.342+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:52:00.342+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:52:00.491+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.205 seconds
[2025-09-11T13:53:00.970+0000] {processor.py:161} INFO - Started process (PID=2144) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:53:00.973+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:53:00.987+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:53:00.986+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:53:01.366+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:53:01.365+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:53:03.224+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:53:03.279+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:53:03.277+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:53:03.300+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:53:03.300+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:53:03.424+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.480 seconds
[2025-09-11T13:54:05.287+0000] {processor.py:161} INFO - Started process (PID=2162) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:54:05.290+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:54:05.297+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:54:05.295+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:54:05.652+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:54:05.651+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:54:07.314+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:54:07.369+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:54:07.368+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:54:07.390+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:54:07.390+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:54:07.525+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.260 seconds
[2025-09-11T13:54:48.424+0000] {processor.py:161} INFO - Started process (PID=2177) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:54:48.426+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:54:48.433+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:54:48.432+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:54:48.700+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:54:48.699+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:54:49.815+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:54:49.869+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:54:49.868+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:54:49.891+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:54:49.891+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:54:50.018+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.617 seconds
[2025-09-11T13:55:52.279+0000] {processor.py:161} INFO - Started process (PID=2198) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:55:52.294+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:55:52.314+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:55:52.312+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:55:53.024+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:55:53.022+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:55:55.433+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:55:55.499+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:55:55.498+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:55:55.527+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:55:55.526+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:55:55.701+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.483 seconds
[2025-09-11T13:56:57.894+0000] {processor.py:161} INFO - Started process (PID=2218) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:56:57.897+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:56:57.906+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:56:57.905+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:56:58.317+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:56:58.316+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:57:00.285+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:57:00.373+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:57:00.373+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:57:00.417+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:57:00.417+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:57:00.710+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.836 seconds
[2025-09-11T13:57:48.355+0000] {processor.py:161} INFO - Started process (PID=2238) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:57:48.364+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:57:48.397+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:57:48.386+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:57:49.355+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:57:49.352+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:57:52.470+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:57:52.593+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:57:52.591+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:57:52.649+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:57:52.647+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:57:52.948+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.670 seconds
[2025-09-11T13:58:57.435+0000] {processor.py:161} INFO - Started process (PID=2256) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:58:57.440+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:58:57.450+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:58:57.448+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:58:57.950+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:58:57.948+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:59:00.494+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:59:00.591+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:59:00.590+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:59:00.636+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:59:00.635+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:59:00.888+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.484 seconds
[2025-09-11T13:59:47.363+0000] {processor.py:161} INFO - Started process (PID=2272) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:59:47.367+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T13:59:47.376+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:59:47.375+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:59:48.002+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:59:47.989+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T13:59:49.674+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T13:59:49.728+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:59:49.727+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T13:59:49.753+0000] {logging_mixin.py:188} INFO - [2025-09-11T13:59:49.753+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T13:59:49.910+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.572 seconds
[2025-09-11T14:00:39.593+0000] {processor.py:161} INFO - Started process (PID=2287) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:00:39.605+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:00:39.635+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:00:39.631+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:00:40.550+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:00:40.547+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:00:43.232+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:00:43.320+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:00:43.319+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:00:43.355+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:00:43.355+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:00:43.603+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.097 seconds
[2025-09-11T14:01:39.002+0000] {processor.py:161} INFO - Started process (PID=2306) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:01:39.012+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:01:39.019+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:01:39.018+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:01:39.965+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:01:39.965+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:01:40.922+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:01:40.981+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:01:40.980+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:01:41.005+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:01:41.005+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:01:41.146+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.212 seconds
[2025-09-11T14:02:41.631+0000] {processor.py:161} INFO - Started process (PID=2325) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:02:41.634+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:02:41.641+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:02:41.640+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:02:41.969+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:02:41.968+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:02:43.500+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:02:43.563+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:02:43.562+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:02:43.585+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:02:43.584+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:02:43.737+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.127 seconds
[2025-09-11T14:03:29.333+0000] {processor.py:161} INFO - Started process (PID=2340) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:03:29.338+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:03:29.349+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:03:29.346+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:03:31.109+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:03:31.108+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:03:32.320+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:03:32.425+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:03:32.423+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:03:32.461+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:03:32.461+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:03:32.753+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.448 seconds
[2025-09-11T14:04:21.922+0000] {processor.py:161} INFO - Started process (PID=2356) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:04:21.926+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:04:21.935+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:04:21.933+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:04:23.183+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:04:23.181+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:04:24.464+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:04:24.565+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:04:24.564+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:04:24.614+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:04:24.613+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:04:24.793+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.896 seconds
[2025-09-11T14:05:01.149+0000] {processor.py:161} INFO - Started process (PID=2370) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:05:01.153+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:05:01.159+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:05:01.158+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:05:02.006+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:05:02.005+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:05:03.090+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:05:03.375+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:05:03.373+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:05:03.453+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:05:03.452+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:05:03.618+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.488 seconds
[2025-09-11T14:05:51.251+0000] {processor.py:161} INFO - Started process (PID=2385) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:05:51.258+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:05:51.267+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:05:51.265+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:05:52.534+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:05:52.533+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:05:54.164+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:05:54.289+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:05:54.288+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:05:54.338+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:05:54.337+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:05:54.523+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.310 seconds
[2025-09-11T14:06:57.467+0000] {processor.py:161} INFO - Started process (PID=2405) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:06:57.472+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:06:57.480+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:06:57.478+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:06:58.627+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:06:58.626+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:06:59.629+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:06:59.680+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:06:59.679+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:06:59.701+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:06:59.700+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:06:59.822+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.376 seconds
[2025-09-11T14:07:47.278+0000] {processor.py:161} INFO - Started process (PID=2420) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:07:47.306+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:07:47.362+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:07:47.348+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:07:49.312+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:07:49.311+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:07:51.157+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:07:51.290+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:07:51.286+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:07:51.341+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:07:51.340+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:07:51.644+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.558 seconds
[2025-09-11T14:08:46.027+0000] {processor.py:161} INFO - Started process (PID=2439) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:08:46.037+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:08:46.049+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:08:46.047+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:08:47.132+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:08:47.131+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:08:48.349+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:08:48.461+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:08:48.460+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:08:48.503+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:08:48.502+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:08:48.775+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.777 seconds
[2025-09-11T14:09:45.832+0000] {processor.py:161} INFO - Started process (PID=2455) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:09:45.836+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:09:45.843+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:09:45.841+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:09:46.774+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:09:46.773+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:09:47.885+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:09:47.980+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:09:47.978+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:09:48.018+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:09:48.018+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:09:48.344+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.533 seconds
[2025-09-11T14:10:47.248+0000] {processor.py:161} INFO - Started process (PID=2475) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:10:47.252+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:10:47.259+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:10:47.258+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:10:47.971+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:10:47.970+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:10:48.846+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:10:48.912+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:10:48.912+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:10:48.935+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:10:48.935+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:10:49.082+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.866 seconds
[2025-09-11T14:11:51.670+0000] {processor.py:161} INFO - Started process (PID=2493) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:11:51.674+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:11:51.691+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:11:51.689+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:11:52.737+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:11:52.737+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:11:54.021+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:11:54.109+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:11:54.108+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:11:54.155+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:11:54.154+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:11:55.048+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.407 seconds
[2025-09-11T14:12:53.094+0000] {processor.py:161} INFO - Started process (PID=2508) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:12:53.113+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:12:53.137+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:12:53.133+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:12:54.110+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:12:54.108+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:12:57.088+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:12:57.202+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:12:57.201+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:12:57.244+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:12:57.243+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:12:57.453+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.461 seconds
[2025-09-11T14:13:52.558+0000] {processor.py:161} INFO - Started process (PID=2528) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:13:52.566+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:13:52.594+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:13:52.590+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:13:53.574+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:13:53.572+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:13:57.104+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:13:57.187+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:13:57.186+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:13:57.223+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:13:57.222+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:13:57.404+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.913 seconds
[2025-09-11T14:14:52.325+0000] {processor.py:161} INFO - Started process (PID=2546) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:14:52.331+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:14:52.341+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:14:52.339+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:14:52.858+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:14:52.856+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:14:54.305+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:14:54.413+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:14:54.412+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:14:54.477+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:14:54.476+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:14:54.729+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.439 seconds
[2025-09-11T14:15:38.529+0000] {processor.py:161} INFO - Started process (PID=2561) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:15:38.536+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:15:38.544+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:15:38.543+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:15:39.002+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:15:39.000+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:15:40.589+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:15:40.684+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:15:40.683+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:15:40.722+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:15:40.721+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:15:40.911+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.416 seconds
[2025-09-11T14:16:32.676+0000] {processor.py:161} INFO - Started process (PID=2578) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:16:32.685+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:16:32.705+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:16:32.700+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:16:33.617+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:16:33.614+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:16:36.312+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:16:36.466+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:16:36.464+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:16:36.547+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:16:36.546+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:16:36.821+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.206 seconds
[2025-09-11T14:17:15.970+0000] {processor.py:161} INFO - Started process (PID=2593) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:17:15.978+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:17:15.993+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:17:15.991+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:17:16.812+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:17:16.810+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:17:18.081+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:17:18.192+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:17:18.191+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:17:18.231+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:17:18.230+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:17:18.390+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.484 seconds
[2025-09-11T14:17:51.669+0000] {processor.py:161} INFO - Started process (PID=2608) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:17:51.673+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:17:51.679+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:17:51.678+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:17:52.055+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:17:52.053+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:17:53.480+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:17:53.554+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:17:53.553+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:17:53.583+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:17:53.583+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:17:53.718+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.065 seconds
[2025-09-11T14:18:49.329+0000] {processor.py:161} INFO - Started process (PID=2627) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:18:49.346+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:18:49.371+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:18:49.367+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:18:50.660+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:18:50.658+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:18:53.262+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:18:53.370+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:18:53.368+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:18:53.414+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:18:53.414+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:18:53.575+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.357 seconds
[2025-09-11T14:19:58.822+0000] {processor.py:161} INFO - Started process (PID=2647) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:19:58.828+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:19:58.834+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:19:58.833+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:19:59.131+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:19:59.130+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:19:59.946+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:20:00.010+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:20:00.009+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:20:00.053+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:20:00.053+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:20:00.189+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.386 seconds
[2025-09-11T14:20:47.713+0000] {processor.py:161} INFO - Started process (PID=2662) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:20:47.728+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:20:47.751+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:20:47.747+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:20:48.753+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:20:48.751+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:20:50.987+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:20:51.164+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:20:51.163+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:20:51.228+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:20:51.227+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:20:51.733+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.101 seconds
[2025-09-11T14:21:33.994+0000] {processor.py:161} INFO - Started process (PID=2678) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:21:34.028+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:21:34.077+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:21:34.068+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:21:35.815+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:21:35.811+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:21:37.584+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:21:37.665+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:21:37.664+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:21:37.703+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:21:37.702+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:21:37.891+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.035 seconds
[2025-09-11T14:22:20.982+0000] {processor.py:161} INFO - Started process (PID=2693) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:22:20.991+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:22:21.019+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:22:21.016+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:22:22.411+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:22:22.408+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:22:24.934+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:22:25.072+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:22:25.071+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:22:25.129+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:22:25.128+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:22:25.396+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.485 seconds
[2025-09-11T14:23:20.771+0000] {processor.py:161} INFO - Started process (PID=2713) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:23:20.782+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:23:20.807+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:23:20.804+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:23:22.557+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:23:22.553+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:23:24.987+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:23:25.103+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:23:25.101+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:23:25.154+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:23:25.154+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:23:25.357+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.647 seconds
[2025-09-11T14:24:25.330+0000] {processor.py:161} INFO - Started process (PID=2732) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:24:25.334+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:24:25.343+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:24:25.341+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:24:25.736+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:24:25.734+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:24:27.810+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:24:27.900+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:24:27.899+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:24:27.933+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:24:27.933+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:24:28.091+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.785 seconds
[2025-09-11T14:25:09.354+0000] {processor.py:161} INFO - Started process (PID=2747) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:25:09.366+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:25:09.386+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:25:09.383+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:25:10.208+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:25:10.204+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:25:13.589+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:25:13.782+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:25:13.781+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:25:13.823+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:25:13.822+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:25:14.936+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.639 seconds
[2025-09-11T14:26:14.631+0000] {processor.py:161} INFO - Started process (PID=2767) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:26:14.634+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:26:14.639+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:26:14.638+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:26:14.900+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:26:14.899+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:26:15.658+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:26:15.718+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:26:15.717+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:26:15.797+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:26:15.796+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:26:16.869+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.252 seconds
[2025-09-11T14:27:01.182+0000] {processor.py:161} INFO - Started process (PID=2783) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:27:01.200+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:27:01.240+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:27:01.235+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:27:02.799+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:27:02.798+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:27:05.131+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:27:05.214+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:27:05.212+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:27:05.251+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:27:05.251+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:27:05.420+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.400 seconds
[2025-09-11T14:28:00.962+0000] {processor.py:161} INFO - Started process (PID=2799) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:28:00.976+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:28:01.002+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:28:00.997+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:28:02.694+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:28:02.682+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:28:04.924+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:28:05.029+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:28:05.025+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:28:05.074+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:28:05.074+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:28:05.293+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.419 seconds
[2025-09-11T14:28:40.927+0000] {processor.py:161} INFO - Started process (PID=2814) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:28:40.941+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:28:40.972+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:28:40.966+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:28:42.552+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:28:42.551+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:28:44.533+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:28:44.680+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:28:44.678+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:28:44.738+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:28:44.737+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:28:44.998+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.185 seconds
[2025-09-11T14:29:44.225+0000] {processor.py:161} INFO - Started process (PID=2833) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:29:44.234+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:29:44.259+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:29:44.250+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:29:45.338+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:29:45.336+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:29:47.998+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:29:48.146+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:29:48.144+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:29:48.233+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:29:48.233+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:29:48.603+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.449 seconds
[2025-09-11T14:30:49.170+0000] {processor.py:161} INFO - Started process (PID=2853) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:30:49.178+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:30:49.189+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:30:49.187+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:30:49.780+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:30:49.778+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:30:52.913+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:30:53.103+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:30:53.101+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:30:53.170+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:30:53.170+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:30:53.441+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.313 seconds
[2025-09-11T14:31:48.938+0000] {processor.py:161} INFO - Started process (PID=2872) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:31:48.954+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:31:48.990+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:31:48.977+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:31:49.975+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:31:49.973+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:31:52.359+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:31:52.483+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:31:52.481+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:31:52.558+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:31:52.557+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:31:52.825+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.970 seconds
[2025-09-11T14:33:02.191+0000] {processor.py:161} INFO - Started process (PID=2893) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:33:02.205+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:33:02.237+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:33:02.226+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:33:03.562+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:33:03.559+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:33:05.864+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:33:05.988+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:33:05.986+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:33:06.061+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:33:06.060+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:33:06.360+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.261 seconds
[2025-09-11T14:33:47.145+0000] {processor.py:161} INFO - Started process (PID=2909) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:33:47.158+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:33:47.178+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:33:47.175+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:33:48.268+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:33:48.265+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:33:50.653+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:33:50.822+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:33:50.820+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:33:50.884+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:33:50.883+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:33:51.188+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.163 seconds
[2025-09-11T14:34:37.716+0000] {processor.py:161} INFO - Started process (PID=2924) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:34:37.722+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:34:37.733+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:34:37.731+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:34:38.417+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:34:38.414+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:34:40.105+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:34:40.267+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:34:40.265+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:34:40.340+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:34:40.339+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:34:40.612+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.937 seconds
[2025-09-11T14:35:29.326+0000] {processor.py:161} INFO - Started process (PID=2939) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:35:29.337+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:35:29.361+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:35:29.357+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:35:30.366+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:35:30.364+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:35:33.922+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:35:34.006+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:35:34.005+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:35:34.069+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:35:34.068+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:35:34.252+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.016 seconds
[2025-09-11T14:36:24.908+0000] {processor.py:161} INFO - Started process (PID=2954) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:36:24.912+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:36:24.927+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:36:24.926+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:36:25.379+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:36:25.377+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:36:26.881+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:36:27.038+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:36:27.036+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:36:27.090+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:36:27.086+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:36:27.334+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.450 seconds
[2025-09-11T14:37:09.487+0000] {processor.py:161} INFO - Started process (PID=2969) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:37:09.493+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:37:09.506+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:37:09.504+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:37:10.092+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:37:10.090+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:37:12.358+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:37:12.494+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:37:12.492+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:37:12.555+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:37:12.554+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:37:12.828+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.385 seconds
[2025-09-11T14:38:05.081+0000] {processor.py:161} INFO - Started process (PID=2988) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:38:05.086+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:38:05.098+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:38:05.096+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:38:05.494+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:38:05.493+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:38:06.247+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:38:06.315+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:38:06.312+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:38:06.338+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:38:06.338+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:38:06.478+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.425 seconds
[2025-09-11T14:38:54.290+0000] {processor.py:161} INFO - Started process (PID=3003) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:38:54.294+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:38:54.301+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:38:54.300+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:38:54.750+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:38:54.749+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:38:55.877+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:38:55.942+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:38:55.941+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:38:55.966+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:38:55.966+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:38:56.097+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.830 seconds
[2025-09-11T14:39:41.520+0000] {processor.py:161} INFO - Started process (PID=3020) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:39:41.533+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:39:41.561+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:39:41.554+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:39:42.870+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:39:42.866+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:39:45.393+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:39:45.482+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:39:45.481+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:39:45.517+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:39:45.517+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:39:45.696+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.298 seconds
[2025-09-11T14:40:29.183+0000] {processor.py:161} INFO - Started process (PID=3035) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:40:29.185+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:40:29.190+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:40:29.189+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:40:29.443+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:40:29.443+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:40:32.071+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:40:32.383+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:40:32.378+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:40:32.516+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:40:32.515+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:40:33.181+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.012 seconds
[2025-09-11T14:41:27.352+0000] {processor.py:161} INFO - Started process (PID=3052) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:41:27.360+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:41:27.388+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:41:27.385+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:41:28.715+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:41:28.711+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:41:31.618+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:41:31.731+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:41:31.728+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:41:31.772+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:41:31.771+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:41:31.972+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.686 seconds
[2025-09-11T14:42:18.550+0000] {processor.py:161} INFO - Started process (PID=3068) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:42:18.559+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:42:18.583+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:42:18.579+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:42:19.516+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:42:19.510+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:42:22.813+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:42:23.069+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:42:23.067+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:42:23.112+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:42:23.111+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:42:23.335+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.894 seconds
[2025-09-11T14:43:16.809+0000] {processor.py:161} INFO - Started process (PID=3087) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:43:16.820+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:43:16.850+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:43:16.847+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:43:17.902+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:43:17.900+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:43:20.721+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:43:20.942+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:43:20.941+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:43:21.020+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:43:21.019+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:43:21.354+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.639 seconds
[2025-09-11T14:44:05.511+0000] {processor.py:161} INFO - Started process (PID=3103) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:44:05.521+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:44:05.540+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:44:05.537+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:44:06.068+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:44:06.066+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:44:07.792+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:44:07.896+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:44:07.892+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:44:07.938+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:44:07.937+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:44:08.218+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.774 seconds
[2025-09-11T14:44:55.500+0000] {processor.py:161} INFO - Started process (PID=3119) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:44:55.503+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:44:55.510+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:44:55.509+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:44:55.884+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:44:55.883+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:44:56.947+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:44:57.020+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:44:57.019+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:44:57.054+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:44:57.053+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:44:57.196+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.715 seconds
[2025-09-11T14:45:42.274+0000] {processor.py:161} INFO - Started process (PID=3136) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:45:42.281+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:45:42.305+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:45:42.304+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:45:43.037+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:45:43.036+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:45:43.945+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:45:44.021+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:45:44.020+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:45:44.054+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:45:44.054+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:45:44.217+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.011 seconds
[2025-09-11T14:46:27.317+0000] {processor.py:161} INFO - Started process (PID=3151) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:46:27.327+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:46:27.357+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:46:27.350+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:46:28.487+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:46:28.485+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:46:30.523+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:46:30.686+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:46:30.684+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:46:30.770+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:46:30.769+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:46:31.127+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.873 seconds
[2025-09-11T14:47:09.621+0000] {processor.py:161} INFO - Started process (PID=3166) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:47:09.629+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:47:09.654+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:47:09.649+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:47:10.631+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:47:10.628+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:47:13.739+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:47:13.876+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:47:13.873+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:47:13.930+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:47:13.929+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:47:14.969+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.403 seconds
[2025-09-11T14:48:05.167+0000] {processor.py:161} INFO - Started process (PID=3182) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:48:05.169+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:48:05.175+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:48:05.173+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:48:05.465+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:48:05.464+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:48:06.551+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:48:06.677+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:48:06.675+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:48:06.711+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:48:06.711+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:48:06.857+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.706 seconds
[2025-09-11T14:48:48.872+0000] {processor.py:161} INFO - Started process (PID=3197) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:48:48.880+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:48:48.899+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:48:48.896+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:48:50.062+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:48:50.058+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:48:52.576+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:48:52.753+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:48:52.750+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:48:52.887+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:48:52.886+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:48:53.512+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.712 seconds
[2025-09-11T14:49:33.280+0000] {processor.py:161} INFO - Started process (PID=3212) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:49:33.284+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:49:33.292+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:49:33.290+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:49:33.700+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:49:33.698+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:49:35.355+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:49:35.463+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:49:35.462+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:49:35.503+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:49:35.502+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:49:35.694+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.470 seconds
[2025-09-11T14:50:21.026+0000] {processor.py:161} INFO - Started process (PID=3231) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:50:21.031+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:50:21.039+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:50:21.037+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:50:21.453+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:50:21.452+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:50:23.413+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:50:23.549+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:50:23.548+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:50:23.599+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:50:23.598+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:50:23.791+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.793 seconds
[2025-09-11T14:51:22.105+0000] {processor.py:161} INFO - Started process (PID=3250) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:51:22.115+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:51:22.142+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:51:22.138+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:51:23.851+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:51:23.849+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:51:26.054+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:51:26.199+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:51:26.193+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:51:26.284+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:51:26.283+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:51:26.731+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.673 seconds
[2025-09-11T14:52:26.985+0000] {processor.py:161} INFO - Started process (PID=3270) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:52:26.989+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:52:26.998+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:52:26.996+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:52:27.389+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:52:27.388+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:52:28.810+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:52:28.923+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:52:28.922+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:52:28.970+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:52:28.969+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:52:29.179+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.218 seconds
[2025-09-11T14:53:23.522+0000] {processor.py:161} INFO - Started process (PID=3288) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:53:23.525+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:53:23.534+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:53:23.531+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:53:23.880+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:53:23.879+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:53:25.270+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:53:25.334+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:53:25.333+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:53:25.368+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:53:25.367+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:53:25.497+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.000 seconds
[2025-09-11T14:54:12.983+0000] {processor.py:161} INFO - Started process (PID=3304) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:54:12.998+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:54:13.046+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:54:13.042+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:54:15.132+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:54:15.127+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:54:16.922+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:54:17.058+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:54:17.057+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:54:17.121+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:54:17.120+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:54:17.337+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.446 seconds
[2025-09-11T14:55:10.336+0000] {processor.py:161} INFO - Started process (PID=3324) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:55:10.344+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:55:10.360+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:55:10.357+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:55:11.326+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:55:11.325+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:55:13.571+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:55:13.652+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:55:13.651+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:55:13.685+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:55:13.685+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:55:13.993+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.728 seconds
[2025-09-11T14:56:01.156+0000] {processor.py:161} INFO - Started process (PID=3339) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:56:01.166+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:56:01.180+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:56:01.178+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:56:01.798+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:56:01.796+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:56:03.157+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:56:03.261+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:56:03.260+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:56:03.365+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:56:03.364+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:56:03.704+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.608 seconds
[2025-09-11T14:57:05.800+0000] {processor.py:161} INFO - Started process (PID=3359) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:57:05.811+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:57:05.835+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:57:05.832+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:57:07.021+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:57:07.019+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:57:09.404+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:57:09.545+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:57:09.544+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:57:09.604+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:57:09.603+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:57:09.882+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.155 seconds
[2025-09-11T14:57:52.995+0000] {processor.py:161} INFO - Started process (PID=3374) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:57:52.999+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:57:53.011+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:57:53.009+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:57:53.385+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:57:53.383+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:57:54.799+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:57:54.913+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:57:54.912+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:57:54.994+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:57:54.993+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:57:55.172+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.207 seconds
[2025-09-11T14:59:01.556+0000] {processor.py:161} INFO - Started process (PID=3395) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:59:01.566+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:59:01.590+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:59:01.584+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:59:02.615+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:59:02.612+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:59:06.118+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:59:06.252+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:59:06.251+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:59:06.350+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:59:06.343+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:59:06.599+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.132 seconds
[2025-09-11T14:59:51.160+0000] {processor.py:161} INFO - Started process (PID=3411) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:59:51.164+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T14:59:51.171+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:59:51.170+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:59:51.557+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:59:51.555+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T14:59:53.348+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T14:59:53.455+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:59:53.454+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T14:59:53.502+0000] {logging_mixin.py:188} INFO - [2025-09-11T14:59:53.501+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T14:59:53.758+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.624 seconds
[2025-09-11T15:00:42.338+0000] {processor.py:161} INFO - Started process (PID=3428) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:00:42.351+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:00:42.376+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:00:42.372+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:00:43.466+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:00:43.464+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:00:46.065+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:00:46.237+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:00:46.235+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:00:46.332+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:00:46.331+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:00:46.778+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.517 seconds
[2025-09-11T15:01:43.536+0000] {processor.py:161} INFO - Started process (PID=3448) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:01:43.539+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:01:43.549+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:01:43.547+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:01:44.106+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:01:44.105+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:01:45.451+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:01:45.528+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:01:45.527+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:01:45.597+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:01:45.595+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:01:45.755+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.242 seconds
[2025-09-11T15:02:27.689+0000] {processor.py:161} INFO - Started process (PID=3463) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:02:27.692+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:02:27.699+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:02:27.697+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:02:27.968+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:02:27.967+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:02:29.191+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:02:29.270+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:02:29.269+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:02:29.306+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:02:29.306+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:02:29.452+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.784 seconds
[2025-09-11T15:03:16.636+0000] {processor.py:161} INFO - Started process (PID=3477) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:03:16.640+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:03:16.648+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:03:16.647+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:03:16.934+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:03:16.933+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:03:17.759+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:03:17.820+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:03:17.819+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:03:17.851+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:03:17.851+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:03:17.997+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.381 seconds
[2025-09-11T15:04:09.943+0000] {processor.py:161} INFO - Started process (PID=3494) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:04:09.947+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:04:09.954+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:04:09.953+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:04:10.369+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:04:10.368+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:04:11.498+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:04:11.557+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:04:11.556+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:04:11.583+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:04:11.583+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:04:11.723+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.800 seconds
[2025-09-11T15:05:00.776+0000] {processor.py:161} INFO - Started process (PID=3510) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:05:00.782+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:05:00.794+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:05:00.792+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:05:01.796+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:05:01.795+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:05:03.308+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:05:03.376+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:05:03.375+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:05:03.411+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:05:03.410+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:05:03.569+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.830 seconds
[2025-09-11T15:05:44.054+0000] {processor.py:161} INFO - Started process (PID=3525) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:05:44.062+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:05:44.072+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:05:44.069+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:05:44.572+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:05:44.571+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:05:45.712+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:05:45.810+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:05:45.809+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:05:45.870+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:05:45.870+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:05:46.061+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.036 seconds
[2025-09-11T15:06:34.519+0000] {processor.py:161} INFO - Started process (PID=3542) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:06:34.526+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:06:34.532+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:06:34.531+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:06:34.884+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:06:34.883+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:06:35.970+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:06:36.052+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:06:36.051+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:06:36.090+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:06:36.089+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:06:36.312+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.816 seconds
[2025-09-11T15:07:24.576+0000] {processor.py:161} INFO - Started process (PID=3557) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:07:24.580+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:07:24.596+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:07:24.595+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:07:25.061+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:07:25.060+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:07:26.351+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:07:26.463+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:07:26.461+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:07:26.512+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:07:26.511+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:07:26.700+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.158 seconds
[2025-09-11T15:08:20.802+0000] {processor.py:161} INFO - Started process (PID=3576) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:08:20.821+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:08:20.844+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:08:20.841+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:08:21.834+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:08:21.831+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:08:24.056+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:08:24.273+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:08:24.271+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:08:24.430+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:08:24.429+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:08:24.803+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.058 seconds
[2025-09-11T15:09:15.089+0000] {processor.py:161} INFO - Started process (PID=3592) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:09:15.103+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:09:15.121+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:09:15.119+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:09:15.636+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:09:15.635+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:09:17.037+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:09:17.112+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:09:17.111+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:09:17.147+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:09:17.147+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:09:17.361+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.325 seconds
[2025-09-11T15:09:52.560+0000] {processor.py:161} INFO - Started process (PID=3607) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:09:52.563+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:09:52.568+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:09:52.567+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:09:52.881+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:09:52.879+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:09:53.788+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:09:53.852+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:09:53.851+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:09:53.880+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:09:53.880+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:09:54.027+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.483 seconds
[2025-09-11T15:11:00.286+0000] {processor.py:161} INFO - Started process (PID=3626) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:11:00.295+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:11:00.324+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:11:00.321+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:11:01.481+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:11:01.477+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:11:03.814+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:11:03.936+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:11:03.934+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:11:03.988+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:11:03.988+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:11:04.332+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.111 seconds
[2025-09-11T15:11:47.545+0000] {processor.py:161} INFO - Started process (PID=3641) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:11:47.547+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:11:47.552+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:11:47.551+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:11:47.778+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:11:47.777+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:11:50.721+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:11:50.990+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:11:50.988+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:11:51.116+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:11:51.114+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:11:51.467+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.935 seconds
[2025-09-11T15:12:42.318+0000] {processor.py:161} INFO - Started process (PID=3660) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:12:42.326+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:12:42.342+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:12:42.339+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:12:43.296+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:12:43.294+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:12:46.025+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:12:46.291+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:12:46.289+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:12:46.372+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:12:46.371+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:12:46.738+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.471 seconds
[2025-09-11T15:13:17.904+0000] {processor.py:161} INFO - Started process (PID=3675) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:13:17.906+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:13:17.910+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:13:17.910+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:13:18.856+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:13:18.854+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:13:22.170+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:13:22.484+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:13:22.473+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:13:22.587+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:13:22.586+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:13:22.910+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.020 seconds
[2025-09-11T15:14:16.404+0000] {processor.py:161} INFO - Started process (PID=3693) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:14:16.415+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:14:16.483+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:14:16.479+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:14:17.649+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:14:17.646+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:14:20.271+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:14:20.443+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:14:20.442+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:14:20.521+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:14:20.520+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:14:20.848+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.510 seconds
[2025-09-11T15:15:07.929+0000] {processor.py:161} INFO - Started process (PID=3709) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:15:07.939+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:15:07.950+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:15:07.948+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:15:08.836+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:15:08.832+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:15:10.659+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:15:10.786+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:15:10.784+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:15:10.866+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:15:10.862+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:15:11.152+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.307 seconds
[2025-09-11T15:16:13.123+0000] {processor.py:161} INFO - Started process (PID=3728) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:16:13.128+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:16:13.143+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:16:13.141+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:16:13.695+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:16:13.694+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:16:15.990+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:16:16.056+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:16:16.055+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:16:16.094+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:16:16.094+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:16:16.288+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.202 seconds
[2025-09-11T15:17:12.083+0000] {processor.py:161} INFO - Started process (PID=3748) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:17:12.095+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:17:12.130+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:17:12.118+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:17:13.412+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:17:13.401+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:17:15.644+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:17:15.714+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:17:15.713+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:17:15.746+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:17:15.745+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:17:15.931+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.939 seconds
[2025-09-11T15:18:06.190+0000] {processor.py:161} INFO - Started process (PID=3765) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:18:06.212+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:18:06.230+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:18:06.228+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:18:06.797+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:18:06.795+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:18:08.112+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:18:08.221+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:18:08.220+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:18:08.282+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:18:08.282+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:18:08.488+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.358 seconds
[2025-09-11T15:18:50.899+0000] {processor.py:161} INFO - Started process (PID=3781) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:18:50.910+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:18:50.928+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:18:50.925+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:18:51.971+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:18:51.968+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:18:55.805+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:18:55.932+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:18:55.931+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:18:55.972+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:18:55.972+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:18:56.188+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.362 seconds
[2025-09-11T15:19:52.978+0000] {processor.py:161} INFO - Started process (PID=3800) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:19:52.987+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:19:53.021+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:19:53.013+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:19:54.026+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:19:54.022+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:19:56.733+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:19:56.869+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:19:56.868+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:19:56.937+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:19:56.936+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:19:57.183+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.330 seconds
[2025-09-11T15:20:47.182+0000] {processor.py:161} INFO - Started process (PID=3818) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:20:47.340+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:20:47.400+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:20:47.399+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:20:48.112+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:20:48.111+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:20:50.736+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:20:50.822+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:20:50.821+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:20:50.854+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:20:50.854+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:20:51.006+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.869 seconds
[2025-09-11T15:21:32.023+0000] {processor.py:161} INFO - Started process (PID=3833) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:21:32.032+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:21:32.048+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:21:32.044+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:21:33.029+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:21:33.026+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:21:35.796+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:21:35.942+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:21:35.938+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:21:35.985+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:21:35.985+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:21:36.374+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.407 seconds
[2025-09-11T15:22:20.659+0000] {processor.py:161} INFO - Started process (PID=3848) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:22:20.671+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:22:20.703+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:22:20.700+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:22:21.536+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:22:21.533+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:22:25.071+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:22:25.201+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:22:25.200+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:22:25.247+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:22:25.246+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:22:25.497+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.893 seconds
[2025-09-11T15:23:08.625+0000] {processor.py:161} INFO - Started process (PID=3864) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:23:08.636+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:23:08.658+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:23:08.656+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:23:09.587+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:23:09.585+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:23:12.380+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:23:12.602+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:23:12.600+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:23:12.685+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:23:12.684+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:23:13.017+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.457 seconds
[2025-09-11T15:24:03.584+0000] {processor.py:161} INFO - Started process (PID=3884) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:24:03.594+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:24:03.621+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:24:03.616+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:24:05.116+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:24:05.113+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:24:07.443+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:24:07.527+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:24:07.526+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:24:07.563+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:24:07.562+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:24:07.807+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.284 seconds
[2025-09-11T15:25:15.971+0000] {processor.py:161} INFO - Started process (PID=3900) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:25:15.986+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:25:16.025+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:25:16.022+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:25:17.586+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:25:17.580+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:25:19.524+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:25:19.617+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:25:19.616+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:25:19.664+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:25:19.664+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:25:20.365+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.543 seconds
[2025-09-11T15:26:02.728+0000] {processor.py:161} INFO - Started process (PID=3915) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:26:02.742+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:26:02.764+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:26:02.760+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:26:03.616+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:26:03.613+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:26:06.864+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:26:07.681+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:26:07.680+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:26:07.717+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:26:07.716+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:26:07.898+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.228 seconds
[2025-09-11T15:26:56.515+0000] {processor.py:161} INFO - Started process (PID=3932) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:26:56.518+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:26:56.526+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:26:56.525+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:26:56.769+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:26:56.768+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:26:57.878+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:26:57.962+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:26:57.961+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:26:57.990+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:26:57.989+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:26:58.122+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.624 seconds
[2025-09-11T15:27:44.347+0000] {processor.py:161} INFO - Started process (PID=3948) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:27:44.355+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:27:44.378+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:27:44.374+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:27:45.535+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:27:45.533+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:27:48.727+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:27:48.885+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:27:48.884+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:27:48.950+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:27:48.950+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:27:49.260+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.964 seconds
[2025-09-11T15:28:29.116+0000] {processor.py:161} INFO - Started process (PID=3963) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:28:29.170+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:28:29.188+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:28:29.178+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:28:29.528+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:28:29.527+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:28:31.262+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:28:31.421+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:28:31.418+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:28:31.488+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:28:31.487+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:28:31.822+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.759 seconds
[2025-09-11T15:29:10.165+0000] {processor.py:161} INFO - Started process (PID=3978) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:29:10.176+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:29:10.200+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:29:10.196+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:29:11.602+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:29:11.589+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:29:14.512+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:29:15.073+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:29:15.068+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:29:15.587+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:29:15.587+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:29:15.734+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.636 seconds
[2025-09-11T15:30:09.788+0000] {processor.py:161} INFO - Started process (PID=3997) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:30:09.796+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:30:09.813+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:30:09.810+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:30:10.716+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:30:10.713+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:30:13.699+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:30:13.899+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:30:13.898+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:30:13.963+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:30:13.963+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:30:15.170+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.425 seconds
[2025-09-11T15:31:15.002+0000] {processor.py:161} INFO - Started process (PID=4015) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:31:15.005+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:31:15.013+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:31:15.012+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:31:15.269+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:31:15.268+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:31:17.805+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:31:17.955+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:31:17.954+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:31:18.895+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:31:18.894+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:31:19.185+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.199 seconds
[2025-09-11T15:31:57.945+0000] {processor.py:161} INFO - Started process (PID=4030) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:31:57.950+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:31:57.958+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:31:57.957+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:31:58.446+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:31:58.445+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:32:00.171+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:32:00.268+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:32:00.267+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:32:00.307+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:32:00.306+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:32:00.504+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.587 seconds
[2025-09-11T15:32:35.426+0000] {processor.py:161} INFO - Started process (PID=4045) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:32:35.436+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:32:35.449+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:32:35.447+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:32:35.920+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:32:35.919+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:32:37.824+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:32:37.909+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:32:37.908+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:32:37.948+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:32:37.947+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:32:38.890+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.513 seconds
[2025-09-11T15:33:29.463+0000] {processor.py:161} INFO - Started process (PID=4060) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:33:29.467+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:33:29.482+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:33:29.481+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:33:30.092+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:33:30.091+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:33:32.913+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:33:33.758+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:33:33.757+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:33:33.850+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:33:33.850+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:33:34.575+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.161 seconds
[2025-09-11T15:34:37.328+0000] {processor.py:161} INFO - Started process (PID=4081) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:34:37.332+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:34:37.343+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:34:37.341+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:34:37.739+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:34:37.737+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:34:40.283+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:34:40.371+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:34:40.370+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:34:40.420+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:34:40.419+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:34:40.628+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.337 seconds
[2025-09-11T15:35:43.035+0000] {processor.py:161} INFO - Started process (PID=4101) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:35:43.051+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:35:43.074+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:35:43.071+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:35:43.985+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:35:43.983+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:35:46.767+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:35:47.451+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:35:47.450+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:35:47.487+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:35:47.487+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:35:47.735+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.776 seconds
[2025-09-11T15:36:54.034+0000] {processor.py:161} INFO - Started process (PID=4122) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:36:54.043+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:36:54.071+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:36:54.065+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:36:55.635+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:36:55.632+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:36:58.155+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:36:58.285+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:36:58.283+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:36:58.332+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:36:58.331+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:36:58.584+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.621 seconds
[2025-09-11T15:37:53.171+0000] {processor.py:161} INFO - Started process (PID=4138) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:37:53.178+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:37:53.188+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:37:53.186+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:37:53.629+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:37:53.627+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:37:55.745+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:37:55.830+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:37:55.829+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:37:55.861+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:37:55.861+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:37:56.054+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.910 seconds
[2025-09-11T15:38:52.066+0000] {processor.py:161} INFO - Started process (PID=4156) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:38:52.075+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:38:52.085+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:38:52.083+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:38:52.679+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:38:52.678+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:38:54.292+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:38:54.386+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:38:54.386+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:38:54.434+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:38:54.434+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:38:54.672+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.637 seconds
[2025-09-11T15:40:00.901+0000] {processor.py:161} INFO - Started process (PID=4178) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:40:00.920+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:40:00.952+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:40:00.940+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:40:02.255+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:40:02.252+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:40:05.494+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:40:05.586+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:40:05.585+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:40:05.625+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:40:05.624+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:40:05.797+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.992 seconds
[2025-09-11T15:40:49.251+0000] {processor.py:161} INFO - Started process (PID=4194) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:40:49.256+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:40:49.266+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:40:49.264+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:40:49.785+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:40:49.783+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:40:52.916+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:40:53.056+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:40:53.055+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:40:53.105+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:40:53.104+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:40:53.354+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.143 seconds
[2025-09-11T15:41:34.502+0000] {processor.py:161} INFO - Started process (PID=4208) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:41:34.516+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:41:34.525+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:41:34.524+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:41:34.837+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:41:34.836+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:41:36.501+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:41:36.588+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:41:36.587+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:41:36.632+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:41:36.632+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:41:36.787+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.305 seconds
[2025-09-11T15:42:15.342+0000] {processor.py:161} INFO - Started process (PID=4223) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:42:15.345+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:42:15.352+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:42:15.351+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:42:15.681+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:42:15.680+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:42:19.845+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:42:20.036+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:42:20.034+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:42:20.105+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:42:20.104+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:42:20.566+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.248 seconds
[2025-09-11T15:43:13.738+0000] {processor.py:161} INFO - Started process (PID=4240) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:43:13.744+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:43:13.753+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:43:13.751+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:43:14.320+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:43:14.319+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:43:17.072+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:43:17.304+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:43:17.303+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:43:17.384+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:43:17.383+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:43:17.818+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.108 seconds
[2025-09-11T15:44:19.581+0000] {processor.py:161} INFO - Started process (PID=4260) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:44:19.586+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:44:19.595+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:44:19.593+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:44:20.121+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:44:20.120+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:44:22.563+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:44:22.742+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:44:22.740+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:44:22.826+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:44:22.826+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:44:23.041+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.493 seconds
[2025-09-11T15:45:14.888+0000] {processor.py:161} INFO - Started process (PID=4277) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:45:14.890+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:45:14.898+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:45:14.897+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:45:15.142+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:45:15.141+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:45:17.027+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:45:17.288+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:45:17.286+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:45:17.360+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:45:17.357+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:45:18.631+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.767 seconds
[2025-09-11T15:46:14.405+0000] {processor.py:161} INFO - Started process (PID=4296) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:46:14.421+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:46:14.438+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:46:14.436+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:46:15.494+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:46:15.492+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:46:17.442+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:46:17.519+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:46:17.518+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:46:17.546+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:46:17.545+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:46:17.728+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.383 seconds
[2025-09-11T15:47:05.211+0000] {processor.py:161} INFO - Started process (PID=4312) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:47:05.215+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:47:05.224+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:47:05.221+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:47:05.615+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:47:05.613+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:47:07.529+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:47:07.743+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:47:07.737+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:47:07.834+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:47:07.833+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:47:08.552+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.366 seconds
[2025-09-11T15:47:54.272+0000] {processor.py:161} INFO - Started process (PID=4328) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:47:54.312+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:47:54.353+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:47:54.349+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:47:56.120+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:47:56.117+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:47:58.731+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:47:58.829+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:47:58.828+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:47:58.870+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:47:58.870+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:47:59.099+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.953 seconds
[2025-09-11T15:48:49.417+0000] {processor.py:161} INFO - Started process (PID=4345) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:48:49.422+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:48:49.430+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:48:49.428+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:48:49.866+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:48:49.864+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:48:51.758+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:48:51.835+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:48:51.834+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:48:51.864+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:48:51.864+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:48:52.046+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.652 seconds
[2025-09-11T15:49:40.553+0000] {processor.py:161} INFO - Started process (PID=4360) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:49:40.559+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:49:40.566+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:49:40.565+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:49:40.926+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:49:40.924+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:49:42.484+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:49:42.576+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:49:42.575+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:49:42.618+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:49:42.617+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:49:42.882+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.350 seconds
[2025-09-11T15:50:52.562+0000] {processor.py:161} INFO - Started process (PID=4382) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:50:52.589+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:50:52.614+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:50:52.608+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:50:54.164+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:50:54.160+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:50:56.940+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:50:57.036+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:50:57.036+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:50:57.073+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:50:57.072+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:50:57.248+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.790 seconds
[2025-09-11T15:51:56.317+0000] {processor.py:161} INFO - Started process (PID=4400) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:51:56.321+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:51:56.335+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:51:56.333+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:51:57.205+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:51:57.203+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:51:58.198+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:51:58.296+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:51:58.293+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:51:58.336+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:51:58.335+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:51:58.560+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.301 seconds
[2025-09-11T15:52:56.692+0000] {processor.py:161} INFO - Started process (PID=4420) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:52:56.705+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:52:56.732+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:52:56.727+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:52:57.777+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:52:57.775+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:53:01.198+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:53:01.317+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:53:01.316+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:53:01.365+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:53:01.365+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:53:01.665+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.061 seconds
[2025-09-11T15:53:57.103+0000] {processor.py:161} INFO - Started process (PID=4438) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:53:57.127+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:53:57.160+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:53:57.157+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:53:59.163+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:53:59.161+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:54:01.192+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:54:01.304+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:54:01.303+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:54:01.350+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:54:01.348+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:54:01.592+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.597 seconds
[2025-09-11T15:55:04.197+0000] {processor.py:161} INFO - Started process (PID=4459) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:55:04.202+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:55:04.212+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:55:04.210+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:55:04.614+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:55:04.613+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:55:06.474+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:55:07.198+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:55:07.197+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:55:07.234+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:55:07.233+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:55:07.430+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.270 seconds
[2025-09-11T15:56:15.801+0000] {processor.py:161} INFO - Started process (PID=4478) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:56:15.839+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:56:15.878+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:56:15.875+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:56:17.416+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:56:17.415+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:56:19.141+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:56:19.249+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:56:19.247+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:56:19.287+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:56:19.286+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:56:19.524+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.871 seconds
[2025-09-11T15:57:13.448+0000] {processor.py:161} INFO - Started process (PID=4494) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:57:13.475+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:57:13.533+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:57:13.517+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:57:15.728+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:57:15.727+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:57:17.387+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:57:17.469+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:57:17.468+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:57:17.501+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:57:17.501+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:57:17.702+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.374 seconds
[2025-09-11T15:58:08.583+0000] {processor.py:161} INFO - Started process (PID=4513) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:58:08.591+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:58:08.599+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:58:08.598+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:58:09.422+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:58:09.421+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:58:10.531+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:58:10.597+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:58:10.596+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:58:10.620+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:58:10.619+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:58:10.821+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.269 seconds
[2025-09-11T15:58:56.276+0000] {processor.py:161} INFO - Started process (PID=4529) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:58:56.287+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:58:56.300+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:58:56.298+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:58:57.356+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:58:57.355+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:58:59.958+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:59:00.081+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:59:00.080+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:59:00.120+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:59:00.120+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:59:00.467+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.259 seconds
[2025-09-11T15:59:51.834+0000] {processor.py:161} INFO - Started process (PID=4546) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:59:51.837+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T15:59:51.846+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:59:51.844+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:59:52.633+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:59:52.632+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T15:59:53.853+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T15:59:53.916+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:59:53.915+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T15:59:53.939+0000] {logging_mixin.py:188} INFO - [2025-09-11T15:59:53.939+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T15:59:54.086+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.269 seconds
[2025-09-11T16:00:53.406+0000] {processor.py:161} INFO - Started process (PID=4564) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T16:00:53.417+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T16:00:53.445+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:00:53.440+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T16:00:56.138+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:00:56.137+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T16:00:57.597+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T16:00:57.672+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:00:57.671+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T16:00:57.705+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:00:57.704+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T16:00:57.879+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.571 seconds
[2025-09-11T16:02:04.525+0000] {processor.py:161} INFO - Started process (PID=4585) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T16:02:04.539+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T16:02:04.546+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:02:04.545+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T16:02:05.379+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:02:05.379+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T16:02:06.595+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T16:02:06.674+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:02:06.673+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T16:02:06.708+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:02:06.707+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T16:02:06.855+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.397 seconds
[2025-09-11T16:03:08.622+0000] {processor.py:161} INFO - Started process (PID=4603) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T16:03:08.631+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T16:03:08.647+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:03:08.643+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T16:03:09.573+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:03:09.569+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T16:03:12.275+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T16:03:12.579+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:03:12.575+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T16:03:12.652+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:03:12.651+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T16:03:13.004+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.443 seconds
[2025-09-11T16:03:52.545+0000] {processor.py:161} INFO - Started process (PID=4618) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T16:03:52.551+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T16:03:52.558+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:03:52.557+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T16:03:52.844+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:03:52.843+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T16:03:53.823+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T16:03:53.941+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:03:53.939+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T16:03:53.964+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:03:53.963+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T16:03:54.075+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.550 seconds
[2025-09-11T16:04:40.796+0000] {processor.py:161} INFO - Started process (PID=4637) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T16:04:40.806+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T16:04:40.835+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:04:40.826+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T16:04:41.685+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:04:41.684+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T16:04:44.688+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T16:04:45.176+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:04:45.175+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T16:04:45.386+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:04:45.385+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T16:04:45.606+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.881 seconds
[2025-09-11T16:05:34.635+0000] {processor.py:161} INFO - Started process (PID=4652) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T16:05:34.639+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T16:05:34.649+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:05:34.647+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T16:05:35.174+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:05:35.170+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T16:05:37.080+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T16:05:37.234+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:05:37.232+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T16:05:37.318+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:05:37.317+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T16:05:37.593+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.996 seconds
[2025-09-11T16:06:15.347+0000] {processor.py:161} INFO - Started process (PID=4667) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T16:06:15.350+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T16:06:15.356+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:06:15.354+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T16:06:15.678+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:06:15.677+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T16:06:17.031+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T16:06:17.110+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:06:17.108+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T16:06:17.147+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:06:17.147+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T16:06:17.305+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.977 seconds
[2025-09-11T16:06:57.733+0000] {processor.py:161} INFO - Started process (PID=4684) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T16:06:57.751+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T16:06:57.784+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:06:57.781+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T16:06:59.533+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:06:59.532+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T16:07:01.304+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T16:07:01.437+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:07:01.435+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T16:07:01.475+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:07:01.475+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T16:07:02.047+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.380 seconds
[2025-09-11T16:09:10.985+0000] {processor.py:161} INFO - Started process (PID=4703) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T16:09:11.038+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T16:09:11.077+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:09:11.073+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T16:09:12.077+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:09:12.075+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T16:09:16.263+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T16:09:16.441+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:09:16.439+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T16:09:16.517+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:09:16.516+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T16:09:16.706+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.859 seconds
[2025-09-11T16:09:48.013+0000] {processor.py:161} INFO - Started process (PID=4718) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T16:09:48.037+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T16:09:48.073+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:09:48.071+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T16:09:49.297+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:09:49.295+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T16:09:51.150+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T16:09:51.299+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:09:51.298+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T16:09:51.354+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:09:51.354+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T16:09:51.588+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.734 seconds
[2025-09-11T16:10:22.596+0000] {processor.py:161} INFO - Started process (PID=4733) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T16:10:22.600+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T16:10:22.606+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:10:22.605+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T16:10:22.997+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:10:22.995+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T16:10:24.180+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T16:10:24.336+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:10:24.334+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T16:10:24.411+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:10:24.411+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T16:10:24.736+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.173 seconds
[2025-09-11T16:14:07.646+0000] {processor.py:161} INFO - Started process (PID=4749) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T16:14:07.670+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T16:14:07.680+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:14:07.679+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T16:14:11.664+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:14:11.663+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T16:14:16.540+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T16:14:17.540+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:14:17.539+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T16:14:17.979+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:14:17.978+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T16:14:22.335+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 14.731 seconds
[2025-09-11T16:22:33.094+0000] {processor.py:161} INFO - Started process (PID=4776) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T16:22:33.110+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T16:22:33.137+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:22:33.136+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T16:22:33.926+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:22:33.914+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T16:22:37.999+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T16:22:38.503+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:22:38.502+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T16:22:38.604+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:22:38.604+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T16:22:39.686+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 6.629 seconds
[2025-09-11T16:30:52.902+0000] {processor.py:161} INFO - Started process (PID=4803) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T16:30:52.936+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T16:30:52.999+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:30:52.998+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T16:30:58.714+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:30:58.704+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T16:31:03.821+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T16:31:05.055+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:31:05.054+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T16:31:05.425+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:31:05.424+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T16:31:07.100+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 14.224 seconds
[2025-09-11T16:40:16.120+0000] {processor.py:161} INFO - Started process (PID=4830) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T16:40:16.151+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T16:40:16.263+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:40:16.262+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T16:40:21.380+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:40:21.369+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T16:40:27.122+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T16:40:28.549+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:40:28.548+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T16:40:29.297+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:40:29.296+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T16:40:34.762+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 18.703 seconds
[2025-09-11T16:49:39.013+0000] {processor.py:161} INFO - Started process (PID=4858) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T16:49:39.024+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T16:49:39.053+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:49:39.051+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T16:49:43.372+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:49:43.371+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T16:49:48.917+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T16:49:50.016+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:49:50.014+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T16:49:50.804+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:49:50.803+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T16:49:55.162+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 16.189 seconds
[2025-09-11T16:58:10.633+0000] {processor.py:161} INFO - Started process (PID=4886) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T16:58:10.681+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T16:58:10.713+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:58:10.712+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T16:58:13.792+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:58:13.790+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T16:58:20.011+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T16:58:21.245+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:58:21.244+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T16:58:21.636+0000] {logging_mixin.py:188} INFO - [2025-09-11T16:58:21.636+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T16:58:23.850+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 13.256 seconds
[2025-09-11T17:02:41.595+0000] {processor.py:161} INFO - Started process (PID=4900) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:02:41.649+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:02:41.677+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:02:41.675+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:02:45.863+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:02:45.836+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:02:52.208+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:02:53.388+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:02:53.387+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:02:53.865+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:02:53.864+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:03:00.272+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 18.708 seconds
[2025-09-11T17:08:26.448+0000] {processor.py:161} INFO - Started process (PID=4915) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:08:26.494+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:08:26.549+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:08:26.548+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:08:31.261+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:08:31.260+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:08:36.904+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:08:37.825+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:08:37.821+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:08:38.210+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:08:38.210+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:08:43.928+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 17.517 seconds
[2025-09-11T17:13:33.836+0000] {processor.py:161} INFO - Started process (PID=4929) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:13:33.840+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:13:33.852+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:13:33.851+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:13:34.491+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:13:34.490+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:13:37.647+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:13:37.853+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:13:37.852+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:13:37.940+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:13:37.939+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:13:38.157+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.351 seconds
[2025-09-11T17:14:20.986+0000] {processor.py:161} INFO - Started process (PID=4945) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:14:20.989+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:14:20.996+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:14:20.995+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:14:21.559+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:14:21.548+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:14:24.056+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:14:24.247+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:14:24.245+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:14:24.405+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:14:24.404+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:14:24.931+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.983 seconds
[2025-09-11T17:15:16.606+0000] {processor.py:161} INFO - Started process (PID=4964) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:15:16.616+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:15:16.628+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:15:16.627+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:15:17.178+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:15:17.177+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:15:18.198+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:15:18.319+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:15:18.319+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:15:18.368+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:15:18.367+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:15:18.573+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.997 seconds
[2025-09-11T17:15:59.994+0000] {processor.py:161} INFO - Started process (PID=4979) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:15:59.997+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:16:00.002+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:16:00.001+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:16:00.507+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:16:00.506+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:16:02.042+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:16:02.172+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:16:02.171+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:16:02.233+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:16:02.232+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:16:06.708+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 6.729 seconds
[2025-09-11T17:17:13.077+0000] {processor.py:161} INFO - Started process (PID=4999) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:17:13.082+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:17:13.098+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:17:13.096+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:17:13.568+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:17:13.567+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:17:15.675+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:17:15.760+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:17:15.758+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:17:15.796+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:17:15.796+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:17:19.353+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 6.318 seconds
[2025-09-11T17:17:53.361+0000] {processor.py:161} INFO - Started process (PID=5014) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:17:53.370+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:17:53.399+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:17:53.386+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:17:54.779+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:17:54.777+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:17:57.419+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:17:57.500+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:17:57.499+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:17:57.540+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:17:57.539+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:17:57.714+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.449 seconds
[2025-09-11T17:18:32.994+0000] {processor.py:161} INFO - Started process (PID=5029) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:18:32.998+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:18:33.011+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:18:33.010+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:18:33.406+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:18:33.404+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:18:35.222+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:18:35.449+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:18:35.442+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:18:35.537+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:18:35.530+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:18:35.782+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.813 seconds
[2025-09-11T17:19:43.901+0000] {processor.py:161} INFO - Started process (PID=5050) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:19:43.906+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:19:43.928+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:19:43.925+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:19:45.562+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:19:45.552+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:19:48.009+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:19:48.154+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:19:48.152+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:19:48.246+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:19:48.242+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:19:48.696+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.842 seconds
[2025-09-11T17:20:42.823+0000] {processor.py:161} INFO - Started process (PID=5069) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:20:42.826+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:20:42.833+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:20:42.832+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:20:43.155+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:20:43.154+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:20:44.174+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:20:44.303+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:20:44.302+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:20:44.366+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:20:44.365+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:20:44.609+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.813 seconds
[2025-09-11T17:21:28.219+0000] {processor.py:161} INFO - Started process (PID=5086) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:21:28.223+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:21:28.235+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:21:28.233+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:21:28.727+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:21:28.725+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:21:30.257+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:21:30.425+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:21:30.423+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:21:30.488+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:21:30.487+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:21:30.828+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.645 seconds
[2025-09-11T17:22:03.047+0000] {processor.py:161} INFO - Started process (PID=5101) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:22:03.055+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:22:03.083+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:22:03.077+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:22:04.066+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:22:04.063+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:22:07.252+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:22:07.368+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:22:07.366+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:22:07.423+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:22:07.422+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:22:07.635+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.703 seconds
[2025-09-11T17:22:44.662+0000] {processor.py:161} INFO - Started process (PID=5117) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:22:44.676+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:22:44.700+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:22:44.697+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:22:45.651+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:22:45.648+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:22:47.992+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:22:48.140+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:22:48.138+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:22:48.220+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:22:48.220+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:22:48.488+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.898 seconds
[2025-09-11T17:23:31.320+0000] {processor.py:161} INFO - Started process (PID=5132) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:23:31.323+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:23:31.328+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:23:31.327+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:23:31.629+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:23:31.628+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:23:32.841+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:23:32.956+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:23:32.955+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:23:33.004+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:23:33.004+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:23:33.202+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.899 seconds
[2025-09-11T17:24:13.523+0000] {processor.py:161} INFO - Started process (PID=5147) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:24:13.527+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:24:13.536+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:24:13.534+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:24:14.031+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:24:14.030+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:24:15.754+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:24:15.842+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:24:15.841+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:24:15.889+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:24:15.888+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:24:16.127+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.634 seconds
[2025-09-11T17:25:09.855+0000] {processor.py:161} INFO - Started process (PID=5166) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:25:09.871+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:25:09.908+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:25:09.895+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:25:11.165+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:25:11.163+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:25:12.924+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:25:13.048+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:25:13.047+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:25:13.100+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:25:13.100+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:25:13.652+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.891 seconds
[2025-09-11T17:25:57.796+0000] {processor.py:161} INFO - Started process (PID=5182) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:25:57.800+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:25:57.808+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:25:57.807+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:25:58.103+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:25:58.101+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:25:59.741+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:25:59.895+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:25:59.894+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:25:59.950+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:25:59.949+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:26:00.134+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.365 seconds
[2025-09-11T17:26:41.127+0000] {processor.py:161} INFO - Started process (PID=5197) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:26:41.137+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:26:41.149+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:26:41.148+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:26:41.765+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:26:41.764+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:26:43.531+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:26:43.610+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:26:43.609+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:26:43.644+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:26:43.644+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:26:47.297+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 6.195 seconds
[2025-09-11T17:27:24.756+0000] {processor.py:161} INFO - Started process (PID=5212) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:27:24.763+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:27:24.769+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:27:24.768+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:27:25.083+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:27:25.082+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:27:26.323+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:27:26.506+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:27:26.501+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:27:26.570+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:27:26.570+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:27:26.858+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.124 seconds
[2025-09-11T17:28:06.750+0000] {processor.py:161} INFO - Started process (PID=5229) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:28:06.755+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:28:06.765+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:28:06.763+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:28:07.101+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:28:07.100+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:28:08.105+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:28:08.209+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:28:08.208+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:28:08.260+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:28:08.259+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:28:08.411+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.682 seconds
[2025-09-11T17:28:47.217+0000] {processor.py:161} INFO - Started process (PID=5246) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:28:47.220+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:28:47.225+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:28:47.224+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:28:47.480+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:28:47.479+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:28:48.620+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:28:48.722+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:28:48.721+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:28:48.800+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:28:48.799+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:28:49.076+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.875 seconds
[2025-09-11T17:29:35.768+0000] {processor.py:161} INFO - Started process (PID=5263) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:29:35.784+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:29:35.799+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:29:35.796+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:29:37.072+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:29:37.061+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:29:38.918+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:29:39.086+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:29:39.085+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:29:39.135+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:29:39.135+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:29:39.284+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.568 seconds
[2025-09-11T17:30:11.252+0000] {processor.py:161} INFO - Started process (PID=5278) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:30:11.255+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:30:11.263+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:30:11.261+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:30:11.640+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:30:11.638+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:30:13.278+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:30:13.392+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:30:13.391+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:30:13.448+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:30:13.448+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:30:13.702+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.478 seconds
[2025-09-11T17:31:07.040+0000] {processor.py:161} INFO - Started process (PID=5296) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:31:07.043+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:31:07.049+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:31:07.048+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:31:07.360+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:31:07.359+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:31:08.628+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:31:08.722+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:31:08.721+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:31:08.765+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:31:08.765+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:31:08.941+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.918 seconds
[2025-09-11T17:31:45.996+0000] {processor.py:161} INFO - Started process (PID=5312) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:31:46.000+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:31:46.005+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:31:46.004+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:31:46.328+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:31:46.327+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:31:47.453+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:31:47.526+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:31:47.525+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:31:47.557+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:31:47.556+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:31:47.689+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.707 seconds
[2025-09-11T17:32:25.242+0000] {processor.py:161} INFO - Started process (PID=5327) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:32:25.248+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:32:25.254+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:32:25.252+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:32:25.592+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:32:25.591+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:32:26.785+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:32:26.871+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:32:26.870+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:32:26.918+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:32:26.918+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:32:27.075+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.851 seconds
[2025-09-11T17:33:07.273+0000] {processor.py:161} INFO - Started process (PID=5342) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:33:07.276+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:33:07.284+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:33:07.283+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:33:07.588+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:33:07.587+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:33:08.708+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:33:08.780+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:33:08.779+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:33:08.812+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:33:08.811+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:33:09.895+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.642 seconds
[2025-09-11T17:33:40.827+0000] {processor.py:161} INFO - Started process (PID=5357) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:33:40.830+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:33:40.839+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:33:40.838+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:33:41.087+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:33:41.086+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:33:41.879+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:33:41.948+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:33:41.948+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:33:41.977+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:33:41.977+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:33:42.107+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.299 seconds
[2025-09-11T17:34:41.409+0000] {processor.py:161} INFO - Started process (PID=5376) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:34:41.418+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:34:41.430+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:34:41.428+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:34:41.781+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:34:41.780+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:34:43.240+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:34:43.332+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:34:43.331+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:34:43.373+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:34:43.372+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:34:43.572+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.182 seconds
[2025-09-11T17:35:30.665+0000] {processor.py:161} INFO - Started process (PID=5393) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:35:30.679+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:35:30.709+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:35:30.704+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:35:32.202+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:35:32.199+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:35:34.942+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:35:35.073+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:35:35.072+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:35:35.123+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:35:35.123+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:35:35.306+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.712 seconds
[2025-09-11T17:36:21.190+0000] {processor.py:161} INFO - Started process (PID=5409) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:36:21.197+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:36:21.222+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:36:21.219+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:36:22.237+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:36:22.233+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:36:24.923+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:36:25.061+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:36:25.059+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:36:25.130+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:36:25.129+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:36:25.381+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.280 seconds
[2025-09-11T17:36:58.549+0000] {processor.py:161} INFO - Started process (PID=5424) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:36:58.553+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:36:58.559+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:36:58.558+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:36:58.916+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:36:58.915+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:37:00.053+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:37:00.142+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:37:00.141+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:37:00.191+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:37:00.190+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:37:00.454+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.924 seconds
[2025-09-11T17:37:45.024+0000] {processor.py:161} INFO - Started process (PID=5441) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:37:45.038+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:37:45.066+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:37:45.057+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:37:46.267+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:37:46.257+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:37:48.557+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:37:48.711+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:37:48.709+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:37:48.785+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:37:48.784+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:37:49.150+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.196 seconds
[2025-09-11T17:38:35.298+0000] {processor.py:161} INFO - Started process (PID=5456) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:38:35.311+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:38:35.332+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:38:35.328+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:38:36.747+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:38:36.735+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:38:38.800+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:38:38.909+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:38:38.908+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:38:38.955+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:38:38.954+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:38:39.190+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.035 seconds
[2025-09-11T17:39:21.076+0000] {processor.py:161} INFO - Started process (PID=5471) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:39:21.097+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:39:21.134+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:39:21.130+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:39:22.175+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:39:22.172+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:39:25.001+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:39:25.097+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:39:25.096+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:39:25.142+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:39:25.142+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:39:25.301+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.319 seconds
[2025-09-11T17:40:14.438+0000] {processor.py:161} INFO - Started process (PID=5486) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:40:14.447+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:40:14.455+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:40:14.454+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:40:14.893+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:40:14.892+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:40:16.514+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:40:16.639+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:40:16.638+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:40:16.695+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:40:16.694+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:40:17.270+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.858 seconds
[2025-09-11T17:41:00.625+0000] {processor.py:161} INFO - Started process (PID=5502) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:41:00.627+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:41:00.633+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:41:00.632+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:41:00.966+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:41:00.965+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:41:01.982+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:41:02.069+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:41:02.068+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:41:02.106+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:41:02.105+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:41:02.337+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.732 seconds
[2025-09-11T17:41:53.004+0000] {processor.py:161} INFO - Started process (PID=5517) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:41:53.015+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:41:53.024+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:41:53.023+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:41:53.945+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:41:53.943+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:41:57.442+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:41:57.738+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:41:57.737+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:41:57.770+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:41:57.769+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:41:57.892+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.925 seconds
[2025-09-11T17:42:51.331+0000] {processor.py:161} INFO - Started process (PID=5537) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:42:51.340+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:42:51.376+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:42:51.371+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:42:52.446+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:42:52.443+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:42:54.609+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:42:54.775+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:42:54.774+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:42:54.872+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:42:54.870+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:42:55.072+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.866 seconds
[2025-09-11T17:43:44.342+0000] {processor.py:161} INFO - Started process (PID=5553) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:43:44.351+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:43:44.369+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:43:44.365+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:43:45.391+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:43:45.388+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:43:47.958+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:43:48.058+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:43:48.056+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:43:48.103+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:43:48.102+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:43:48.370+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.092 seconds
[2025-09-11T17:44:51.287+0000] {processor.py:161} INFO - Started process (PID=5572) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:44:51.291+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:44:51.301+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:44:51.297+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:44:51.904+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:44:51.902+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:44:53.452+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:44:53.545+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:44:53.544+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:44:53.585+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:44:53.585+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:44:53.791+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.533 seconds
[2025-09-11T17:45:36.214+0000] {processor.py:161} INFO - Started process (PID=5587) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:45:36.247+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:45:36.338+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:45:36.335+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:45:37.303+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:45:37.302+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:45:38.694+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:45:38.791+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:45:38.789+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:45:38.830+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:45:38.830+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:45:39.016+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.896 seconds
[2025-09-11T17:46:29.000+0000] {processor.py:161} INFO - Started process (PID=5606) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:46:29.014+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:46:29.053+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:46:29.047+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:46:30.025+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:46:30.020+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:46:32.808+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:46:32.945+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:46:32.943+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:46:32.997+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:46:32.997+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:46:33.289+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.386 seconds
[2025-09-11T17:47:18.822+0000] {processor.py:161} INFO - Started process (PID=5622) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:47:18.832+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:47:18.857+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:47:18.849+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:47:20.293+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:47:20.282+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:47:22.531+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:47:22.715+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:47:22.714+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:47:22.771+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:47:22.768+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:47:23.024+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.354 seconds
[2025-09-11T17:48:05.975+0000] {processor.py:161} INFO - Started process (PID=5637) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:48:05.981+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:48:05.999+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:48:05.996+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:48:07.609+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:48:07.604+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:48:11.267+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:48:11.361+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:48:11.360+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:48:11.399+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:48:11.399+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:48:11.642+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 5.732 seconds
[2025-09-11T17:49:20.051+0000] {processor.py:161} INFO - Started process (PID=5656) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:49:20.054+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:49:20.060+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:49:20.059+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:49:20.506+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:49:20.505+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:49:21.749+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:49:21.838+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:49:21.836+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:49:21.876+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:49:21.875+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:49:22.064+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.042 seconds
[2025-09-11T17:50:05.722+0000] {processor.py:161} INFO - Started process (PID=5672) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:50:05.726+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:50:05.732+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:50:05.731+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:50:06.037+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:50:06.035+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:50:07.498+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:50:07.560+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:50:07.557+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:50:07.585+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:50:07.585+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:50:07.695+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.992 seconds
[2025-09-11T17:50:49.431+0000] {processor.py:161} INFO - Started process (PID=5686) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:50:49.447+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:50:49.485+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:50:49.476+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:50:50.882+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:50:50.874+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:50:53.074+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:50:53.222+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:50:53.220+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:50:53.283+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:50:53.282+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:50:53.534+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.177 seconds
[2025-09-11T17:51:39.677+0000] {processor.py:161} INFO - Started process (PID=5701) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:51:39.686+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:51:39.709+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:51:39.705+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:51:40.922+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:51:40.919+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:51:43.409+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:51:43.548+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:51:43.546+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:51:43.608+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:51:43.607+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:51:43.912+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.287 seconds
[2025-09-11T17:52:25.784+0000] {processor.py:161} INFO - Started process (PID=5717) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:52:25.790+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:52:25.803+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:52:25.801+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:52:26.602+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:52:26.599+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:52:28.648+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:52:28.871+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:52:28.869+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:52:28.939+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:52:28.938+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:52:29.191+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.453 seconds
[2025-09-11T17:53:18.982+0000] {processor.py:161} INFO - Started process (PID=5732) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:53:19.000+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:53:19.021+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:53:19.019+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:53:19.873+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:53:19.867+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:53:22.242+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:53:22.341+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:53:22.340+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:53:22.386+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:53:22.386+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:53:22.590+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.687 seconds
[2025-09-11T17:54:27.791+0000] {processor.py:161} INFO - Started process (PID=5752) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:54:27.794+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:54:27.810+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:54:27.808+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:54:28.112+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:54:28.111+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:54:29.242+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:54:29.306+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:54:29.305+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:54:29.333+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:54:29.333+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:54:29.438+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.680 seconds
[2025-09-11T17:55:21.097+0000] {processor.py:161} INFO - Started process (PID=5770) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:55:21.101+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:55:21.115+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:55:21.107+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:55:21.492+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:55:21.491+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:55:23.318+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:55:23.397+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:55:23.396+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:55:23.431+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:55:23.431+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:55:23.595+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.535 seconds
[2025-09-11T17:56:04.531+0000] {processor.py:161} INFO - Started process (PID=5786) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:56:04.540+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:56:04.574+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:56:04.568+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:56:05.583+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:56:05.581+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:56:08.799+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:56:08.932+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:56:08.931+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:56:08.992+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:56:08.992+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:56:09.252+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.795 seconds
[2025-09-11T17:56:53.200+0000] {processor.py:161} INFO - Started process (PID=5801) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:56:53.230+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:56:53.282+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:56:53.276+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:56:54.108+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:56:54.106+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:56:56.515+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:56:56.650+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:56:56.649+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:56:56.702+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:56:56.701+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:56:57.063+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.008 seconds
[2025-09-11T17:57:48.723+0000] {processor.py:161} INFO - Started process (PID=5820) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:57:48.754+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:57:48.794+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:57:48.790+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:57:50.270+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:57:50.268+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:57:52.163+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:57:52.348+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:57:52.346+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:57:52.418+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:57:52.417+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:57:52.726+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.190 seconds
[2025-09-11T17:58:51.059+0000] {processor.py:161} INFO - Started process (PID=5838) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:58:51.077+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:58:51.109+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:58:51.104+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:58:52.050+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:58:52.048+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:58:54.268+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:58:54.464+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:58:54.462+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:58:54.526+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:58:54.525+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:58:54.768+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.866 seconds
[2025-09-11T17:59:50.836+0000] {processor.py:161} INFO - Started process (PID=5853) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:59:50.840+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T17:59:50.848+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:59:50.847+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:59:51.297+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:59:51.294+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T17:59:53.053+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T17:59:53.160+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:59:53.159+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T17:59:53.206+0000] {logging_mixin.py:188} INFO - [2025-09-11T17:59:53.205+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T17:59:53.386+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.580 seconds
[2025-09-11T18:00:38.905+0000] {processor.py:161} INFO - Started process (PID=5868) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T18:00:38.911+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T18:00:38.920+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:00:38.918+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T18:00:39.414+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:00:39.413+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T18:00:40.875+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T18:00:40.975+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:00:40.974+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T18:00:41.018+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:00:41.018+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T18:00:41.196+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.322 seconds
[2025-09-11T18:01:20.803+0000] {processor.py:161} INFO - Started process (PID=5884) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T18:01:20.814+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T18:01:20.827+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:01:20.825+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T18:01:21.372+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:01:21.370+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T18:01:23.323+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T18:01:23.429+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:01:23.428+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T18:01:23.477+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:01:23.476+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T18:01:23.699+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.935 seconds
[2025-09-11T18:02:06.355+0000] {processor.py:161} INFO - Started process (PID=5899) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T18:02:06.365+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T18:02:06.386+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:02:06.384+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T18:02:07.865+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:02:07.862+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T18:02:10.000+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T18:02:10.119+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:02:10.118+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T18:02:10.190+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:02:10.189+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T18:02:10.518+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.223 seconds
[2025-09-11T18:02:53.633+0000] {processor.py:161} INFO - Started process (PID=5914) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T18:02:53.637+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T18:02:53.645+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:02:53.643+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T18:02:54.084+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:02:54.083+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T18:02:55.724+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T18:02:55.818+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:02:55.817+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T18:02:55.857+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:02:55.856+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T18:02:56.050+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.445 seconds
[2025-09-11T18:03:36.942+0000] {processor.py:161} INFO - Started process (PID=5929) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T18:03:36.946+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T18:03:36.960+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:03:36.958+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T18:03:37.581+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:03:37.579+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T18:03:39.344+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T18:03:39.456+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:03:39.455+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T18:03:39.503+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:03:39.503+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T18:03:39.683+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.778 seconds
[2025-09-11T18:04:22.340+0000] {processor.py:161} INFO - Started process (PID=5944) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T18:04:22.344+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T18:04:22.355+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:04:22.353+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T18:04:22.826+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:04:22.825+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T18:04:24.215+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T18:04:24.462+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:04:24.461+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T18:04:24.535+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:04:24.535+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T18:04:24.742+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.430 seconds
[2025-09-11T18:05:13.422+0000] {processor.py:161} INFO - Started process (PID=5959) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T18:05:13.425+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T18:05:13.432+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:05:13.430+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T18:05:13.921+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:05:13.918+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T18:05:15.780+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T18:05:15.896+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:05:15.895+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T18:05:15.945+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:05:15.945+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T18:05:16.128+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 2.726 seconds
[2025-09-11T18:06:02.381+0000] {processor.py:161} INFO - Started process (PID=5975) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T18:06:02.393+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T18:06:02.420+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:06:02.416+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T18:06:03.494+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:06:03.492+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T18:06:05.982+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T18:06:06.117+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:06:06.116+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T18:06:06.184+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:06:06.182+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T18:06:06.814+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.536 seconds
[2025-09-11T18:06:50.952+0000] {processor.py:161} INFO - Started process (PID=5990) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T18:06:50.969+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T18:06:51.006+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:06:51.002+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T18:06:52.326+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:06:52.313+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T18:06:55.067+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T18:06:55.171+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:06:55.170+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T18:06:55.209+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:06:55.209+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T18:06:55.408+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.564 seconds
[2025-09-11T18:07:34.747+0000] {processor.py:161} INFO - Started process (PID=6005) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T18:07:34.758+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T18:07:34.779+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:07:34.776+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T18:07:35.852+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:07:35.849+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T18:07:38.882+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T18:07:39.038+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:07:39.037+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T18:07:39.121+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:07:39.121+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T18:07:39.337+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.663 seconds
[2025-09-11T18:08:33.629+0000] {processor.py:161} INFO - Started process (PID=6024) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T18:08:33.649+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T18:08:33.700+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:08:33.695+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T18:08:35.071+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:08:35.068+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T18:08:37.094+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T18:08:37.195+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:08:37.194+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T18:08:37.233+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:08:37.232+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T18:08:37.460+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.006 seconds
[2025-09-11T18:09:34.367+0000] {processor.py:161} INFO - Started process (PID=6043) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T18:09:34.375+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T18:09:34.382+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:09:34.380+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T18:09:34.767+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:09:34.766+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T18:09:35.841+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T18:09:35.898+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:09:35.897+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T18:09:35.921+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:09:35.920+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T18:09:36.036+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 1.695 seconds
[2025-09-11T18:10:22.814+0000] {processor.py:161} INFO - Started process (PID=6060) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T18:10:22.819+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T18:10:22.890+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:10:22.888+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T18:10:23.854+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:10:23.853+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T18:10:25.503+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T18:10:25.582+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:10:25.581+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T18:10:25.617+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:10:25.617+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T18:10:25.778+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 3.005 seconds
[2025-09-11T18:11:11.768+0000] {processor.py:161} INFO - Started process (PID=6075) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T18:11:11.779+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T18:11:11.809+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:11:11.805+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T18:11:12.860+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:11:12.857+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T18:11:15.387+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T18:11:15.534+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:11:15.533+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T18:11:16.177+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:11:16.177+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T18:11:16.578+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.913 seconds
[2025-09-11T18:12:09.658+0000] {processor.py:161} INFO - Started process (PID=6095) to work on /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T18:12:09.673+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/snowspark-dataframe-ETL.py for tasks to queue
[2025-09-11T18:12:09.741+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:12:09.724+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T18:12:11.727+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:12:11.720+0000] {utils.py:1009} INFO - AST state has not been set explicitly. Defaulting to ast_enabled = True.
[2025-09-11T18:12:13.570+0000] {processor.py:840} INFO - DAG(s) 'snowpark_dataframe_dag_1' retrieved from /opt/airflow/dags/snowspark-dataframe-ETL.py
[2025-09-11T18:12:13.661+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:12:13.660+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-09-11T18:12:13.699+0000] {logging_mixin.py:188} INFO - [2025-09-11T18:12:13.699+0000] {dag.py:3954} INFO - Setting next_dagrun for snowpark_dataframe_dag_1 to None, run_after=None
[2025-09-11T18:12:13.893+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/snowspark-dataframe-ETL.py took 4.343 seconds
